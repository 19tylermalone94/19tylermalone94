{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/19tylermalone94/19tylermalone94/blob/main/Final_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbC0B5tuT1ny",
        "outputId": "d314838d-6089-414a-881b-b1bbd387a148"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.6-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmN6tQkTgLb2",
        "outputId": "cf30a460-cfb8-4a0d-e45c-b15e5f394469"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Tyler, this will save any files being made during the process to our respective google drives\n",
        "#Just gotta be sure to run this and authenticate before running any code that creates files\n",
        "#or else I think the file goes away if a session automatically disconnects/ends.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cw3UaouQd_FW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "import random\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import multiprocessing\n",
        "from sklearn import svm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import LinearSVC\n",
        "from collections import defaultdict\n",
        "from joblib import Parallel, delayed\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsXghBhpPtqB",
        "outputId": "fa5072ee-fcf2-4142-d43f-8c32dcbab261"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  a1 a2 a3 a4 a5 a6 b1 b2 b3 b4  ... f3 f4 f5 f6 g1 g2 g3 g4 g5 g6\n",
            "0  b  b  b  b  b  b  b  b  b  b  ...  b  b  b  b  b  b  b  b  b  b\n",
            "1  b  b  b  b  b  b  b  b  b  b  ...  b  b  b  b  b  b  b  b  b  b\n",
            "2  b  b  b  b  b  b  o  b  b  b  ...  b  b  b  b  b  b  b  b  b  b\n",
            "\n",
            "[3 rows x 42 columns]\n",
            "  class\n",
            "0   win\n",
            "1   win\n",
            "2   win\n"
          ]
        }
      ],
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "connect_4 = fetch_ucirepo(id=26)\n",
        "\n",
        "# print first 3 examples\n",
        "print(connect_4.data.features.head(3))\n",
        "print(connect_4.data.targets.head(3))\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = connect_4.data.features\n",
        "y = connect_4.data.targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzgzcIC1X6eU"
      },
      "source": [
        "# UCIML Connect 4 Dataset Overview\n",
        "\n",
        "The UCIML Connect 4 dataset, available from the UCI Machine Learning Repository https://archive.ics.uci.edu/dataset/26/connect+4, is a collection of examples that represent incomplete Connect 4 games, with outcome predictions calculated by some 8-move look ahead strategy.\n",
        "\n",
        "## Dataset Details\n",
        "\n",
        "- **Number of Instances:** The dataset comprises over 67,000 instances, each representing a unique board configuration at the stage of the game when the dataset was captured.\n",
        "- **Number of Attributes:** Each instance has 43 attributes. The first 42 attributes represent each cell in the game board, labeled from top to bottom, left to right. Each cell is described by one of three statuses: `b` (blank), `x` (player x’s disk), or `o` (player o’s disk). The 43rd attribute is the class label indicating the outcome (`win`, `loss`, or `draw`) from the perspective of the player about to move.\n",
        "\n",
        "## Objective\n",
        "The inital objective was to train both a support vector classifier (SVC), and a neural network classifier (NN), to predict the outcome of the game (43rd data attribute).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8XEICmcQbnM"
      },
      "source": [
        "Website link to the data: https://archive.ics.uci.edu/dataset/26/connect+4\n",
        "\n",
        "Dataset Information\n",
        "\n",
        "This database contains all legal 8-ply positions in the game of connect-4 in which neither player has won yet, and in which the next move is not forced.\n",
        "\n",
        "x is the first player; o the second.\n",
        "\n",
        "The outcome class is the game theoretical value for the first player (win, loss, draw).\n",
        "\n",
        "Contains 67557 datapoints and 42 features (the individual locations on the board).\n",
        "\n",
        "Attribute Information: (x=player x has taken, o=player o has taken, b=blank)\n",
        "\n",
        "\n",
        "The board is numbered like:  \n",
        "6 . . . . . . .  \n",
        "5 . . . . . . .  \n",
        "4 . . . . . . .  \n",
        "3 . . . . . . .  \n",
        "2 . . . . . . .  \n",
        "1 . . . . . . .  \n",
        " a b c d e f g\n",
        "\n",
        "\n",
        "1. a1: (x,o,b)  \n",
        "2. a2: (x,o,b)  \n",
        "3. a3: (x,o,b)  \n",
        "4. a4: (x,o,b)  \n",
        "5. a5: (x,o,b)  \n",
        "6. a6: (x,o,b)  \n",
        "7. b1: (x,o,b)  \n",
        "8. b2: (x,o,b)  \n",
        "9. b3: (x,o,b)  \n",
        "10. b4: (x,o,b)  \n",
        "11. b5: (x,o,b)  \n",
        "12. b6: (x,o,b)  \n",
        "13. c1: (x,o,b)  \n",
        "14. c2: (x,o,b)  \n",
        "15. c3: (x,o,b)  \n",
        "16. c4: (x,o,b)\n",
        "17. c5: (x,o,b)\n",
        "18. c6: (x,o,b)\n",
        "19. d1: (x,o,b)\n",
        "20. d2: (x,o,b)\n",
        "21. d3: (x,o,b)\n",
        "22. d4: (x,o,b)\n",
        "23. d5: (x,o,b)\n",
        "24. d6: (x,o,b)\n",
        "25. e1: (x,o,b)\n",
        "26. e2: (x,o,b)\n",
        "27. e3: (x,o,b)\n",
        "28. e4: (x,o,b)\n",
        "29. e5: (x,o,b)\n",
        "30. e6: (x,o,b)\n",
        "31. f1: (x,o,b)\n",
        "32. f2: (x,o,b)\n",
        "33. f3: (x,o,b)\n",
        "34. f4: (x,o,b)\n",
        "35. f5: (x,o,b)\n",
        "36. f6: (x,o,b)\n",
        "37. g1: (x,o,b)\n",
        "38. g2: (x,o,b)\n",
        "39. g3: (x,o,b)\n",
        "40. g4: (x,o,b)\n",
        "41. g5: (x,o,b)\n",
        "42. g6: (x,o,b)\n",
        "43. Class: (win,loss,draw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNXtCiuuQ4I_"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In the codeblock below, we can see that this dataset is quite strongly imbalanced so we have made attempts to account for this in our models as well focusing on balanced accuracy as our main metric. We initially began our investigations using just regular accuracy and both our SVM and neural network models were capping around 85% accuracy. Good accuracy but largely due to the fact that it was very good at predicting the dominant class that had the most test and training representatives. We figured it would be better to focus on approaching this from a balanced accuracy perspective for the sake of demonstrating the extra steps necessary to account for imbalanced datasets. Given the low-stakes nature of predictions on a game of Connect 4, either metric feels fairly arbitrary at the end of the day but, again, the balanced approach demonstrates more knowledge.\n",
        "\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Due to the amount of knowledge learned along the way for this project and the switch to balanced accuracy, our code ended up reworked and fine-tuned from our earlier tests around plain accuracy. Many results were simply stored in the variables of the notebook kernel and due to various issues along the way requiring a restart of the kernel for the sake of cutting excessively long unfinished trials short, most of the original data for the plain accuracy tests is no longer around but we did take notes and some big takeaways based on that early testing which we will reference throughout other parts of this notebook. Our approach for much of the longer running codeblocks now stores information in json files as models are trained so that we could stop losing data if the kernel restarted or if we needed to cut a training session short before it could finish all hyperparameter permutations (and therefore the final results list would not be in a usable state). However, the vast majority of the code you will see was the same we used in these plain accuracy trials so even though most of the data is not around, just know that our approach was very similar to the balanced accuracy portion that is much better documented. When we use \"accuracy\" on its own in this document, we are referring to balanced accuracy and \"plain accuracy\" will be how we refer to our initial accuracy tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OI2nzcuKRAPt",
        "outputId": "dbc4d42b-22ea-4f6f-b2da-9f7f48e17528"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Win percentage: 65.83%\n",
            "Loss percentage: 24.62%\n",
            "Draw percentage: 9.55%\n"
          ]
        }
      ],
      "source": [
        "class_counts = pd.Series(y['class']).value_counts()\n",
        "total_samples = class_counts.sum()\n",
        "\n",
        "win_percentage = (class_counts['win'] / total_samples) * 100\n",
        "loss_percentage = (class_counts['loss'] / total_samples) * 100\n",
        "draw_percentage = (class_counts['draw'] / total_samples) * 100\n",
        "\n",
        "print(f\"Win percentage: {win_percentage:.2f}%\")\n",
        "print(f\"Loss percentage: {loss_percentage:.2f}%\")\n",
        "print(f\"Draw percentage: {draw_percentage:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJvDemHaaLY-"
      },
      "source": [
        "# SVM Section\n",
        "\n",
        "To begin processing the data, we needed to translate the values of x/o/b (game pieces or (b)lank/empty spots)\n",
        "and win/loss/draw into numbers that our SVMs could better work with. Once done with that, they are transformed\n",
        "into arrays for easy processing because out of the box SVMs are not set up to work with pandas dataframes. We set aside 15% of the data for a final test set, 15% for validation data, and the remaining 70% for training purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1SUbbAfZ84q",
        "outputId": "0718119d-d4fe-4e3b-da6b-81804c997813"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0.08341695  1.87285453 -0.4425539  -0.29486271 -0.17804405 -0.08515059\n",
            "  1.31036912  0.51607082 -0.46344946 -0.30455314 -0.18086918 -0.08465818\n",
            " -1.43984895 -0.8145394  -0.49367353 -0.31685436 -0.18255183 -0.08296368\n",
            " -1.02539776 -0.61493172 -0.38468716 -0.25092033 -0.1439731  -0.06454235\n",
            " -0.76667509 -0.43517445 -0.27208348 -0.16992488 -0.09112061 -0.03544077\n",
            "  1.43286599 -0.52785567 -0.32517488 -0.19431067 -0.10006771 -0.03622119\n",
            "  0.19401288  0.77094251  3.37385726 -0.21375886 -0.10776536 -0.03603316]\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "X_encode_map = {'x':1, 'o': 2, 'b': 0}\n",
        "X_encoded_dataframes = X.replace(X_encode_map)\n",
        "X_encoded = X_encoded_dataframes.values\n",
        "\n",
        "y_encode_map = {\"win\": 1, \"loss\": 2, \"draw\": 0}\n",
        "y_encoded_dataframes = y.replace({\"class\": y_encode_map})\n",
        "y_encoded = y_encoded_dataframes['class'].values\n",
        "\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X_encoded, y_encoded, test_size=0.15, random_state=5, stratify=y_encoded)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_val_std = scaler.fit_transform(X_train_val)\n",
        "\n",
        "X_train_full, X_val, y_train_full, y_val = train_test_split(\n",
        "    X_train_val_std, y_train_val, test_size=0.1765, random_state=5, stratify=y_train_val)\n",
        "    #0.1765 gives us 15% of our entire dataset as validation sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K11ErHUPaQoU"
      },
      "source": [
        "Due to the size of the data (approximately 67.5k instances), we quickly realized we would need to find a way to speed\n",
        "up data processing if we wanted to do a thorough investigation of different hyperparameter settings without spending\n",
        "hours on every configuration. We will discuss this in more detail in several relevant sections below. To start,\n",
        "the code cell below this one has the PCA code necessary to determine the amount of principal components we can reduce\n",
        "to while still maintaining the majority of our data's information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "Q5mrf3wBaJgp",
        "outputId": "7d2518f1-ec92-4a07-9ff6-77d7055e782d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of features needed to maintain:\n",
            "80% of the original information: 24\n",
            "85% of the original information: 27\n",
            "90% of the original information: 31\n",
            "95% of the original information: 36\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x79458a151a80>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_encoded)\n",
        "pca = PCA(n_components=42)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "explained_variance_ratio = pca.explained_variance_ratio_\n",
        "\n",
        "feature_counts = {'80%': None, '85%': None, '90%': None, '95%': None}\n",
        "total_variance = 0\n",
        "\n",
        "# This will calculate how many principal components we need to maintain different percentages of our information.\n",
        "for i, ratio in enumerate(explained_variance_ratio):\n",
        "    total_variance += ratio\n",
        "    for threshold in feature_counts:\n",
        "        if feature_counts[threshold] is None and total_variance >= float(threshold.strip('%')) / 100:\n",
        "            feature_counts[threshold] = i + 1  # Add 1 to convert from 0-based index to count of features\n",
        "            break\n",
        "\n",
        "print(\"Number of features needed to maintain:\")\n",
        "for threshold, count in feature_counts.items():\n",
        "    print(f\"{threshold} of the original information:\", count)\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.bar(range(1, 43), pca.explained_variance_ratio_, alpha=0.5, align='center', label='Individual explained variance')\n",
        "plt.step(range(1, 43), np.cumsum(pca.explained_variance_ratio_), where='mid', label='Cumulative explained variance')\n",
        "plt.ylabel('Explained variance ratio')\n",
        "plt.xlabel('Principal components')\n",
        "plt.legend(loc='best')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10hioGOZb6eG"
      },
      "source": [
        "We now needed to get some baseline results to compare our experiments against. We ran tests for a range of poly kernel degrees as well as the gamma=[\"auto\", \"scale\"] values for rbf kernels. In the section below, we start with a full, unmodified data run for an absolute baseline and then start comparing those results with the accuracy achieved when we run the same models using different levels of principal components. Our goal here was to assess what would be a reasonable trade off between reduced accuracy compared to time savings for using lower amounts of principal components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDfkTcQLAkWP",
        "outputId": "ef6fd282-9319-42a6-a0d0-8910e981b7ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Following results use the original data (no PCA).\n",
            "Balanced accuracy for 2 degree: 0.6009\n",
            "Balanced accuracy for 3 degree: 0.6137\n",
            "Balanced accuracy for 4 degree: 0.6049\n",
            "Balanced accuracy for 5 degree: 0.5653\n",
            "Balanced accuracy for 6 degree: 0.5160\n",
            "Balanced accuracy for auto as gamma value: 0.6578\n",
            "Balanced accuracy for scale as gamma value: 0.6575\n",
            "Total time for components None: 37m 33.8s\n",
            "\n",
            "Following results use 36 principal components:\n",
            "Balanced accuracy for 2 degree: 0.5696\n",
            "Balanced accuracy for 3 degree: 0.5840\n",
            "Balanced accuracy for 4 degree: 0.5796\n",
            "Balanced accuracy for 5 degree: 0.5394\n",
            "Balanced accuracy for 6 degree: 0.5041\n",
            "Balanced accuracy for auto as gamma value: 0.6331\n",
            "Balanced accuracy for scale as gamma value: 0.6281\n",
            "Total time for components 36: 30m 19.2s\n",
            "\n",
            "Following results use 31 principal components:\n",
            "Balanced accuracy for 2 degree: 0.5498\n",
            "Balanced accuracy for 3 degree: 0.5658\n",
            "Balanced accuracy for 4 degree: 0.5636\n",
            "Balanced accuracy for 5 degree: 0.5281\n",
            "Balanced accuracy for 6 degree: 0.4913\n",
            "Balanced accuracy for auto as gamma value: 0.6141\n",
            "Balanced accuracy for scale as gamma value: 0.6084\n",
            "Total time for components 31: 34m 7.8s\n",
            "\n",
            "Following results use 27 principal components:\n",
            "Balanced accuracy for 2 degree: 0.5250\n",
            "Balanced accuracy for 3 degree: 0.5423\n",
            "Balanced accuracy for 4 degree: 0.5535\n",
            "Balanced accuracy for 5 degree: 0.5133\n",
            "Balanced accuracy for 6 degree: 0.4871\n",
            "Balanced accuracy for auto as gamma value: 0.6007\n",
            "Balanced accuracy for scale as gamma value: 0.5877\n",
            "Total time for components 27: 31m 1.4s\n",
            "\n",
            "Following results use 24 principal components:\n",
            "Balanced accuracy for 2 degree: 0.4953\n",
            "Balanced accuracy for 3 degree: 0.5239\n",
            "Balanced accuracy for 4 degree: 0.5364\n",
            "Balanced accuracy for 5 degree: 0.5051\n",
            "Balanced accuracy for 6 degree: 0.4742\n",
            "Balanced accuracy for auto as gamma value: 0.5830\n",
            "Balanced accuracy for scale as gamma value: 0.5734\n",
            "Total time for components 24: 29m 16.8s\n"
          ]
        }
      ],
      "source": [
        "pca_components = [None, 36, 31, 27, 24]  # None represents the original training data\n",
        "results_baseline = defaultdict(dict)\n",
        "total_time_per_component = []\n",
        "\n",
        "for components in pca_components:\n",
        "    component_start_time = time.time()\n",
        "\n",
        "    if components is not None:\n",
        "        print(f\"\\nFollowing results use {components} principal components:\")\n",
        "        pca = PCA(n_components=components)\n",
        "        X_train_pca = pca.fit_transform(X_train_full)\n",
        "        X_val_pca = pca.transform(X_val)\n",
        "        X_new_train = X_train_pca\n",
        "        X_new_val = X_val_pca\n",
        "    else:\n",
        "        print(\"Following results use the original data (no PCA).\")\n",
        "        X_new_train = X_train_full\n",
        "        X_new_val = X_val\n",
        "\n",
        "    poly_results = defaultdict(tuple)\n",
        "\n",
        "    for degree in range(2, 7):\n",
        "        svc_poly = svm.SVC(kernel='poly', degree=degree, C=1.0, coef0=0.0, class_weight='balanced')\n",
        "        svc_poly.fit(X_new_train, y_train_full)\n",
        "        y_pred_poly = svc_poly.predict(X_new_val)\n",
        "        report = classification_report(y_val, y_pred_poly)\n",
        "        balanced_accuracy = balanced_accuracy_score(y_val, y_pred_poly)\n",
        "        poly_results[degree] = (balanced_accuracy, report)\n",
        "        print(f\"Balanced accuracy for {degree} degree: {balanced_accuracy:.4f}\")\n",
        "\n",
        "    rbf_results = defaultdict(tuple)\n",
        "    gamma_values = [\"auto\", \"scale\"]\n",
        "\n",
        "    for gamma in gamma_values:\n",
        "        svc_rbf = svm.SVC(kernel='rbf', C=1.0, gamma=gamma, class_weight='balanced')\n",
        "        svc_rbf.fit(X_new_train, y_train_full)\n",
        "        y_pred_rbf = svc_rbf.predict(X_new_val)\n",
        "        report = classification_report(y_val, y_pred_rbf)\n",
        "        balanced_accuracy = balanced_accuracy_score(y_val, y_pred_rbf)\n",
        "        rbf_results[gamma] = (balanced_accuracy, report)\n",
        "        print(f\"Balanced accuracy for {gamma} as gamma value: {balanced_accuracy:.4f}\")\n",
        "\n",
        "    results_baseline[components] = {'poly': poly_results, 'rbf': rbf_results}\n",
        "\n",
        "    elapsed_time = time.time() - component_start_time\n",
        "    total_time_per_component.append(elapsed_time)\n",
        "    minutes, seconds = divmod(elapsed_time, 60)\n",
        "    print(f\"Total time for components {components}: {int(minutes)}m {seconds:.1f}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMtuHGDJBCPl"
      },
      "source": [
        "Below is simply some code to set up a table for easy comparison of these output values above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YqMgbZOpcSO",
        "outputId": "505a2e97-42d4-4f51-8b43-c022f1524497"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "PCA Comp   Avg Accuracy         Acc Diff             Time (s)             % of Baseline Time  \n",
            "None       0.6023               0.0000               2253.8               100.0               %\n",
            "36         0.5769               -0.0255              1819.2               80.7                %\n",
            "31         0.5601               -0.0422              2047.8               90.9                %\n",
            "27         0.5442               -0.0581              1861.4               82.6                %\n",
            "24         0.5273               -0.0750              1756.8               77.9                %\n"
          ]
        }
      ],
      "source": [
        "baseline_info = None\n",
        "\n",
        "# Below is for setting up a table to compare our accuracy loss and time savings\n",
        "print()\n",
        "print(\"{:<10} {:<20} {:<20} {:<20} {:<20}\".format('PCA Comp', 'Avg Accuracy', 'Acc Diff', 'Time (s)', '% of Baseline Time'))\n",
        "for i, components in enumerate(pca_components):\n",
        "    accuracies = [result[0] for result_dict in results_baseline[components].values() for result in result_dict.values()]\n",
        "    avg_accuracy = np.mean(accuracies)\n",
        "    time_for_components = total_time_per_component[i]\n",
        "\n",
        "    if components is None:\n",
        "        accuracy_diff = 0\n",
        "        time_percentage = 100\n",
        "        baseline_info = (avg_accuracy, time_for_components)\n",
        "    else:\n",
        "        baseline_avg_accuracy = baseline_info[0]\n",
        "        accuracy_diff = avg_accuracy - baseline_avg_accuracy\n",
        "        time_percentage = (time_for_components / baseline_info[1]) * 100\n",
        "\n",
        "    print(\"{:<10} {:<20.4f} {:<20.4f} {:<20.1f} {:<20.1f}%\".format(\n",
        "        'None' if components is None else components,\n",
        "        avg_accuracy,\n",
        "        accuracy_diff,\n",
        "        time_for_components,\n",
        "        time_percentage\n",
        "    ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1NQHH-GvzSN"
      },
      "source": [
        "\n",
        "PCA Comp   Avg Accuracy         Acc Diff             Time (s)             % of Baseline Time  \n",
        "None       0.6023               0.0000               983.8                100.0               %  \n",
        "36         0.5769               -0.0255              828.4                84.2                %  \n",
        "31         0.5602               -0.0421              799.7                81.3                %  \n",
        "27         0.5471               -0.0552              777.5                79.0                %  \n",
        "24         0.5241               -0.0782              786.7                80.0  \n",
        "\n",
        "RETURN TO THIS CELL, PUT A SCREENSHOT OF THE TABLE ABOVE IN SO IT'S NOT IMPOSSIBLE TO READ.\n",
        "\n",
        "We would like to note that the majority of SVM testing was done on one of our laptops and that the results you see in the cell above do not match what consistently happened in that environment. This Final_Report notebook is made up of code transferred as we polished it up and we ran it using Google's Colab environment for the sake of showing you what the output looks like but we did not anticipate how frequently Colab would disconnect and how varied the time metrics would be in said environment so please forgive us for that inconsistency.\n",
        "\n",
        "Below you will see an image [INSERT TABLE IMAGE FROM ABOVE BELOW] that reflects what we saw during testing. You can see that using 31 principal components, we can save about ~19% of our time in exchange for a straight loss of 4.21% to our averaged balanced accuracy. At 31 PCs, we retain 90% of our original information and the aforementioned tradeoff seemed to be the most reasonable of the options available as we knew we wanted to give ourselves a little more accuracy wiggle room for when we experimented with reduced datasets. It's hard to truly discern how much using PCA will skew the results when doing the final testing of the hyperparameters on the full dataset but we figured, given the low stakes of Connect 4, staying within a single digit territory of accuracy loss would be acceptable for the sake of time saving.\n",
        "\n",
        "In the cell below, we have some code that will give us the average accuracy of each poly degree and each rbf gamma value across the different principal component levels. We thought narrowing our search down to the 5 highest performing models would help us save time in future parameter testing and we knew from our experimenting in plain accuracy that poly degrees of 6 and 7 did not perform well in addition to taking a drastically longer amount of time to train. From our results below, you will see that we have moved the following models onward for further experimenting: poly models using degrees 2, 3, and 4; rbf models using gamma values of \"scale\" and \"auto\". We do use the 5 and 6 model one more time in the code cell that starts with \"percent_of_training_data...\" not too far below because we wanted to be sure the accuracy average in that section was directly comparable to this section above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGiDEBq4xdYO",
        "outputId": "37a54298-934b-4385-9771-e909612f366d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avg Balanced Accuracies for 'Poly' Kernels:\n",
            "Degree 2: 0.5499\n",
            "Degree 3: 0.5637\n",
            "Degree 4: 0.5653\n",
            "Degree 5: 0.5293\n",
            "Degree 6: 0.4941\n",
            "\n",
            "Avg Balanced Accuracies for 'RBF' Kernels:\n",
            "Gamma auto: 0.6179\n",
            "Gamma scale: 0.6108\n"
          ]
        }
      ],
      "source": [
        "poly_accuracies = defaultdict(list)\n",
        "rbf_accuracies = defaultdict(list)\n",
        "\n",
        "for pca_comp, result_dict in results_baseline.items():\n",
        "    poly_results = result_dict['poly']\n",
        "    rbf_results = result_dict['rbf']\n",
        "\n",
        "    for degree, values in poly_results.items():\n",
        "        balanced_accuracy = values[0]\n",
        "        poly_accuracies[degree].append(balanced_accuracy)\n",
        "\n",
        "    for gamma, values in rbf_results.items():\n",
        "        balanced_accuracy = values[0]\n",
        "        rbf_accuracies[gamma].append(balanced_accuracy)\n",
        "\n",
        "print(\"Avg Balanced Accuracies for 'Poly' Kernels:\")\n",
        "for degree, accuracies in poly_accuracies.items():\n",
        "    average_accuracy = sum(accuracies) / len(accuracies)\n",
        "    print(f\"Degree {degree}: {average_accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nAvg Balanced Accuracies for 'RBF' Kernels:\")\n",
        "for gamma, accuracies in rbf_accuracies.items():\n",
        "    average_accuracy = sum(accuracies) / len(accuracies)\n",
        "    print(f\"Gamma {gamma}: {average_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBlI-1T6z4xf"
      },
      "source": [
        "For thoroughness, we used the code below to test a \"sigmoid\" kernel as well as a LinearSVC model. Considering these models are better suited to binary classifications and not our 3 class problem, we did not expect any impressive results and our test below confirms that they are indeed handily outcompeted by the models we moved ahead from the section above. With these poor preliminary results, we did not opt to experiment further with the 2 models below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TxfBmqg1MJh",
        "outputId": "c1087e5d-d967-4b37-87e1-4adff49599a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Balanced Accuracy (Sigmoid): 0.33073546850770585\n",
            "Test Balanced Accuracy (Sigmoid): 0.34752973240260226\n",
            "Validation Balanced Accuracy (LinearSVC): 0.39752494573185726\n",
            "Test Balanced Accuracy (LinearSVC): 0.3501545638621469\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "svc_sigmoid = svm.SVC(kernel='sigmoid', gamma='auto', coef0=1, class_weight='balanced')\n",
        "svc_sigmoid.fit(X_train_full, y_train_full)\n",
        "y_pred_sigmoid_val = svc_sigmoid.predict(X_val)\n",
        "print(\"Validation Balanced Accuracy (Sigmoid):\", balanced_accuracy_score(y_val, y_pred_sigmoid_val))\n",
        "y_pred_sigmoid_test = svc_sigmoid.predict(X_test)\n",
        "print(\"Test Balanced Accuracy (Sigmoid):\", balanced_accuracy_score(y_test, y_pred_sigmoid_test))\n",
        "\n",
        "n_samples, n_features = X_train_full.shape\n",
        "svc_linear = svm.LinearSVC(random_state=5, dual=n_samples > n_features, class_weight='balanced')\n",
        "svc_linear.fit(X_train_full, y_train_full)\n",
        "y_pred_linear_val = svc_linear.predict(X_val)\n",
        "print(\"Validation Balanced Accuracy (LinearSVC):\", balanced_accuracy_score(y_val, y_pred_linear_val))\n",
        "y_pred_linear_test = svc_linear.predict(X_test)\n",
        "print(\"Test Balanced Accuracy (LinearSVC):\", balanced_accuracy_score(y_test, y_pred_linear_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSCto3HRA45m"
      },
      "source": [
        "In the cell below, we are performing some further experimentation to see how much farther we can reduce the size of our dataset while still retaining a reasonable accuracy in comparison to the full, unmodified dataset. We ran this data set with all the same models as the PCA test for the sake of direct comparison. These models are all being run using the 31 PCs we decided on from our test above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rymqx4ETAufl",
        "outputId": "ba0bafb6-06e5-4174-a5d2-d7ad88e656f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training with 100.0% of data:\n",
            "Balanced accuracy for 2 degree: 0.5498\n",
            "Balanced accuracy for 3 degree: 0.5658\n",
            "Balanced accuracy for 4 degree: 0.5636\n",
            "Balanced accuracy for 5 degree: 0.5281\n",
            "Balanced accuracy for 6 degree: 0.4913\n",
            "Balanced accuracy for auto as gamma value: 0.6141\n",
            "Balanced accuracy for scale as gamma value: 0.6085\n",
            "Total time for 100.0% of data: 35m 46.4s\n",
            "\n",
            "Training with 75.0% of data:\n",
            "Balanced accuracy for 2 degree: 0.5417\n",
            "Balanced accuracy for 3 degree: 0.5591\n",
            "Balanced accuracy for 4 degree: 0.5518\n",
            "Balanced accuracy for 5 degree: 0.5135\n",
            "Balanced accuracy for 6 degree: 0.4754\n",
            "Balanced accuracy for auto as gamma value: 0.5980\n",
            "Balanced accuracy for scale as gamma value: 0.5952\n",
            "Total time for 75.0% of data: 18m 0.7s\n",
            "\n",
            "Training with 50.0% of data:\n",
            "Balanced accuracy for 2 degree: 0.5384\n",
            "Balanced accuracy for 3 degree: 0.5338\n",
            "Balanced accuracy for 4 degree: 0.5345\n",
            "Balanced accuracy for 5 degree: 0.4900\n",
            "Balanced accuracy for 6 degree: 0.4541\n",
            "Balanced accuracy for auto as gamma value: 0.5818\n",
            "Balanced accuracy for scale as gamma value: 0.5766\n",
            "Total time for 50.0% of data: 8m 1.3s\n",
            "\n",
            "Training with 25.0% of data:\n",
            "Balanced accuracy for 2 degree: 0.5159\n",
            "Balanced accuracy for 3 degree: 0.4996\n",
            "Balanced accuracy for 4 degree: 0.5036\n",
            "Balanced accuracy for 5 degree: 0.4662\n",
            "Balanced accuracy for 6 degree: 0.4403\n",
            "Balanced accuracy for auto as gamma value: 0.5549\n",
            "Balanced accuracy for scale as gamma value: 0.5511\n",
            "Total time for 25.0% of data: 2m 26.0s\n",
            "\n",
            "Data %          Avg Accuracy         Acc Diff             Time (s)             % of Baseline Time  \n",
            "100.0%          0.5602               0.0000               2146.4               100.0               %\n",
            "75.0%           0.5478               -0.0124              1080.7               50.3                %\n",
            "50.0%           0.5299               -0.0303              481.3                22.4                %\n",
            "25.0%           0.5045               -0.0556              146.0                6.8                 %\n"
          ]
        }
      ],
      "source": [
        "percent_of_training_data = [1.0, 0.75, .5, .25]\n",
        "results_31_pca = defaultdict(dict)\n",
        "total_time_per_percentage = []\n",
        "\n",
        "pca = PCA(n_components=31)\n",
        "X_train_pca = pca.fit_transform(X_train_full)\n",
        "X_val_pca = pca.transform(X_val)\n",
        "\n",
        "for percentage in percent_of_training_data:\n",
        "    print(f\"\\nTraining with {percentage * 100}% of data:\")\n",
        "    percentage_start_time = time.time()\n",
        "\n",
        "    if percentage < 1.0:\n",
        "        X_train_subset, X_discard, y_train_subset, y_discard = train_test_split(\n",
        "            X_train_pca, y_train_full, test_size=1-percentage, random_state=5, stratify=y_train_full)\n",
        "    else:\n",
        "        X_train_subset = X_train_pca\n",
        "        y_train_subset = y_train_full\n",
        "\n",
        "    poly_results = defaultdict(tuple)\n",
        "\n",
        "    for degree in range(2, 7):\n",
        "        svc_poly = svm.SVC(kernel='poly', degree=degree, C=1.0, coef0=0.0, class_weight='balanced')\n",
        "        svc_poly.fit(X_train_subset, y_train_subset)\n",
        "        y_pred_poly = svc_poly.predict(X_val_pca)\n",
        "        balanced_accuracy = balanced_accuracy_score(y_val, y_pred_poly)\n",
        "        poly_results[degree] = balanced_accuracy\n",
        "        print(f\"Balanced accuracy for {degree} degree: {balanced_accuracy:.4f}\")\n",
        "\n",
        "    rbf_results = defaultdict(tuple)\n",
        "    gamma_values = [\"auto\", \"scale\"]\n",
        "    for gamma in gamma_values:\n",
        "        svc_rbf = svm.SVC(kernel='rbf', C=1.0, gamma=gamma, class_weight='balanced')\n",
        "        svc_rbf.fit(X_train_subset, y_train_subset)\n",
        "        y_pred_rbf = svc_rbf.predict(X_val_pca)\n",
        "        balanced_accuracy = balanced_accuracy_score(y_val, y_pred_rbf)\n",
        "        rbf_results[gamma] = balanced_accuracy\n",
        "        print(f\"Balanced accuracy for {gamma} as gamma value: {balanced_accuracy:.4f}\")\n",
        "\n",
        "    results_31_pca[percentage] = {'poly': poly_results, 'rbf': rbf_results}\n",
        "\n",
        "    elapsed_time = time.time() - percentage_start_time\n",
        "    total_time_per_percentage.append(elapsed_time)\n",
        "    minutes, seconds = divmod(elapsed_time, 60)\n",
        "    print(f\"Total time for {percentage * 100}% of data: {int(minutes)}m {seconds:.1f}s\")\n",
        "\n",
        "\n",
        "\n",
        "baseline_info = None\n",
        "\n",
        "#Creation of comparison table below, very similar to PCA table farther above\n",
        "print()\n",
        "print(\"{:<15} {:<20} {:<20} {:<20} {:<20}\".format('Data %', 'Avg Accuracy', 'Acc Diff', 'Time (s)', '% of Baseline Time'))\n",
        "for i, percentage in enumerate(percent_of_training_data):\n",
        "    accuracies = [acc for kernel_results in results_31_pca[percentage].values() for acc in kernel_results.values()]\n",
        "    avg_accuracy = np.mean(accuracies)\n",
        "    time_for_percentage = total_time_per_percentage[i]\n",
        "\n",
        "    if percentage == 1.0:\n",
        "        accuracy_diff = 0\n",
        "        time_percentage = 100\n",
        "        baseline_info = (avg_accuracy, time_for_percentage)\n",
        "    else:\n",
        "        full_data_avg_accuracy = baseline_info[0]\n",
        "        accuracy_diff = avg_accuracy - full_data_avg_accuracy\n",
        "        time_percentage = (time_for_percentage / baseline_info[1]) * 100\n",
        "\n",
        "    print(\"{:<15} {:<20.4f} {:<20.4f} {:<20.1f} {:<20.1f}%\".format(\n",
        "        f\"{percentage * 100}%\",\n",
        "        avg_accuracy,\n",
        "        accuracy_diff,\n",
        "        time_for_percentage,\n",
        "        time_percentage\n",
        "    ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s0ab0k_CVuw"
      },
      "source": [
        "While these numbers above are not quite the same ones we were working with on a local laptop environment, they still hold up for demonstrating the justification for our next decision. As a reminder, the original full dataset (no PCA) had an average accuracy of 0.6023 and required 2253.8 s to finish training (Colab run, not laptop). With these numbers in mind, we chose to use 50% of the training data with 31 PCs as the future data configuration for further experimentation. This results in a loss of 7.24% accuracy but it allows us to experiment with different hyperparameters using only ~21.4% of the time we otherwise would have needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTtMqE5SFtm3"
      },
      "source": [
        "Below this is a cell with code to calculate the effect on accuracy that different numbers of stratified kfolds have and also the amount of time it takes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QufSQWg9G46k",
        "outputId": "bb3c1320-ee0f-4d74-9289-d2abf4f4ed8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For 3 folds, elapsed time: 4m 50s\n",
            "Kernel Type: poly\n",
            "Parameter: 2, Balanced Accuracy: 0.5408\n",
            "Parameter: 3, Balanced Accuracy: 0.5371\n",
            "Parameter: 4, Balanced Accuracy: 0.5268\n",
            "Kernel Type: rbf\n",
            "Parameter: auto, Balanced Accuracy: 0.5859\n",
            "Parameter: scale, Balanced Accuracy: 0.5825\n",
            "For 5 folds, elapsed time: 10m 30s\n",
            "Kernel Type: poly\n",
            "Parameter: 2, Balanced Accuracy: 0.5456\n",
            "Parameter: 3, Balanced Accuracy: 0.5403\n",
            "Parameter: 4, Balanced Accuracy: 0.5411\n",
            "Kernel Type: rbf\n",
            "Parameter: auto, Balanced Accuracy: 0.5920\n",
            "Parameter: scale, Balanced Accuracy: 0.5846\n",
            "For 10 folds, elapsed time: 25m 16s\n",
            "Kernel Type: poly\n",
            "Parameter: 2, Balanced Accuracy: 0.5525\n",
            "Parameter: 3, Balanced Accuracy: 0.5476\n",
            "Parameter: 4, Balanced Accuracy: 0.5465\n",
            "Kernel Type: rbf\n",
            "Parameter: auto, Balanced Accuracy: 0.6003\n",
            "Parameter: scale, Balanced Accuracy: 0.5921\n"
          ]
        }
      ],
      "source": [
        "X_train_kfold, X_discard, y_train_kfold, y_discard = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=0.5, random_state=5, stratify=y_train_full)\n",
        "\n",
        "pca = PCA(n_components=31)\n",
        "X_train_pca = pca.fit_transform(X_train_kfold)\n",
        "\n",
        "results_kfold = defaultdict(lambda: defaultdict(list))\n",
        "elapsed_times = []\n",
        "folds = [3,5,10]\n",
        "\n",
        "for fold_num in folds:\n",
        "    start_time = time.time()\n",
        "    skf = StratifiedKFold(n_splits=fold_num, shuffle=True, random_state=5)\n",
        "    for degree in range(2, 5):\n",
        "        accuracies = []\n",
        "        for train_index, test_index in skf.split(X_train_pca, y_train_kfold):\n",
        "            X_train_fold = X_train_pca[train_index]\n",
        "            X_test_fold = X_train_pca[test_index]\n",
        "            y_train_fold = y_train_kfold[train_index]\n",
        "            y_test_fold = y_train_kfold[test_index]\n",
        "\n",
        "            svc_poly = svm.SVC(kernel='poly', degree=degree, C=1.0, coef0=0, class_weight='balanced')\n",
        "            svc_poly.fit(X_train_fold, y_train_fold)\n",
        "            y_pred_poly = svc_poly.predict(X_test_fold)\n",
        "            accuracy = balanced_accuracy_score(y_test_fold, y_pred_poly)\n",
        "            accuracies.append(accuracy)\n",
        "\n",
        "        results_kfold[fold_num]['poly'].append((degree, np.mean(accuracies)))\n",
        "\n",
        "    gamma_values = [\"auto\", \"scale\"]\n",
        "    for gamma in gamma_values:\n",
        "        accuracies = []\n",
        "        for train_index, test_index in skf.split(X_train_pca, y_train_kfold):\n",
        "            X_train_fold = X_train_pca[train_index]\n",
        "            X_test_fold = X_train_pca[test_index]\n",
        "            y_train_fold = y_train_kfold[train_index]\n",
        "            y_test_fold = y_train_kfold[test_index]\n",
        "\n",
        "            svc_rbf = svm.SVC(kernel='rbf', C=1.0, gamma=gamma, class_weight='balanced')\n",
        "            svc_rbf.fit(X_train_fold, y_train_fold)\n",
        "            y_pred_rbf = svc_rbf.predict(X_test_fold)\n",
        "            accuracy = balanced_accuracy_score(y_test_fold, y_pred_rbf)\n",
        "            accuracies.append(accuracy)\n",
        "\n",
        "        results_kfold[fold_num]['rbf'].append((gamma, np.mean(accuracies)))\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    elapsed_times.append(elapsed_time)\n",
        "    minutes, seconds = divmod(elapsed_time, 60)\n",
        "    print(f\"For {fold_num} folds, elapsed time: {int(minutes)}m {int(seconds)}s\")\n",
        "    for kernel_type, results in results_kfold[fold_num].items():\n",
        "        print(f\"Kernel Type: {kernel_type}\")\n",
        "        for param, acc in results:\n",
        "            print(f\"Parameter: {param}, Balanced Accuracy: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gisLUObfIMI5"
      },
      "source": [
        "For the 5 models we are continuing with (poly degrees 2, 3, 4 and rbf with gamma=['auto', 'scale']), the average accuracy from the no kfold section above this one for 50% data, 31 PCs was 0.553 (234 seconds - note, this number comes from unshown test where poly degrees 5 and 6 not trained so number is comparable to those below). Using a stratified kfold, we achieved the following average accuracies: 3 folds: 0.5545 (290 seconds); 5 folds: 0.5607 (630 seconds); 10 folds: 0.5678 (1516 seconds). This translates to: 3 folds: ~24% time increase for an accuracy increase of only 0.0015; 5 folds: ~270% more time for 0.0077; and 10 folds: ~650% more time for 0.0148.\n",
        "\n",
        "We acknowledge that using a kfold value of 3 wouldn't have hurt search times too horribly and that it could lead to a more robust model but after all the time spent fumbling around with the plain accuracy experimentation, time was a little bit tighter near the end as finals loomed near. Lack of time combined with the fact that, again, predicting the outcome of a Connect 4 game is fairly low stakes, missing out on these tiny accuracy gains seemed like an acceptable sacrifice to speed up the hyperparameter search.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Dj_P5NdOCB3"
      },
      "source": [
        "With the decision above to cut the time needed for kfold cross validation, we started searching for optimal hyperparameters using ParameterGrids below. We begin with our search through various poly hyperparameter configurations below. From here on, we make heavy use of saving configurations and their performance in json files as there was a painful process of discovery having things run overnight just to find that, although the majority was processed, the remaining models were taking far too long and the process had to be stopped thus resulting in quite a few large losses of time in the early experimentation phase. The code in the cell below is what was used to generate the data we are about to share but, given the time it took to process the info in the first place and the time/connection inconsistency on Colab, we will use another cell below the following cell to load previously made jsons on the local laptop environment and discuss the results further there. The cell below has been run with 1/30th the data on Colab for the saking of demonstrating functionality. The code to print out the results in order is a few cells down."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFKjhgzsLgn2",
        "outputId": "0fb492cf-f4a3-494f-8cbf-eb400e422807"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing parameters: {'C': 0.1, 'class_weight': 'balanced', 'coef0': 0.0, 'degree': 2, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.7s\n",
            "Done with 1 of 48. We are (very) approximately 2.08% done\n",
            "Testing parameters: {'C': 0.1, 'class_weight': 'balanced', 'coef0': 0.0, 'degree': 3, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.6s\n",
            "Done with 2 of 48. We are (very) approximately 4.17% done\n",
            "Testing parameters: {'C': 0.1, 'class_weight': 'balanced', 'coef0': 0.0, 'degree': 4, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.6s\n",
            "Done with 3 of 48. We are (very) approximately 6.25% done\n",
            "Testing parameters: {'C': 0.1, 'class_weight': 'balanced', 'coef0': 1.0, 'degree': 2, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.6s\n",
            "Done with 4 of 48. We are (very) approximately 8.33% done\n",
            "Testing parameters: {'C': 0.1, 'class_weight': 'balanced', 'coef0': 1.0, 'degree': 3, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.6s\n",
            "Done with 5 of 48. We are (very) approximately 10.42% done\n",
            "Testing parameters: {'C': 0.1, 'class_weight': 'balanced', 'coef0': 1.0, 'degree': 4, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.6s\n",
            "Done with 6 of 48. We are (very) approximately 12.50% done\n",
            "Testing parameters: {'C': 0.1, 'class_weight': 'balanced', 'coef0': 3.0, 'degree': 2, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.6s\n",
            "Done with 7 of 48. We are (very) approximately 14.58% done\n",
            "Testing parameters: {'C': 0.1, 'class_weight': 'balanced', 'coef0': 3.0, 'degree': 3, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.5s\n",
            "Done with 8 of 48. We are (very) approximately 16.67% done\n",
            "Testing parameters: {'C': 0.1, 'class_weight': 'balanced', 'coef0': 3.0, 'degree': 4, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.6s\n",
            "Done with 9 of 48. We are (very) approximately 18.75% done\n",
            "Testing parameters: {'C': 0.1, 'class_weight': 'balanced', 'coef0': 10.0, 'degree': 2, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.6s\n",
            "Done with 10 of 48. We are (very) approximately 20.83% done\n",
            "Testing parameters: {'C': 0.1, 'class_weight': 'balanced', 'coef0': 10.0, 'degree': 3, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.6s\n",
            "Done with 11 of 48. We are (very) approximately 22.92% done\n",
            "Testing parameters: {'C': 0.1, 'class_weight': 'balanced', 'coef0': 10.0, 'degree': 4, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 1.0s\n",
            "Done with 12 of 48. We are (very) approximately 25.00% done\n",
            "Testing parameters: {'C': 1, 'class_weight': 'balanced', 'coef0': 0.0, 'degree': 2, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.6s\n",
            "Done with 13 of 48. We are (very) approximately 27.08% done\n",
            "Testing parameters: {'C': 1, 'class_weight': 'balanced', 'coef0': 0.0, 'degree': 3, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.6s\n",
            "Done with 14 of 48. We are (very) approximately 29.17% done\n",
            "Testing parameters: {'C': 1, 'class_weight': 'balanced', 'coef0': 0.0, 'degree': 4, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.6s\n",
            "Done with 15 of 48. We are (very) approximately 31.25% done\n",
            "Testing parameters: {'C': 1, 'class_weight': 'balanced', 'coef0': 1.0, 'degree': 2, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.6s\n",
            "Done with 16 of 48. We are (very) approximately 33.33% done\n",
            "Testing parameters: {'C': 1, 'class_weight': 'balanced', 'coef0': 1.0, 'degree': 3, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.5s\n",
            "Done with 17 of 48. We are (very) approximately 35.42% done\n",
            "Testing parameters: {'C': 1, 'class_weight': 'balanced', 'coef0': 1.0, 'degree': 4, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.5s\n",
            "Done with 18 of 48. We are (very) approximately 37.50% done\n",
            "Testing parameters: {'C': 1, 'class_weight': 'balanced', 'coef0': 3.0, 'degree': 2, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.6s\n",
            "Done with 19 of 48. We are (very) approximately 39.58% done\n",
            "Testing parameters: {'C': 1, 'class_weight': 'balanced', 'coef0': 3.0, 'degree': 3, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.6s\n",
            "Done with 20 of 48. We are (very) approximately 41.67% done\n",
            "Testing parameters: {'C': 1, 'class_weight': 'balanced', 'coef0': 3.0, 'degree': 4, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.7s\n",
            "Done with 21 of 48. We are (very) approximately 43.75% done\n",
            "Testing parameters: {'C': 1, 'class_weight': 'balanced', 'coef0': 10.0, 'degree': 2, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.6s\n",
            "Done with 22 of 48. We are (very) approximately 45.83% done\n",
            "Testing parameters: {'C': 1, 'class_weight': 'balanced', 'coef0': 10.0, 'degree': 3, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 1.0s\n",
            "Done with 23 of 48. We are (very) approximately 47.92% done\n",
            "Testing parameters: {'C': 1, 'class_weight': 'balanced', 'coef0': 10.0, 'degree': 4, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 2.8s\n",
            "Done with 24 of 48. We are (very) approximately 50.00% done\n",
            "Testing parameters: {'C': 10, 'class_weight': 'balanced', 'coef0': 0.0, 'degree': 2, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.5s\n",
            "Done with 25 of 48. We are (very) approximately 52.08% done\n",
            "Testing parameters: {'C': 10, 'class_weight': 'balanced', 'coef0': 0.0, 'degree': 3, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.5s\n",
            "Done with 26 of 48. We are (very) approximately 54.17% done\n",
            "Testing parameters: {'C': 10, 'class_weight': 'balanced', 'coef0': 0.0, 'degree': 4, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.6s\n",
            "Done with 27 of 48. We are (very) approximately 56.25% done\n",
            "Testing parameters: {'C': 10, 'class_weight': 'balanced', 'coef0': 1.0, 'degree': 2, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.6s\n",
            "Done with 28 of 48. We are (very) approximately 58.33% done\n",
            "Testing parameters: {'C': 10, 'class_weight': 'balanced', 'coef0': 1.0, 'degree': 3, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.5s\n",
            "Done with 29 of 48. We are (very) approximately 60.42% done\n",
            "Testing parameters: {'C': 10, 'class_weight': 'balanced', 'coef0': 1.0, 'degree': 4, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.5s\n",
            "Done with 30 of 48. We are (very) approximately 62.50% done\n",
            "Testing parameters: {'C': 10, 'class_weight': 'balanced', 'coef0': 3.0, 'degree': 2, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.6s\n",
            "Done with 31 of 48. We are (very) approximately 64.58% done\n",
            "Testing parameters: {'C': 10, 'class_weight': 'balanced', 'coef0': 3.0, 'degree': 3, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.8s\n",
            "Done with 32 of 48. We are (very) approximately 66.67% done\n",
            "Testing parameters: {'C': 10, 'class_weight': 'balanced', 'coef0': 3.0, 'degree': 4, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 1.0s\n",
            "Done with 33 of 48. We are (very) approximately 68.75% done\n",
            "Testing parameters: {'C': 10, 'class_weight': 'balanced', 'coef0': 10.0, 'degree': 2, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.9s\n",
            "Done with 34 of 48. We are (very) approximately 70.83% done\n",
            "Testing parameters: {'C': 10, 'class_weight': 'balanced', 'coef0': 10.0, 'degree': 3, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 2.9s\n",
            "Done with 35 of 48. We are (very) approximately 72.92% done\n",
            "Testing parameters: {'C': 10, 'class_weight': 'balanced', 'coef0': 10.0, 'degree': 4, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 4.3s\n",
            "Done with 36 of 48. We are (very) approximately 75.00% done\n",
            "Testing parameters: {'C': 100, 'class_weight': 'balanced', 'coef0': 0.0, 'degree': 2, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.7s\n",
            "Done with 37 of 48. We are (very) approximately 77.08% done\n",
            "Testing parameters: {'C': 100, 'class_weight': 'balanced', 'coef0': 0.0, 'degree': 3, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.5s\n",
            "Done with 38 of 48. We are (very) approximately 79.17% done\n",
            "Testing parameters: {'C': 100, 'class_weight': 'balanced', 'coef0': 0.0, 'degree': 4, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.5s\n",
            "Done with 39 of 48. We are (very) approximately 81.25% done\n",
            "Testing parameters: {'C': 100, 'class_weight': 'balanced', 'coef0': 1.0, 'degree': 2, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.9s\n",
            "Done with 40 of 48. We are (very) approximately 83.33% done\n",
            "Testing parameters: {'C': 100, 'class_weight': 'balanced', 'coef0': 1.0, 'degree': 3, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.7s\n",
            "Done with 41 of 48. We are (very) approximately 85.42% done\n",
            "Testing parameters: {'C': 100, 'class_weight': 'balanced', 'coef0': 1.0, 'degree': 4, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 0.6s\n",
            "Done with 42 of 48. We are (very) approximately 87.50% done\n",
            "Testing parameters: {'C': 100, 'class_weight': 'balanced', 'coef0': 3.0, 'degree': 2, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 1.6s\n",
            "Done with 43 of 48. We are (very) approximately 89.58% done\n",
            "Testing parameters: {'C': 100, 'class_weight': 'balanced', 'coef0': 3.0, 'degree': 3, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 1.6s\n",
            "Done with 44 of 48. We are (very) approximately 91.67% done\n",
            "Testing parameters: {'C': 100, 'class_weight': 'balanced', 'coef0': 3.0, 'degree': 4, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 1.1s\n",
            "Done with 45 of 48. We are (very) approximately 93.75% done\n",
            "Testing parameters: {'C': 100, 'class_weight': 'balanced', 'coef0': 10.0, 'degree': 2, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 4.6s\n",
            "Done with 46 of 48. We are (very) approximately 95.83% done\n",
            "Testing parameters: {'C': 100, 'class_weight': 'balanced', 'coef0': 10.0, 'degree': 3, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 7.7s\n",
            "Done with 47 of 48. We are (very) approximately 97.92% done\n",
            "Testing parameters: {'C': 100, 'class_weight': 'balanced', 'coef0': 10.0, 'degree': 4, 'kernel': 'poly'}\n",
            "Elapsed time: 0m 4.2s\n",
            "Done with 48 of 48. We are (very) approximately 100.00% done\n"
          ]
        }
      ],
      "source": [
        "# Can adjust the test size to configure how much of our 70% training data is thrown away\n",
        "# for the sake of testing this faster with less data.\n",
        "X_train, X_discard, y_train, y_discard = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=29/30, random_state=5, stratify=y_train_full)\n",
        "\n",
        "pca = PCA(n_components=31)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_val_pca = pca.transform(X_val)\n",
        "\n",
        "# Below are the variations of grids we experimented, more discussion beyond this cell.\n",
        "#1/30th grid\n",
        "poly_param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'class_weight': ['balanced'],\n",
        "    'coef0': [0.0, 1.0, 3.0, 10.0],\n",
        "    'degree': [2, 3, 4],\n",
        "    'kernel': ['poly']\n",
        "}\n",
        "\n",
        "# #1/20th grid\n",
        "# poly_param_grid = {\n",
        "#     'C': [1, 10, 100],\n",
        "#     'class_weight': ['balanced'],\n",
        "#     'coef0': [1.0, 3.0, 10.0],\n",
        "#     'degree': [2, 3, 4],\n",
        "#     'kernel': ['poly']\n",
        "# }\n",
        "\n",
        "# #1/10th grid\n",
        "# poly_param_grid = {\n",
        "#     'C': [1, 10, 100],\n",
        "#     'class_weight': ['balanced'],\n",
        "#     'coef0': [1.0, 3.0, 10.0],\n",
        "#     'degree': [3, 4],\n",
        "#     'kernel': ['poly']\n",
        "# }\n",
        "\n",
        "# #1/2 grid\n",
        "# poly_param_grid = {\n",
        "#     'C': [1, 10, 50],\n",
        "#     'class_weight': ['balanced'],\n",
        "#     'coef0': [1.0, 3.0, 10.0],\n",
        "#     'degree': [3, 4],\n",
        "#     'kernel': ['poly']\n",
        "# }\n",
        "\n",
        "poly_results = []\n",
        "runCount = 0\n",
        "save_path = 'svm_poly_results_throwaway.json' #Rename this based on percentage of data used\n",
        "total_permutations = len(list(ParameterGrid(poly_param_grid)))\n",
        "\n",
        "for params in ParameterGrid(poly_param_grid):\n",
        "    print(f\"Testing parameters: {params}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    model = svm.SVC(**params)\n",
        "    model.fit(X_train_pca, y_train)\n",
        "    y_pred = model.predict(X_val_pca)\n",
        "\n",
        "    balanced_accuracy = balanced_accuracy_score(y_val, y_pred)\n",
        "    report = classification_report(y_val, y_pred, output_dict=True, zero_division=1)\n",
        "    poly_results.append({\n",
        "        'params': params,\n",
        "        'balanced_accuracy': balanced_accuracy,\n",
        "        'report': report\n",
        "    })\n",
        "\n",
        "    with open(save_path, 'w') as f:\n",
        "        json.dump(poly_results, f, indent=4)\n",
        "    elapsed_time = time.time() - start_time\n",
        "    minutes, seconds = divmod(elapsed_time, 60)\n",
        "    print(f\"Elapsed time: {int(minutes)}m {seconds:.1f}s\")\n",
        "\n",
        "    runCount += 1\n",
        "    runCountPercent = (runCount / total_permutations) * 100\n",
        "    print(f\"Done with {runCount} of {total_permutations}. We are (very) approximately {runCountPercent:.2f}% done\")\n",
        "\n",
        "poly_results.sort(key=lambda x: x['balanced_accuracy'], reverse=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_Bys3toYaij"
      },
      "source": [
        "Despite all the testing to find what we thought would be a reasonable amount of data to work with for the ParameterGrid (50% data, 31 PCs), we were unfortunately blindsided by some wildly time intensive models that caused us to have to abandon some early runs. In the early plain accuracy runs, 6 and 7 degree poly kernels took an absurd amount of time and we also found that, for poly models, a C value of 100 or higher and coef0 values of 25 or higher led to extremely long training times even at 1/10th our full dataset. This lead to a more iterative exploration with smaller datasets so that when we finally spent the large amount of time necessary for a larger portion of the data, that effort would be focused on a range of parameters that would be more likely to be successful compared to the wider, and blinder, net of hyperparameters being cast at the beginning of experimentation. We did continue to use 31 PCs throughout this part of the process.\n",
        "\n",
        "Once the code above was done training/assessing the models, the code below would be used to evaluate if certain parameters were worth continuing to explore. In the cell above, you can see the original ParameterGrid that we began exploring at 1/30th the full dataset. Using the code below, we can assess how many times a parameter landed in the top 50% of solutions. Here is the full printout for 1/30th the data:\n",
        "\n",
        "Parameter: C  \n",
        "C=0.1: 25.00% of permutations in top 50%  \n",
        "C=1: 50.00% of permutations in top 50%  \n",
        "C=10: 75.00% of permutations in top 50%  \n",
        "C=100: 58.33% of permutations in top 50%  \n",
        "\n",
        "Parameter: coef0  \n",
        "coef0=0.0: 0.00% of permutations in top 50%  \n",
        "coef0=1.0: 50.00% of permutations in top 50%  \n",
        "coef0=3.0: 75.00% of permutations in top 50%  \n",
        "coef0=10.0: 83.33% of permutations in top 50%  \n",
        "\n",
        "Parameter: degree  \n",
        "degree=2: 37.50% of permutations in top 50%  \n",
        "degree=3: 56.25% of permutations in top 50%  \n",
        "degree=4: 62.50% of permutations in top 50%  \n",
        "\n",
        "In the beginning ParameterGrid, each C value can have a total of 12 different permutations for any given C value. What the results above are saying for C=0.1, for example, is that only 3 out of the 12 combinations (25%) were good enough to land them in the top 50% of parameter configurations sorted by accuracy. The results above were enough for us to justify removing C=0.1 and coef0=0.0. We removed these from the ParameterGrid and continued exploring larger portions of the data. If you wish to view all of the info for each amount of data, feel free to change the json file name in the code below. For brevity, we will only show the worst performing parameters for the rest of this discussion to justify why we made the decisions we did.\n",
        "\n",
        "1/20th data:  \n",
        "degree=2: 11.11% of permutations in top 50%\n",
        "2nd degree removed from grid.\n",
        "All other parameters: 44.44% or more in top 50%.\n",
        "\n",
        "1/10th data:  \n",
        "C=1: 33.33% of permutations in top 50% was the lowest value. Not quite low enough for us to consider elimination so we looked in top 33% of solutions and found that C=100 drops from 50% in the top 50% to just 16.67% in the top 33%. This, to us, suggested a higher C value could potentially be useful but perhaps C=100 is overshooting it so we changed that 100 to 50 for the final 1/2 data run since that would put it a bit closer to our more successful numbers.\n",
        "\n",
        "We can see the final experimentation outcome with 1/2 the data for the poly kernels printed out by the code cell beyond the one below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNfpsETaLf75",
        "outputId": "256a17ea-a2a4-4b03-aa83-6e16c402b9ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Parameter: C\n",
            "C=0.1: 25.00% of permutations in top 50%\n",
            "C=1: 50.00% of permutations in top 50%\n",
            "C=10: 75.00% of permutations in top 50%\n",
            "C=100: 58.33% of permutations in top 50%\n",
            "\n",
            "Parameter: coef0\n",
            "coef0=0.0: 0.00% of permutations in top 50%\n",
            "coef0=1.0: 50.00% of permutations in top 50%\n",
            "coef0=3.0: 75.00% of permutations in top 50%\n",
            "coef0=10.0: 83.33% of permutations in top 50%\n",
            "\n",
            "Parameter: degree\n",
            "degree=2: 37.50% of permutations in top 50%\n",
            "degree=3: 56.25% of permutations in top 50%\n",
            "degree=4: 62.50% of permutations in top 50%\n"
          ]
        }
      ],
      "source": [
        "# folder_path = '/content/drive/My Drive/Experimentation Results/'\n",
        "# file_path = folder_path + 'svm_poly_results_half.json'\n",
        "# with open(file_path, 'r') as file:\n",
        "#     poly_results = json.load(file)\n",
        "# The above is for the sake of getting some useful output saved to this document\n",
        "# by putting the documents in my google drive.\n",
        "# REMOVE BEFORE TURNING IN AS IT WON'T WORK FOR OTHERS\n",
        "# Json loading below should work fine provided we put the jsons in the\n",
        "# correct folder with the notebook before turning in. Must test.\n",
        "\n",
        "\n",
        "# Please note that you will need to uncomment the poly_param_grid above that corresponds to the\n",
        "# json file you are loading if you want the # Calculate percentage section below to work as intended.\n",
        "with open('svm_poly_results_throwaway.json', 'r') as f:\n",
        "    poly_results = json.load(f)\n",
        "\n",
        "poly_results.sort(key=lambda x: x['balanced_accuracy'], reverse=True)\n",
        "\n",
        "total_counts = defaultdict(int)\n",
        "top_counts = defaultdict(int)\n",
        "\n",
        "# Determine the counts of each parameter in the top X% of configurations by balanced accuracy\n",
        "top_indices_stop_index = int(len(poly_results) * 0.5)\n",
        "\n",
        "# Count instances of parameter\n",
        "for i, result in enumerate(poly_results):\n",
        "    for param, value in result['params'].items():\n",
        "        if param in ['kernel', 'class_weight']:\n",
        "            continue\n",
        "        param_value_key = f'{param}_{value}'\n",
        "        total_counts[param_value_key] += 1\n",
        "        if i <= top_indices_stop_index:\n",
        "            top_counts[param_value_key] += 1\n",
        "\n",
        "# Calculate percentage\n",
        "for param in ['C', 'coef0', 'degree']:\n",
        "    print(f\"\\nParameter: {param}\")\n",
        "    for value in poly_param_grid[param]:\n",
        "        param_value_key = f'{param}_{value}'\n",
        "        if total_counts[param_value_key] > 0:\n",
        "            percentage_in_top_third = (top_counts[param_value_key] / total_counts[param_value_key]) * 100\n",
        "            print(f\"{param}={value}: {percentage_in_top_third:.2f}% of permutations in top 50%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zvutt0tdbKF"
      },
      "source": [
        "The cell below can be used to print the final sorted results of the best parameters found in the grid search above. We have run the cell below with the final results of the 50% data run so you can see the top contenders for the poly kernels. There is one permutation missing (C=50, coef0=10, degree=4) below unfortunately. This was one of those instances where the model was taking an unexpectedly very long time to train and the laptop needed to be shut off before it could finish. For the sake of time, we had to move on without the knowledge of accuracy for that particular permutation.\n",
        "\n",
        "Beyond the cell below, we are going to repeat the same process except for the rbf models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2U3D_VKdbeY",
        "outputId": "063fdc43-e066-4864-ea75-f1079ce63347"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best parameters: {'C': 50, 'class_weight': 'balanced', 'coef0': 3.0, 'degree': 4, 'kernel': 'poly'}\n",
            "Best Combination Balanced Accuracy: 0.639\n",
            "The #2 best option\n",
            "{'C': 1, 'class_weight': 'balanced', 'coef0': 10.0, 'degree': 4, 'kernel': 'poly'}\n",
            "Balanced Acc: 0.639\n",
            "The #3 best option\n",
            "{'C': 10, 'class_weight': 'balanced', 'coef0': 10.0, 'degree': 3, 'kernel': 'poly'}\n",
            "Balanced Acc: 0.638\n",
            "The #4 best option\n",
            "{'C': 10, 'class_weight': 'balanced', 'coef0': 10.0, 'degree': 4, 'kernel': 'poly'}\n",
            "Balanced Acc: 0.637\n",
            "The #5 best option\n",
            "{'C': 1, 'class_weight': 'balanced', 'coef0': 3.0, 'degree': 4, 'kernel': 'poly'}\n",
            "Balanced Acc: 0.637\n",
            "The #6 best option\n",
            "{'C': 10, 'class_weight': 'balanced', 'coef0': 3.0, 'degree': 3, 'kernel': 'poly'}\n",
            "Balanced Acc: 0.636\n",
            "The #7 best option\n",
            "{'C': 50, 'class_weight': 'balanced', 'coef0': 3.0, 'degree': 3, 'kernel': 'poly'}\n",
            "Balanced Acc: 0.636\n",
            "The #8 best option\n",
            "{'C': 10, 'class_weight': 'balanced', 'coef0': 3.0, 'degree': 4, 'kernel': 'poly'}\n",
            "Balanced Acc: 0.636\n",
            "The #9 best option\n",
            "{'C': 10, 'class_weight': 'balanced', 'coef0': 1.0, 'degree': 4, 'kernel': 'poly'}\n",
            "Balanced Acc: 0.636\n",
            "The #10 best option\n",
            "{'C': 50, 'class_weight': 'balanced', 'coef0': 1.0, 'degree': 3, 'kernel': 'poly'}\n",
            "Balanced Acc: 0.636\n",
            "The #11 best option\n",
            "{'C': 10, 'class_weight': 'balanced', 'coef0': 1.0, 'degree': 3, 'kernel': 'poly'}\n",
            "Balanced Acc: 0.636\n",
            "The #12 best option\n",
            "{'C': 50, 'class_weight': 'balanced', 'coef0': 1.0, 'degree': 4, 'kernel': 'poly'}\n",
            "Balanced Acc: 0.633\n",
            "The #13 best option\n",
            "{'C': 50, 'class_weight': 'balanced', 'coef0': 10.0, 'degree': 3, 'kernel': 'poly'}\n",
            "Balanced Acc: 0.633\n",
            "The #14 best option\n",
            "{'C': 1, 'class_weight': 'balanced', 'coef0': 1.0, 'degree': 4, 'kernel': 'poly'}\n",
            "Balanced Acc: 0.627\n",
            "The #15 best option\n",
            "{'C': 1, 'class_weight': 'balanced', 'coef0': 10.0, 'degree': 3, 'kernel': 'poly'}\n",
            "Balanced Acc: 0.612\n",
            "The #16 best option\n",
            "{'C': 1, 'class_weight': 'balanced', 'coef0': 3.0, 'degree': 3, 'kernel': 'poly'}\n",
            "Balanced Acc: 0.610\n",
            "The #17 best option\n",
            "{'C': 1, 'class_weight': 'balanced', 'coef0': 1.0, 'degree': 3, 'kernel': 'poly'}\n",
            "Balanced Acc: 0.607\n"
          ]
        }
      ],
      "source": [
        "folder_path = '/content/drive/My Drive/Experimentation Results/'\n",
        "file_path = folder_path + 'svm_poly_results_half.json'\n",
        "with open(file_path, 'r') as file:\n",
        "    poly_results = json.load(file)\n",
        "# The above is for the sake of getting some useful output saved to this document\n",
        "# by putting the documents in my google drive.\n",
        "# REMOVE BEFORE TURNING IN AS IT WON'T WORK FOR OTHERS\n",
        "# Json loading below should work fine provided we put the jsons in the\n",
        "# correct folder with the notebook before turning in. Must test.\n",
        "\n",
        "# with open('svm_poly_results_throwaway.json', 'r') as f:\n",
        "#     poly_results = json.load(f)\n",
        "\n",
        "poly_results.sort(key=lambda x: x['balanced_accuracy'], reverse=True)\n",
        "\n",
        "first_result = True\n",
        "index = 1\n",
        "for result in poly_results:\n",
        "    if first_result:\n",
        "        print(f\"\\nBest parameters: {result['params']}\")\n",
        "        print(f\"Best Combination Balanced Accuracy: {result['balanced_accuracy']:.3f}\")\n",
        "        first_result = False\n",
        "        index += 1\n",
        "    else:\n",
        "        print(f\"The #{index} best option\")\n",
        "        print(result['params'])\n",
        "        print(f\"Balanced Acc: {result['balanced_accuracy']:.3f}\")\n",
        "        index += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1dyxS82r9XY"
      },
      "source": [
        "Below we have the code used to generate our rbf kernel jsons. Further discussion below in similar format as above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR0Qoa86sBx8",
        "outputId": "dfdfe485-56f6-40c3-f927-fe9744ded067"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing parameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Elapsed time: 0m 1s\n",
            "Done with 1 of 20. We are (very) approximately 5.00% done.\n",
            "Testing parameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'}\n",
            "Elapsed time: 0m 1s\n",
            "Done with 2 of 20. We are (very) approximately 10.00% done.\n",
            "Testing parameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "Elapsed time: 0m 1s\n",
            "Done with 3 of 20. We are (very) approximately 15.00% done.\n",
            "Testing parameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "Elapsed time: 0m 1s\n",
            "Done with 4 of 20. We are (very) approximately 20.00% done.\n",
            "Testing parameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "Elapsed time: 0m 1s\n",
            "Done with 5 of 20. We are (very) approximately 25.00% done.\n",
            "Testing parameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Elapsed time: 0m 1s\n",
            "Done with 6 of 20. We are (very) approximately 30.00% done.\n",
            "Testing parameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'}\n",
            "Elapsed time: 0m 1s\n",
            "Done with 7 of 20. We are (very) approximately 35.00% done.\n",
            "Testing parameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "Elapsed time: 0m 1s\n",
            "Done with 8 of 20. We are (very) approximately 40.00% done.\n",
            "Testing parameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "Elapsed time: 0m 1s\n",
            "Done with 9 of 20. We are (very) approximately 45.00% done.\n",
            "Testing parameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "Elapsed time: 0m 1s\n",
            "Done with 10 of 20. We are (very) approximately 50.00% done.\n",
            "Testing parameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Elapsed time: 0m 1s\n",
            "Done with 11 of 20. We are (very) approximately 55.00% done.\n",
            "Testing parameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'}\n",
            "Elapsed time: 0m 1s\n",
            "Done with 12 of 20. We are (very) approximately 60.00% done.\n",
            "Testing parameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "Elapsed time: 0m 1s\n",
            "Done with 13 of 20. We are (very) approximately 65.00% done.\n",
            "Testing parameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "Elapsed time: 0m 1s\n",
            "Done with 14 of 20. We are (very) approximately 70.00% done.\n",
            "Testing parameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "Elapsed time: 0m 1s\n",
            "Done with 15 of 20. We are (very) approximately 75.00% done.\n",
            "Testing parameters: {'C': 100, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Elapsed time: 0m 1s\n",
            "Done with 16 of 20. We are (very) approximately 80.00% done.\n",
            "Testing parameters: {'C': 100, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'}\n",
            "Elapsed time: 0m 1s\n",
            "Done with 17 of 20. We are (very) approximately 85.00% done.\n",
            "Testing parameters: {'C': 100, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "Elapsed time: 0m 1s\n",
            "Done with 18 of 20. We are (very) approximately 90.00% done.\n",
            "Testing parameters: {'C': 100, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "Elapsed time: 0m 1s\n",
            "Done with 19 of 20. We are (very) approximately 95.00% done.\n",
            "Testing parameters: {'C': 100, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "Elapsed time: 0m 1s\n",
            "Done with 20 of 20. We are (very) approximately 100.00% done.\n"
          ]
        }
      ],
      "source": [
        "X_train_pca, X_discard, y_train, y_discard = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=19/20, random_state=5, stratify=y_train_full)\n",
        "\n",
        "pca = PCA(n_components=31)\n",
        "X_train_pca = pca.fit_transform(X_train_pca)\n",
        "X_val_pca = pca.transform(X_val)\n",
        "\n",
        "#1/20th grid\n",
        "rbf_param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': ['scale', 'auto', 0.1, 0.01, 0.001],\n",
        "    'kernel': ['rbf'],\n",
        "    'class_weight': ['balanced']\n",
        "}\n",
        "\n",
        "# #1/10th grid\n",
        "# rbf_param_grid = {\n",
        "#     'C': [1, 10, 100],\n",
        "#     'gamma': ['scale', 'auto', 0.1, 0.01],\n",
        "#     'kernel': ['rbf'],\n",
        "#     'class_weight': ['balanced']\n",
        "# }\n",
        "\n",
        "# #1/2 grid\n",
        "# rbf_param_grid = {\n",
        "#     'C': [10, 100],\n",
        "#     'gamma': ['scale', 'auto', 0.01],\n",
        "#     'kernel': ['rbf'],\n",
        "#     'class_weight': ['balanced']\n",
        "# }\n",
        "\n",
        "rbf_results = []\n",
        "runCount = 0\n",
        "save_path = 'svm_rbf_results_throwaway.json'\n",
        "total_permutations = len(list(ParameterGrid(rbf_param_grid)))\n",
        "\n",
        "for params in ParameterGrid(rbf_param_grid):\n",
        "    print(f\"Testing parameters: {params}\")\n",
        "    start_time = time.time()\n",
        "    model = svm.SVC(**params)\n",
        "    model.fit(X_train_pca, y_train)\n",
        "    y_pred = model.predict(X_val_pca)\n",
        "    balanced_acc = balanced_accuracy_score(y_val, y_pred)\n",
        "    report = classification_report(y_val, y_pred, output_dict=True, zero_division=1)\n",
        "    rbf_results.append({\n",
        "        'params': params,\n",
        "        'balanced_accuracy': balanced_acc,\n",
        "        'report': report\n",
        "    })\n",
        "\n",
        "    with open(save_path, 'w') as f:\n",
        "        json.dump(rbf_results, f, indent=4)\n",
        "    elapsed_time = time.time() - start_time\n",
        "    minutes, seconds = divmod(elapsed_time, 60)\n",
        "    runCount += 1\n",
        "    runCountPercent = (runCount / total_permutations) * 100\n",
        "    print(f\"Elapsed time: {int(minutes)}m {int(seconds)}s\")\n",
        "    print(f\"Done with {runCount} of {total_permutations}. We are (very) approximately {runCountPercent:.2f}% done.\")\n",
        "\n",
        "\n",
        "rbf_results.sort(key=lambda x: x['balanced_accuracy'], reverse=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDXpliDP00CK"
      },
      "source": [
        "The code cell below operates extremely similarly to poly equivalent above so not much to discuss in that regard. Let's take a look at some of the decisions that runs with different amounts of data resulted in.\n",
        "\n",
        "1/20th data:  \n",
        "Both C=0.1 and gamma=0.001 had 0% representation in the top 50% of combinations. Eash choice to remove these parameters.\n",
        "\n",
        "1/10th data:  \n",
        "C=1 had 0% representation in the top 50% and was also removed. Wanted to see if we could justify removing just one more parameter so we narrowed our search to the top 25% of combinations where gamma=0.1 had 0% representation. Removed this parameter as well.\n",
        "\n",
        "We can see the final experimentation outcome with 1/2 the data for the rbf kernels printed out by the code cell beyond the one below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJaDBzl-0ymU",
        "outputId": "99457969-5125-4963-892e-8612e31739b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Parameter: C\n",
            "C=0.1: 0.00% of permutations using this param in top 50%\n",
            "C=1: 60.00% of permutations using this param in top 50%\n",
            "C=10: 80.00% of permutations using this param in top 50%\n",
            "C=100: 80.00% of permutations using this param in top 50%\n",
            "\n",
            "Parameter: gamma\n",
            "gamma=scale: 75.00% of permutations using this param in top 50%\n",
            "gamma=auto: 75.00% of permutations using this param in top 50%\n",
            "gamma=0.1: 75.00% of permutations using this param in top 50%\n",
            "gamma=0.01: 50.00% of permutations using this param in top 50%\n",
            "gamma=0.001: 0.00% of permutations using this param in top 50%\n"
          ]
        }
      ],
      "source": [
        "folder_path = '/content/drive/My Drive/Experimentation Results/'\n",
        "file_path = folder_path + 'svm_rbf_results_1_20th.json'\n",
        "with open(file_path, 'r') as file:\n",
        "    rbf_results = json.load(file)\n",
        "# The above is for the sake of getting some useful output saved to this document\n",
        "# by putting the documents in my google drive.\n",
        "# REMOVE BEFORE TURNING IN AS IT WON'T WORK FOR OTHERS\n",
        "# Json loading below should work fine provided we put the jsons in the\n",
        "# correct folder with the notebook before turning in. Must test.\n",
        "\n",
        "# with open('svm_rbf_results_1_20th.json', 'r') as f:\n",
        "#     rbf_results = json.load(f)\n",
        "\n",
        "rbf_results.sort(key=lambda x: x['balanced_accuracy'], reverse=True)\n",
        "\n",
        "total_counts = defaultdict(int)\n",
        "top_counts = defaultdict(int)\n",
        "\n",
        "# Define the top X% threshold index\n",
        "top_indices_stop_index = int(len(rbf_results) * 0.50)\n",
        "\n",
        "# Count instances of parameter\n",
        "for i, result in enumerate(rbf_results):\n",
        "    for param, value in result['params'].items():\n",
        "        if param == 'kernel':\n",
        "            continue\n",
        "        value_key = f'{param}_{value}'\n",
        "        total_counts[value_key] += 1\n",
        "        if i <= top_indices_stop_index:\n",
        "            top_counts[value_key] += 1\n",
        "\n",
        "# Calculate percentage\n",
        "for param, values in rbf_param_grid.items():\n",
        "    if param == 'kernel' or param == 'class_weight':\n",
        "        continue\n",
        "    print(f\"\\nParameter: {param}\")\n",
        "    for value in values:\n",
        "        value_key = f'{param}_{value}'\n",
        "        if total_counts[value_key] > 0:\n",
        "            percentage = (top_counts[value_key] / total_counts[value_key]) * 100\n",
        "            print(f\"{param}={value}: {percentage:.2f}% of permutations using this param in top 50%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efWolX8e0zFL"
      },
      "source": [
        "Below we have the code to print our ParameterGrid final results for our 50% data experiment for rbf."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2jGlENl01zJ",
        "outputId": "d584dae9-e001-465a-90a0-8916eb3bc00f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best parameters: {'C': 100, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best Combination Balanced Accuracy: 0.641\n",
            "The #2 best option\n",
            "{'C': 100, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'}\n",
            "Balanced Acc: 0.638\n",
            "The #3 best option\n",
            "{'C': 100, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "Balanced Acc: 0.637\n",
            "The #4 best option\n",
            "{'C': 10, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'}\n",
            "Balanced Acc: 0.631\n",
            "The #5 best option\n",
            "{'C': 10, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Balanced Acc: 0.630\n",
            "The #6 best option\n",
            "{'C': 10, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf'}\n",
            "Balanced Acc: 0.597\n"
          ]
        }
      ],
      "source": [
        "folder_path = '/content/drive/My Drive/Experimentation Results/'\n",
        "file_path = folder_path + 'svm_rbf_results_half.json'\n",
        "with open(file_path, 'r') as file:\n",
        "    rbf_results = json.load(file)\n",
        "# The above is for the sake of getting some useful output saved to this document\n",
        "# by putting the documents in my google drive.\n",
        "# REMOVE BEFORE TURNING IN AS IT WON'T WORK FOR OTHERS\n",
        "# Json loading below should work fine provided we put the jsons in the\n",
        "# correct folder with the notebook before turning in. Must test.\n",
        "\n",
        "# with open('svm_rbf_results_1_20th.json', 'r') as f:\n",
        "#     rbf_results = json.load(f)\n",
        "\n",
        "rbf_results.sort(key=lambda x: x['balanced_accuracy'], reverse=True)\n",
        "\n",
        "first_result = True\n",
        "index = 1\n",
        "for result in rbf_results:\n",
        "    if first_result:\n",
        "        print(f\"\\nBest parameters: {result['params']}\")\n",
        "        print(f\"Best Combination Balanced Accuracy: {result['balanced_accuracy']:.3f}\")\n",
        "        first_result = False\n",
        "        index += 1\n",
        "    else:\n",
        "        print(f\"The #{index} best option\")\n",
        "        print(result['params'])\n",
        "        print(f\"Balanced Acc: {result['balanced_accuracy']:.3f}\")\n",
        "        index += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDrzxV7yH05o"
      },
      "source": [
        "While we now definitely had some promising combinations of hyperparameters, we had just done a really fascinating genetic algorithm assignment for another class and wanted to see if we could leverage that kind of structure to help us find further high performing hyperparameter combos. Before we dive into the nitty gritty of that, we wanted to have a better idea of what values \"auto\" and \"scale\" for gamma actually represented for our specific problem so that we could pick some additional similar but alternative values to explore since both of those gamma values typically perform well in general.\n",
        "\n",
        "In the output below, we can see the values for our specific data when using 31 PCs. We already saw 0.01 was a well performing value above and with the information below, we opted to add 0.025 and 0.05 as starting search parameters as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRPf6SZKLhLT",
        "outputId": "779aa916-4f85-4203-a764-24711980cb0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Auto: 0.03225806451612903\n",
            "Scale: [0.00987422 0.01052967 0.01080061 0.01148157 0.01249186 0.01343583\n",
            " 0.01892233 0.01937618 0.02303561 0.02434611 0.02574028 0.02700921\n",
            " 0.03047033 0.03250493 0.03305156 0.03645451 0.04072587 0.04121029\n",
            " 0.0431669  0.04541239 0.04676979 0.04943647 0.05238596 0.05667528\n",
            " 0.05810447 0.05882341 0.06103426 0.06241538 0.06315527 0.06542864\n",
            " 0.06678605]\n",
            "Mean Scale Gamma: 0.037130814195091504\n"
          ]
        }
      ],
      "source": [
        "pca = PCA(n_components=31)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_val_pca = pca.transform(X_val)\n",
        "\n",
        "n_samples_all, n_features_all = X_train_pca.shape\n",
        "auto = 1 / n_features_all\n",
        "print(f\"Auto: {auto}\")\n",
        "scale = 1 / (n_features_all * np.var(X_train_pca, axis=0))\n",
        "print(f\"Scale: {scale}\")\n",
        "mean_scale_gamma = np.mean(scale)\n",
        "print(\"Mean Scale Gamma:\", mean_scale_gamma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpceR6ikLgmg"
      },
      "source": [
        "Below is the genetic algorithm we put together for searching for more fine tuner hyperparameters. It takes an extremely long time to run so we will have some discussion farther below about some of the jsons that resulted from running it with larger datasets. We were able to run rbf kernels at 50% of the population as they trained much faster than the poly kernels which we unfortunately had to limit to 15% of the training data due to time constraints. There was seemed to be quite an exponential increase in time needed to train high C and coef0 poly kernel models. Because of this, for poly kernels, we limited C to a max of 50 and coef0 to 20. Some of the low dataset percentages (like 2%) ended up with rbf models having C=300 to 400 so we limited rbf models to C=150 at max to avoid longer training times and also to avoid possibly trending towards a highly overfitting C value. We experimented quite extensively with various solutions to get the ideal output from this process and we will discuss that below the code below.\n",
        "\n",
        "We think it would be best to just start with a broad overview of what the code below started with and we will talk about all the things that changed after the code. This code generates two populations of hyperparameter combinations based on two parameter grids (rbf and poly) much like the ParameterGrid searches we already did. Each combination represents an individual in the population and each population will maintain the same amount of individuals throughout the run. The rbf and poly kernel populations are kept apart throughout the process and each of them evolve within their own population. Once the initial populations are set up, the models are trained and each population is sorted starting with the best models first. For each population, we select parents equaling up to 25% of their kernel's total population. Starting with the best model, it has an 85% chance to be picked. Whether or not it was picked, we continue down the list of parents and each time a parent is picked, this starting 85% is multiplied by 85% until it bottoms out at 5%. This means the best models are generally picked but there is a possibility lower models will also get a chance to contribute.\n",
        "\n",
        "Once the parents have been picked from a population, we then would pair them off and combine their parameter traits to create one offspring combination. This would involve randomly choosing from one of the two parents' traits or, if it made sense for a particular parameter, taking the average of both of them. All the children resulting from the parents pairing off would then be put through a mutate function that would have a random chance to very slightly increase/decrease any one (or potentially multiple) of their parameter values. There was also a chance to switch between \"scale\"/\"auto\" gamma values and hardcoded values that you can see in the rbf_param_grid or for poly kernels to increase/decrease degrees.\n",
        "\n",
        "Once this process was done, the children models are all trained and then added to the population they came from. This population is then sorted again and the worst performing individuals are cut from the end of the list to maintain a stable population which helps prevent computational costs from going out of control with unchecked populations. This summarizes how the code began. We will put some brief in code comments below to give a brief overview of what each function does and we will discuss all the changes we had to make in the space below the codecell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkbppWucNA5c",
        "outputId": "0b0aaabc-fd9e-4d34-a0de-55eb609b08d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training models for kernel: poly\n",
            "Training models for kernel: rbf\n",
            "--- Generation 1 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=1, coef0=7, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=6.27656, coef0=1.025, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=0.3, coef0=15, degree=3, Balanced Accuracy: 0.468\n",
            "Params: C=10, coef0=7, degree=3, Balanced Accuracy: 0.466\n",
            "Params: C=0.3, coef0=7, degree=4, Balanced Accuracy: 0.465\n",
            "Params: C=1, coef0=15, degree=3, Balanced Accuracy: 0.464\n",
            "Params: C=10, coef0=1, degree=3, Balanced Accuracy: 0.463\n",
            "Params: C=30, coef0=1, degree=3, Balanced Accuracy: 0.462\n",
            "Params: C=0.3, coef0=15, degree=4, Balanced Accuracy: 0.461\n",
            "Params: C=1, coef0=7, degree=4, Balanced Accuracy: 0.461\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=70, gamma=0.01, Balanced Accuracy: 0.472\n",
            "Params: C=65, gamma=0.0135, Balanced Accuracy: 0.470\n",
            "Params: C=40, gamma=0.01628, Balanced Accuracy: 0.470\n",
            "Params: C=39, gamma=0.01345, Balanced Accuracy: 0.469\n",
            "Params: C=40, gamma=0.01, Balanced Accuracy: 0.464\n",
            "Params: C=10, gamma=scale, Balanced Accuracy: 0.462\n",
            "Params: C=10, gamma=0.025, Balanced Accuracy: 0.461\n",
            "Params: C=40, gamma=0.025, Balanced Accuracy: 0.459\n",
            "Params: C=40, gamma=scale, Balanced Accuracy: 0.458\n",
            "--- Generation 2 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=1, coef0=7, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=6.27656, coef0=1.025, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=0.3, coef0=15, degree=3, Balanced Accuracy: 0.468\n",
            "Params: C=10, coef0=7, degree=3, Balanced Accuracy: 0.466\n",
            "Params: C=19.41375, coef0=4, degree=3, Balanced Accuracy: 0.466\n",
            "Params: C=0.3, coef0=7, degree=4, Balanced Accuracy: 0.465\n",
            "Params: C=1, coef0=15, degree=3, Balanced Accuracy: 0.464\n",
            "Params: C=10, coef0=1, degree=3, Balanced Accuracy: 0.463\n",
            "Params: C=30, coef0=1, degree=3, Balanced Accuracy: 0.462\n",
            "Params: C=0.3, coef0=15, degree=4, Balanced Accuracy: 0.461\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=70, gamma=0.01, Balanced Accuracy: 0.472\n",
            "Params: C=65, gamma=0.0135, Balanced Accuracy: 0.470\n",
            "Params: C=40, gamma=0.01628, Balanced Accuracy: 0.470\n",
            "Params: C=39, gamma=0.01345, Balanced Accuracy: 0.469\n",
            "Params: C=89.6875, gamma=0.01347, Balanced Accuracy: 0.468\n",
            "Params: C=40, gamma=0.01, Balanced Accuracy: 0.464\n",
            "Params: C=10, gamma=scale, Balanced Accuracy: 0.462\n",
            "Params: C=10, gamma=0.025, Balanced Accuracy: 0.461\n",
            "Params: C=64.333, gamma=0.00643, Balanced Accuracy: 0.460\n",
            "--- Generation 3 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=1, coef0=7, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=6.27656, coef0=1.025, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=0.3, coef0=15, degree=3, Balanced Accuracy: 0.468\n",
            "Params: C=10, coef0=7, degree=3, Balanced Accuracy: 0.466\n",
            "Params: C=19.41375, coef0=4, degree=3, Balanced Accuracy: 0.466\n",
            "Params: C=1.36334, coef0=9.54338, degree=3, Balanced Accuracy: 0.466\n",
            "Params: C=0.3, coef0=7, degree=4, Balanced Accuracy: 0.465\n",
            "Params: C=5.5, coef0=11.275, degree=3, Balanced Accuracy: 0.465\n",
            "Params: C=1, coef0=15, degree=3, Balanced Accuracy: 0.464\n",
            "Params: C=10, coef0=1, degree=3, Balanced Accuracy: 0.463\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=36.23734, gamma=0.01572, Balanced Accuracy: 0.472\n",
            "Params: C=70, gamma=0.01, Balanced Accuracy: 0.472\n",
            "Params: C=65, gamma=0.0135, Balanced Accuracy: 0.470\n",
            "Params: C=40, gamma=0.01628, Balanced Accuracy: 0.470\n",
            "Params: C=39, gamma=0.01345, Balanced Accuracy: 0.469\n",
            "Params: C=89.6875, gamma=0.01347, Balanced Accuracy: 0.468\n",
            "Params: C=40, gamma=0.01, Balanced Accuracy: 0.464\n",
            "Params: C=28.68176, gamma=0.01185, Balanced Accuracy: 0.463\n",
            "Params: C=10, gamma=scale, Balanced Accuracy: 0.462\n",
            "--- Generation 4 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=1, coef0=7, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=6.27656, coef0=1.025, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=0.3, coef0=15, degree=3, Balanced Accuracy: 0.468\n",
            "Params: C=10, coef0=7, degree=3, Balanced Accuracy: 0.466\n",
            "Params: C=19.41375, coef0=4, degree=3, Balanced Accuracy: 0.466\n",
            "Params: C=1.37001, coef0=9.59007, degree=3, Balanced Accuracy: 0.466\n",
            "Params: C=1.36334, coef0=9.54338, degree=3, Balanced Accuracy: 0.466\n",
            "Params: C=0.3, coef0=7, degree=4, Balanced Accuracy: 0.465\n",
            "Params: C=5.5, coef0=11.275, degree=3, Balanced Accuracy: 0.465\n",
            "Params: C=10.15, coef0=5, degree=3, Balanced Accuracy: 0.465\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=36.23734, gamma=0.01572, Balanced Accuracy: 0.472\n",
            "Params: C=70, gamma=0.01, Balanced Accuracy: 0.472\n",
            "Params: C=65, gamma=0.0135, Balanced Accuracy: 0.470\n",
            "Params: C=40, gamma=0.01628, Balanced Accuracy: 0.470\n",
            "Params: C=39, gamma=0.01345, Balanced Accuracy: 0.469\n",
            "Params: C=89.6875, gamma=0.01347, Balanced Accuracy: 0.468\n",
            "Params: C=40, gamma=0.01, Balanced Accuracy: 0.464\n",
            "Params: C=28.68176, gamma=0.01185, Balanced Accuracy: 0.463\n",
            "Params: C=10, gamma=scale, Balanced Accuracy: 0.462\n",
            "--- Generation 5 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=1, coef0=7, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=6.27656, coef0=1.025, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=0.3, coef0=15, degree=3, Balanced Accuracy: 0.468\n",
            "Params: C=10, coef0=7, degree=3, Balanced Accuracy: 0.466\n",
            "Params: C=19.41375, coef0=4, degree=3, Balanced Accuracy: 0.466\n",
            "Params: C=1.37001, coef0=9.59007, degree=3, Balanced Accuracy: 0.466\n",
            "Params: C=1.36334, coef0=9.54338, degree=3, Balanced Accuracy: 0.466\n",
            "Params: C=0.3, coef0=7, degree=4, Balanced Accuracy: 0.465\n",
            "Params: C=5.5, coef0=11.275, degree=3, Balanced Accuracy: 0.465\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=36.23734, gamma=0.01572, Balanced Accuracy: 0.472\n",
            "Params: C=70, gamma=0.01, Balanced Accuracy: 0.472\n",
            "Params: C=60.01488, gamma=0.01299, Balanced Accuracy: 0.472\n",
            "Params: C=65, gamma=0.0135, Balanced Accuracy: 0.470\n",
            "Params: C=40, gamma=0.01628, Balanced Accuracy: 0.470\n",
            "Params: C=39, gamma=0.01345, Balanced Accuracy: 0.469\n",
            "Params: C=89.6875, gamma=0.01347, Balanced Accuracy: 0.468\n",
            "Params: C=68.75, gamma=0.01794, Balanced Accuracy: 0.465\n",
            "Params: C=40, gamma=0.01, Balanced Accuracy: 0.464\n",
            "--- Generation 6 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.6277, coef0=1.85004, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=1, coef0=7, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=6.27656, coef0=1.025, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=0.3, coef0=15, degree=3, Balanced Accuracy: 0.468\n",
            "Params: C=1.11264, coef0=10.725, degree=3, Balanced Accuracy: 0.466\n",
            "Params: C=10, coef0=7, degree=3, Balanced Accuracy: 0.466\n",
            "Params: C=19.41375, coef0=4, degree=3, Balanced Accuracy: 0.466\n",
            "Params: C=1.37001, coef0=9.59007, degree=3, Balanced Accuracy: 0.466\n",
            "Params: C=1.36334, coef0=9.54338, degree=3, Balanced Accuracy: 0.466\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=36.23734, gamma=0.01572, Balanced Accuracy: 0.472\n",
            "Params: C=80.00744, gamma=0.01178, Balanced Accuracy: 0.472\n",
            "Params: C=70, gamma=0.01, Balanced Accuracy: 0.472\n",
            "Params: C=60.01488, gamma=0.01299, Balanced Accuracy: 0.472\n",
            "Params: C=65, gamma=0.0135, Balanced Accuracy: 0.470\n",
            "Params: C=40, gamma=0.01628, Balanced Accuracy: 0.470\n",
            "Params: C=39, gamma=0.01345, Balanced Accuracy: 0.469\n",
            "Params: C=89.6875, gamma=0.01347, Balanced Accuracy: 0.468\n",
            "Params: C=27.50865, gamma=0.01458, Balanced Accuracy: 0.467\n",
            "--- Generation 7 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.63063, coef0=4.16868, degree=3, Balanced Accuracy: 0.470\n",
            "Params: C=2.6277, coef0=1.85004, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=1, coef0=7, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=6.27656, coef0=1.025, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=0.3, coef0=15, degree=3, Balanced Accuracy: 0.468\n",
            "Params: C=5.92323, coef0=1.85896, degree=3, Balanced Accuracy: 0.468\n",
            "Params: C=1.11264, coef0=10.725, degree=3, Balanced Accuracy: 0.466\n",
            "Params: C=10, coef0=7, degree=3, Balanced Accuracy: 0.466\n",
            "Params: C=19.41375, coef0=4, degree=3, Balanced Accuracy: 0.466\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=36.23734, gamma=0.01572, Balanced Accuracy: 0.472\n",
            "Params: C=80.00744, gamma=0.01178, Balanced Accuracy: 0.472\n",
            "Params: C=70, gamma=0.01, Balanced Accuracy: 0.472\n",
            "Params: C=60.01488, gamma=0.01299, Balanced Accuracy: 0.472\n",
            "Params: C=65, gamma=0.0135, Balanced Accuracy: 0.470\n",
            "Params: C=60.998, gamma=0.0139, Balanced Accuracy: 0.470\n",
            "Params: C=40, gamma=0.01628, Balanced Accuracy: 0.470\n",
            "Params: C=39, gamma=0.01345, Balanced Accuracy: 0.469\n",
            "Params: C=89.6875, gamma=0.01347, Balanced Accuracy: 0.468\n",
            "--- Generation 8 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.63063, coef0=4.16868, degree=3, Balanced Accuracy: 0.470\n",
            "Params: C=2.6277, coef0=1.85004, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=1, coef0=7, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=6.27656, coef0=1.025, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=0.3, coef0=15, degree=3, Balanced Accuracy: 0.468\n",
            "Params: C=5.92323, coef0=1.85896, degree=3, Balanced Accuracy: 0.468\n",
            "Params: C=8.44448, coef0=1.5937, degree=3, Balanced Accuracy: 0.467\n",
            "Params: C=1.11264, coef0=10.725, degree=3, Balanced Accuracy: 0.466\n",
            "Params: C=10, coef0=7, degree=3, Balanced Accuracy: 0.466\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=36.23734, gamma=0.01572, Balanced Accuracy: 0.472\n",
            "Params: C=80.00744, gamma=0.01178, Balanced Accuracy: 0.472\n",
            "Params: C=70, gamma=0.01, Balanced Accuracy: 0.472\n",
            "Params: C=60.01488, gamma=0.01299, Balanced Accuracy: 0.472\n",
            "Params: C=60.331, gamma=0.01397, Balanced Accuracy: 0.470\n",
            "Params: C=65, gamma=0.0135, Balanced Accuracy: 0.470\n",
            "Params: C=60.998, gamma=0.0139, Balanced Accuracy: 0.470\n",
            "Params: C=40, gamma=0.01628, Balanced Accuracy: 0.470\n",
            "Params: C=39, gamma=0.01345, Balanced Accuracy: 0.469\n",
            "--- Generation 9 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.63063, coef0=4.16868, degree=3, Balanced Accuracy: 0.470\n",
            "Params: C=2.6277, coef0=1.85004, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=1, coef0=7, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=6.27656, coef0=1.025, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=0.3, coef0=15, degree=3, Balanced Accuracy: 0.468\n",
            "Params: C=5.92323, coef0=1.85896, degree=3, Balanced Accuracy: 0.468\n",
            "Params: C=2.37067, coef0=1.76949, degree=3, Balanced Accuracy: 0.468\n",
            "Params: C=8.44448, coef0=1.5937, degree=3, Balanced Accuracy: 0.467\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=36.23734, gamma=0.01572, Balanced Accuracy: 0.472\n",
            "Params: C=80.00744, gamma=0.01178, Balanced Accuracy: 0.472\n",
            "Params: C=70, gamma=0.01, Balanced Accuracy: 0.472\n",
            "Params: C=60.01488, gamma=0.01299, Balanced Accuracy: 0.472\n",
            "Params: C=60.331, gamma=0.01397, Balanced Accuracy: 0.470\n",
            "Params: C=65, gamma=0.0135, Balanced Accuracy: 0.470\n",
            "Params: C=59.664, gamma=0.01403, Balanced Accuracy: 0.470\n",
            "Params: C=60.998, gamma=0.0139, Balanced Accuracy: 0.470\n",
            "--- Generation 10 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.63063, coef0=4.16868, degree=3, Balanced Accuracy: 0.470\n",
            "Params: C=2.6277, coef0=1.85004, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=1, coef0=7, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=6.27656, coef0=1.025, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=0.3, coef0=15, degree=3, Balanced Accuracy: 0.468\n",
            "Params: C=5.92323, coef0=1.85896, degree=3, Balanced Accuracy: 0.468\n",
            "Params: C=2.37067, coef0=1.76949, degree=3, Balanced Accuracy: 0.468\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=36.23734, gamma=0.01572, Balanced Accuracy: 0.472\n",
            "Params: C=80.00744, gamma=0.01178, Balanced Accuracy: 0.472\n",
            "Params: C=70, gamma=0.01, Balanced Accuracy: 0.472\n",
            "Params: C=60.01488, gamma=0.01299, Balanced Accuracy: 0.472\n",
            "Params: C=60.331, gamma=0.01397, Balanced Accuracy: 0.470\n",
            "Params: C=65, gamma=0.0135, Balanced Accuracy: 0.470\n",
            "Params: C=59.664, gamma=0.01403, Balanced Accuracy: 0.470\n",
            "--- Generation 11 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.63063, coef0=4.16868, degree=3, Balanced Accuracy: 0.470\n",
            "Params: C=16.70236, coef0=2.62827, degree=2, Balanced Accuracy: 0.469\n",
            "Params: C=2.6277, coef0=1.85004, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=1, coef0=7, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=6.27656, coef0=1.025, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=0.3, coef0=15, degree=3, Balanced Accuracy: 0.468\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=36.23734, gamma=0.01572, Balanced Accuracy: 0.472\n",
            "Params: C=80.00744, gamma=0.01178, Balanced Accuracy: 0.472\n",
            "Params: C=70, gamma=0.01, Balanced Accuracy: 0.472\n",
            "Params: C=60.01488, gamma=0.01299, Balanced Accuracy: 0.472\n",
            "Params: C=60.331, gamma=0.01397, Balanced Accuracy: 0.470\n",
            "Params: C=65, gamma=0.0135, Balanced Accuracy: 0.470\n",
            "Params: C=59.664, gamma=0.01403, Balanced Accuracy: 0.470\n",
            "--- Generation 12 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.63063, coef0=4.16868, degree=3, Balanced Accuracy: 0.470\n",
            "Params: C=16.70236, coef0=2.62827, degree=2, Balanced Accuracy: 0.469\n",
            "Params: C=2.6277, coef0=1.85004, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=1, coef0=7, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=6.27656, coef0=1.025, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=0.3, coef0=15, degree=3, Balanced Accuracy: 0.468\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=36.23734, gamma=0.01572, Balanced Accuracy: 0.472\n",
            "Params: C=80.00744, gamma=0.01178, Balanced Accuracy: 0.472\n",
            "Params: C=70, gamma=0.01, Balanced Accuracy: 0.472\n",
            "Params: C=60.01488, gamma=0.01299, Balanced Accuracy: 0.472\n",
            "Params: C=60.331, gamma=0.01397, Balanced Accuracy: 0.470\n",
            "Params: C=65, gamma=0.0135, Balanced Accuracy: 0.470\n",
            "Params: C=59.664, gamma=0.01403, Balanced Accuracy: 0.470\n",
            "--- Generation 13 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.63063, coef0=4.16868, degree=3, Balanced Accuracy: 0.470\n",
            "Params: C=16.70236, coef0=2.62827, degree=2, Balanced Accuracy: 0.469\n",
            "Params: C=2.6277, coef0=1.85004, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=1, coef0=7, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=6.27656, coef0=1.025, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=0.3, coef0=15, degree=3, Balanced Accuracy: 0.468\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=36.23734, gamma=0.01572, Balanced Accuracy: 0.472\n",
            "Params: C=80.00744, gamma=0.01178, Balanced Accuracy: 0.472\n",
            "Params: C=70, gamma=0.01, Balanced Accuracy: 0.472\n",
            "Params: C=60.01488, gamma=0.01299, Balanced Accuracy: 0.472\n",
            "Params: C=60.331, gamma=0.01397, Balanced Accuracy: 0.470\n",
            "Params: C=56.996, gamma=0.0143, Balanced Accuracy: 0.470\n",
            "Params: C=65, gamma=0.0135, Balanced Accuracy: 0.470\n",
            "--- Generation 14 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.63063, coef0=4.16868, degree=3, Balanced Accuracy: 0.470\n",
            "Params: C=16.70236, coef0=2.62827, degree=2, Balanced Accuracy: 0.469\n",
            "Params: C=2.6277, coef0=1.85004, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=1, coef0=7, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=6.27656, coef0=1.025, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=0.3, coef0=15, degree=3, Balanced Accuracy: 0.468\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=66.63262, gamma=0.01178, Balanced Accuracy: 0.474\n",
            "Params: C=36.23734, gamma=0.01572, Balanced Accuracy: 0.472\n",
            "Params: C=58.12239, gamma=0.01375, Balanced Accuracy: 0.472\n",
            "Params: C=80.00744, gamma=0.01178, Balanced Accuracy: 0.472\n",
            "Params: C=70, gamma=0.01, Balanced Accuracy: 0.472\n",
            "Params: C=60.01488, gamma=0.01299, Balanced Accuracy: 0.472\n",
            "Params: C=60.331, gamma=0.01397, Balanced Accuracy: 0.470\n",
            "--- Generation 15 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.63063, coef0=4.16868, degree=3, Balanced Accuracy: 0.470\n",
            "Params: C=3.44594, coef0=2.82185, degree=3, Balanced Accuracy: 0.470\n",
            "Params: C=16.70236, coef0=2.62827, degree=2, Balanced Accuracy: 0.469\n",
            "Params: C=2.6277, coef0=1.85004, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=1, coef0=7, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=6.27656, coef0=1.025, degree=3, Balanced Accuracy: 0.469\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=81.2334, gamma=0.01077, Balanced Accuracy: 0.474\n",
            "Params: C=66.63262, gamma=0.01178, Balanced Accuracy: 0.474\n",
            "Params: C=47.17986, gamma=0.01436, Balanced Accuracy: 0.473\n",
            "Params: C=36.23734, gamma=0.01572, Balanced Accuracy: 0.472\n",
            "Params: C=58.12239, gamma=0.01375, Balanced Accuracy: 0.472\n",
            "Params: C=80.00744, gamma=0.01178, Balanced Accuracy: 0.472\n",
            "Params: C=70, gamma=0.01, Balanced Accuracy: 0.472\n",
            "--- Generation 16 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.63063, coef0=4.16868, degree=3, Balanced Accuracy: 0.470\n",
            "Params: C=3.44594, coef0=2.82185, degree=3, Balanced Accuracy: 0.470\n",
            "Params: C=2.69639, coef0=4.16868, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=16.70236, coef0=2.62827, degree=2, Balanced Accuracy: 0.469\n",
            "Params: C=2.6277, coef0=1.85004, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=1, coef0=7, degree=3, Balanced Accuracy: 0.469\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=81.2334, gamma=0.01077, Balanced Accuracy: 0.474\n",
            "Params: C=66.63262, gamma=0.01178, Balanced Accuracy: 0.474\n",
            "Params: C=72.38974, gamma=0.01218, Balanced Accuracy: 0.473\n",
            "Params: C=47.17986, gamma=0.01436, Balanced Accuracy: 0.473\n",
            "Params: C=36.23734, gamma=0.01572, Balanced Accuracy: 0.472\n",
            "Params: C=58.12239, gamma=0.01375, Balanced Accuracy: 0.472\n",
            "--- Generation 17 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.99439, coef0=3.58265, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=2.63063, coef0=4.16868, degree=3, Balanced Accuracy: 0.470\n",
            "Params: C=3.44594, coef0=2.82185, degree=3, Balanced Accuracy: 0.470\n",
            "Params: C=2.69639, coef0=4.16868, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=16.70236, coef0=2.62827, degree=2, Balanced Accuracy: 0.469\n",
            "Params: C=2.6277, coef0=1.85004, degree=3, Balanced Accuracy: 0.469\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=81.2334, gamma=0.01077, Balanced Accuracy: 0.474\n",
            "Params: C=66.63262, gamma=0.01178, Balanced Accuracy: 0.474\n",
            "Params: C=88.35128, gamma=0.01006, Balanced Accuracy: 0.473\n",
            "Params: C=72.38974, gamma=0.01218, Balanced Accuracy: 0.473\n",
            "Params: C=47.17986, gamma=0.01436, Balanced Accuracy: 0.473\n",
            "Params: C=36.23734, gamma=0.01572, Balanced Accuracy: 0.472\n",
            "--- Generation 18 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.99439, coef0=3.58265, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=2.63063, coef0=4.16868, degree=3, Balanced Accuracy: 0.470\n",
            "Params: C=3.44594, coef0=2.82185, degree=3, Balanced Accuracy: 0.470\n",
            "Params: C=2.69639, coef0=4.16868, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=16.70236, coef0=2.62827, degree=2, Balanced Accuracy: 0.469\n",
            "Params: C=2.6277, coef0=1.85004, degree=3, Balanced Accuracy: 0.469\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=90.6167, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "Params: C=81.2334, gamma=0.01077, Balanced Accuracy: 0.474\n",
            "Params: C=66.63262, gamma=0.01178, Balanced Accuracy: 0.474\n",
            "Params: C=88.35128, gamma=0.01006, Balanced Accuracy: 0.473\n",
            "Params: C=72.38974, gamma=0.01218, Balanced Accuracy: 0.473\n",
            "Params: C=47.17986, gamma=0.01436, Balanced Accuracy: 0.473\n",
            "--- Generation 19 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.99439, coef0=3.58265, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=2.63063, coef0=4.16868, degree=3, Balanced Accuracy: 0.470\n",
            "Params: C=3.44594, coef0=2.82185, degree=3, Balanced Accuracy: 0.470\n",
            "Params: C=2.69639, coef0=4.16868, degree=3, Balanced Accuracy: 0.469\n",
            "Params: C=16.70236, coef0=2.62827, degree=2, Balanced Accuracy: 0.469\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=90.6167, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "Params: C=81.2334, gamma=0.01077, Balanced Accuracy: 0.474\n",
            "Params: C=66.63262, gamma=0.01178, Balanced Accuracy: 0.474\n",
            "Params: C=88.35128, gamma=0.01006, Balanced Accuracy: 0.473\n",
            "Params: C=72.38974, gamma=0.01218, Balanced Accuracy: 0.473\n",
            "Params: C=47.17986, gamma=0.01436, Balanced Accuracy: 0.473\n",
            "--- Generation 20 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.04593, coef0=1.83497, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=2.99439, coef0=3.58265, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=2.63063, coef0=4.16868, degree=3, Balanced Accuracy: 0.470\n",
            "Params: C=3.44594, coef0=2.82185, degree=3, Balanced Accuracy: 0.470\n",
            "Params: C=2.69639, coef0=4.16868, degree=3, Balanced Accuracy: 0.469\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=90.6167, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "Params: C=81.2334, gamma=0.01077, Balanced Accuracy: 0.474\n",
            "Params: C=66.63262, gamma=0.01178, Balanced Accuracy: 0.474\n",
            "Params: C=88.35128, gamma=0.01006, Balanced Accuracy: 0.473\n",
            "Params: C=72.38974, gamma=0.01218, Balanced Accuracy: 0.473\n",
            "Params: C=47.17986, gamma=0.01436, Balanced Accuracy: 0.473\n",
            "--- Generation 21 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.02296, coef0=4.30705, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=3.04593, coef0=1.83497, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=2.99439, coef0=3.58265, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=2.63063, coef0=4.16868, degree=3, Balanced Accuracy: 0.470\n",
            "Params: C=3.44594, coef0=2.82185, degree=3, Balanced Accuracy: 0.470\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=90.6167, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "Params: C=81.2334, gamma=0.01077, Balanced Accuracy: 0.474\n",
            "Params: C=66.63262, gamma=0.01178, Balanced Accuracy: 0.474\n",
            "Params: C=88.35128, gamma=0.01006, Balanced Accuracy: 0.473\n",
            "Params: C=72.38974, gamma=0.01218, Balanced Accuracy: 0.473\n",
            "Params: C=47.17986, gamma=0.01436, Balanced Accuracy: 0.473\n",
            "--- Generation 22 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.57085, coef0=3.03156, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.02296, coef0=4.30705, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=3.04593, coef0=1.83497, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=2.99439, coef0=3.58265, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=2.63063, coef0=4.16868, degree=3, Balanced Accuracy: 0.470\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01098, Balanced Accuracy: 0.474\n",
            "Params: C=90.6167, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "Params: C=92.92564, gamma=0.01041, Balanced Accuracy: 0.474\n",
            "Params: C=81.2334, gamma=0.01077, Balanced Accuracy: 0.474\n",
            "Params: C=66.63262, gamma=0.01178, Balanced Accuracy: 0.474\n",
            "Params: C=88.35128, gamma=0.01006, Balanced Accuracy: 0.473\n",
            "--- Generation 23 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.57085, coef0=3.03156, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.02296, coef0=4.30705, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=3.04593, coef0=1.83497, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=2.99439, coef0=3.58265, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=2.63063, coef0=4.16868, degree=3, Balanced Accuracy: 0.470\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01098, Balanced Accuracy: 0.474\n",
            "Params: C=90.6167, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "Params: C=92.92564, gamma=0.01041, Balanced Accuracy: 0.474\n",
            "Params: C=81.2334, gamma=0.01077, Balanced Accuracy: 0.474\n",
            "Params: C=66.63262, gamma=0.01178, Balanced Accuracy: 0.474\n",
            "--- Generation 24 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.57085, coef0=3.03156, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.02296, coef0=4.30705, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=3.04593, coef0=1.83497, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=2.99439, coef0=3.58265, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=2.63063, coef0=4.16868, degree=3, Balanced Accuracy: 0.470\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01098, Balanced Accuracy: 0.474\n",
            "Params: C=90.6167, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "Params: C=92.92564, gamma=0.01041, Balanced Accuracy: 0.474\n",
            "Params: C=81.2334, gamma=0.01077, Balanced Accuracy: 0.474\n",
            "Params: C=66.63262, gamma=0.01178, Balanced Accuracy: 0.474\n",
            "--- Generation 25 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.57085, coef0=3.03156, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.02296, coef0=4.30705, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=3.04593, coef0=1.83497, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=2.99439, coef0=3.58265, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=2.63063, coef0=4.16868, degree=3, Balanced Accuracy: 0.470\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01098, Balanced Accuracy: 0.474\n",
            "Params: C=90.6167, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "Params: C=92.92564, gamma=0.01041, Balanced Accuracy: 0.474\n",
            "Params: C=81.2334, gamma=0.01077, Balanced Accuracy: 0.474\n",
            "Params: C=66.63262, gamma=0.01178, Balanced Accuracy: 0.474\n",
            "--- Generation 26 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.57085, coef0=3.03156, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.02296, coef0=4.30705, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=3.04593, coef0=1.83497, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=2.99439, coef0=3.58265, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=2.63063, coef0=4.16868, degree=3, Balanced Accuracy: 0.470\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01098, Balanced Accuracy: 0.474\n",
            "Params: C=90.6167, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "Params: C=92.92564, gamma=0.01041, Balanced Accuracy: 0.474\n",
            "Params: C=81.2334, gamma=0.01077, Balanced Accuracy: 0.474\n",
            "Params: C=66.63262, gamma=0.01178, Balanced Accuracy: 0.474\n",
            "--- Generation 27 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.57085, coef0=3.03156, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.17961, coef0=2.25852, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.02296, coef0=4.30705, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=3.04593, coef0=1.83497, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=2.99439, coef0=3.58265, degree=3, Balanced Accuracy: 0.471\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01098, Balanced Accuracy: 0.474\n",
            "Params: C=90.6167, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "Params: C=92.92564, gamma=0.01041, Balanced Accuracy: 0.474\n",
            "Params: C=81.2334, gamma=0.01077, Balanced Accuracy: 0.474\n",
            "Params: C=66.63262, gamma=0.01178, Balanced Accuracy: 0.474\n",
            "--- Generation 28 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.57085, coef0=3.03156, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.17961, coef0=2.25852, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.02296, coef0=4.30705, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=3.96023, coef0=2.33259, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=3.04593, coef0=1.83497, degree=3, Balanced Accuracy: 0.471\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01098, Balanced Accuracy: 0.474\n",
            "Params: C=90.6167, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "Params: C=77.24729, gamma=0.01124, Balanced Accuracy: 0.474\n",
            "Params: C=92.92564, gamma=0.01041, Balanced Accuracy: 0.474\n",
            "Params: C=81.2334, gamma=0.01077, Balanced Accuracy: 0.474\n",
            "--- Generation 29 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.57085, coef0=3.03156, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.17961, coef0=2.25852, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.02296, coef0=4.30705, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=3.96023, coef0=2.33259, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=3.04593, coef0=1.83497, degree=3, Balanced Accuracy: 0.471\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01098, Balanced Accuracy: 0.474\n",
            "Params: C=90.6167, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "Params: C=77.24729, gamma=0.01124, Balanced Accuracy: 0.474\n",
            "Params: C=92.92564, gamma=0.01041, Balanced Accuracy: 0.474\n",
            "Params: C=81.2334, gamma=0.01077, Balanced Accuracy: 0.474\n",
            "--- Generation 30 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.57085, coef0=3.03156, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.17961, coef0=2.25852, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.02296, coef0=4.30705, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=3.16818, coef0=2.91573, degree=3, Balanced Accuracy: 0.471\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01098, Balanced Accuracy: 0.474\n",
            "Params: C=90.6167, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "Params: C=77.24729, gamma=0.01124, Balanced Accuracy: 0.474\n",
            "Params: C=92.92564, gamma=0.01041, Balanced Accuracy: 0.474\n",
            "Params: C=81.2334, gamma=0.01077, Balanced Accuracy: 0.474\n",
            "--- Generation 31 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.57085, coef0=3.03156, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.17961, coef0=2.25852, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.02296, coef0=4.30705, degree=3, Balanced Accuracy: 0.471\n",
            "Params: C=3.16818, coef0=2.91573, degree=3, Balanced Accuracy: 0.471\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01098, Balanced Accuracy: 0.474\n",
            "Params: C=90.6167, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "Params: C=77.24729, gamma=0.01124, Balanced Accuracy: 0.474\n",
            "Params: C=92.92564, gamma=0.01041, Balanced Accuracy: 0.474\n",
            "Params: C=81.2334, gamma=0.01077, Balanced Accuracy: 0.474\n",
            "--- Generation 32 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.81187, coef0=2.33296, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.57085, coef0=3.03156, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.17961, coef0=2.25852, degree=3, Balanced Accuracy: 0.472\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01098, Balanced Accuracy: 0.474\n",
            "Params: C=90.6167, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "Params: C=77.24729, gamma=0.01124, Balanced Accuracy: 0.474\n",
            "Params: C=92.92564, gamma=0.01041, Balanced Accuracy: 0.474\n",
            "--- Generation 33 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.81187, coef0=2.33296, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.57085, coef0=3.03156, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.17961, coef0=2.25852, degree=3, Balanced Accuracy: 0.472\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=91.20127, gamma=0.0102, Balanced Accuracy: 0.474\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01098, Balanced Accuracy: 0.474\n",
            "Params: C=90.6167, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "Params: C=77.24729, gamma=0.01124, Balanced Accuracy: 0.474\n",
            "--- Generation 34 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.81187, coef0=2.33296, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.57085, coef0=3.03156, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.17961, coef0=2.25852, degree=3, Balanced Accuracy: 0.472\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=91.20127, gamma=0.0102, Balanced Accuracy: 0.474\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01098, Balanced Accuracy: 0.474\n",
            "Params: C=90.6167, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "--- Generation 35 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.81187, coef0=2.33296, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.57085, coef0=3.03156, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=91.20127, gamma=0.0102, Balanced Accuracy: 0.474\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01098, Balanced Accuracy: 0.474\n",
            "Params: C=90.6167, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "--- Generation 36 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.81187, coef0=2.33296, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.57085, coef0=3.03156, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=91.20127, gamma=0.0102, Balanced Accuracy: 0.474\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01098, Balanced Accuracy: 0.474\n",
            "Params: C=90.6167, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "--- Generation 37 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.81187, coef0=2.33296, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.57085, coef0=3.03156, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=91.20127, gamma=0.0102, Balanced Accuracy: 0.474\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "Params: C=93.76821, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01098, Balanced Accuracy: 0.474\n",
            "--- Generation 38 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.81187, coef0=2.33296, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.57085, coef0=3.03156, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=91.20127, gamma=0.0102, Balanced Accuracy: 0.474\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "Params: C=93.76821, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01098, Balanced Accuracy: 0.474\n",
            "--- Generation 39 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.81187, coef0=2.33296, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.57085, coef0=3.03156, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=91.20127, gamma=0.0102, Balanced Accuracy: 0.474\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "Params: C=93.76821, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01098, Balanced Accuracy: 0.474\n",
            "--- Generation 40 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.81187, coef0=2.33296, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.57085, coef0=3.03156, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=91.20127, gamma=0.0102, Balanced Accuracy: 0.474\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "Params: C=93.76821, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01098, Balanced Accuracy: 0.474\n",
            "--- Generation 41 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.81187, coef0=2.33296, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.57085, coef0=3.03156, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=91.20127, gamma=0.0102, Balanced Accuracy: 0.474\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "Params: C=93.76821, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01098, Balanced Accuracy: 0.474\n",
            "--- Generation 42 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.81187, coef0=2.33296, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.57085, coef0=3.03156, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=91.20127, gamma=0.0102, Balanced Accuracy: 0.474\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "Params: C=93.76821, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01098, Balanced Accuracy: 0.474\n",
            "--- Generation 43 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.81187, coef0=2.33296, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.57085, coef0=3.03156, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=91.20127, gamma=0.0102, Balanced Accuracy: 0.474\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "Params: C=93.76821, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01098, Balanced Accuracy: 0.474\n",
            "--- Generation 44 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.81187, coef0=2.33296, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.57085, coef0=3.03156, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.86122, coef0=2.33259, degree=3, Balanced Accuracy: 0.472\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=102.5, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=91.20127, gamma=0.0102, Balanced Accuracy: 0.474\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "Params: C=93.76821, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "Params: C=68.26088, gamma=0.01208, Balanced Accuracy: 0.474\n",
            "--- Generation 45 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.64835, coef0=2.85932, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.81187, coef0=2.33296, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.57085, coef0=3.03156, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.57657, coef0=2.21954, degree=3, Balanced Accuracy: 0.472\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=102.5, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=91.20127, gamma=0.0102, Balanced Accuracy: 0.474\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "Params: C=93.76821, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "--- Generation 46 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.64835, coef0=2.85932, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.81187, coef0=2.33296, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.57085, coef0=3.03156, degree=3, Balanced Accuracy: 0.472\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=102.5, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=91.20127, gamma=0.0102, Balanced Accuracy: 0.474\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "Params: C=93.76821, gamma=0.01032, Balanced Accuracy: 0.474\n",
            "--- Generation 47 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.64835, coef0=2.85932, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.82094, coef0=1.77845, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.81187, coef0=2.33296, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=4.26125, coef0=1.33736, degree=3, Balanced Accuracy: 0.472\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=102.5, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=91.20127, gamma=0.0102, Balanced Accuracy: 0.474\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "--- Generation 48 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.64835, coef0=2.85932, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.82094, coef0=1.77845, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.58997, coef0=3.7617, degree=3, Balanced Accuracy: 0.472\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=102.5, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=91.20127, gamma=0.0102, Balanced Accuracy: 0.474\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "--- Generation 49 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.64835, coef0=2.85932, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.82094, coef0=1.77845, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.58997, coef0=3.7617, degree=3, Balanced Accuracy: 0.472\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=102.5, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=91.20127, gamma=0.0102, Balanced Accuracy: 0.474\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "--- Generation 50 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.67782, coef0=1.85737, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.64835, coef0=2.85932, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.82094, coef0=1.77845, degree=3, Balanced Accuracy: 0.472\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=102.5, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=91.20127, gamma=0.0102, Balanced Accuracy: 0.474\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "--- Generation 51 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.67782, coef0=1.85737, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.64835, coef0=2.85932, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.82094, coef0=1.77845, degree=3, Balanced Accuracy: 0.472\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=102.5, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=91.20127, gamma=0.0102, Balanced Accuracy: 0.474\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "--- Generation 52 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.67782, coef0=1.85737, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.64835, coef0=2.85932, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.82094, coef0=1.77845, degree=3, Balanced Accuracy: 0.472\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=102.5, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=91.20127, gamma=0.0102, Balanced Accuracy: 0.474\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "--- Generation 53 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.67782, coef0=1.85737, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.64835, coef0=2.85932, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=3.82094, coef0=1.77845, degree=3, Balanced Accuracy: 0.472\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=102.5, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=91.20127, gamma=0.0102, Balanced Accuracy: 0.474\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "--- Generation 54 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.67782, coef0=1.85737, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.64835, coef0=2.85932, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Params: C=2.88058, coef0=2.69295, degree=3, Balanced Accuracy: 0.472\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=102.5, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=91.20127, gamma=0.0102, Balanced Accuracy: 0.474\n",
            "Params: C=100, gamma=0.00975, Balanced Accuracy: 0.474\n",
            "Params: C=86.2337, gamma=0.01091, Balanced Accuracy: 0.474\n",
            "--- Generation 55 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.96737, coef0=1.60001, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.67782, coef0=1.85737, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.64835, coef0=2.85932, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.62916, coef0=2.93413, degree=3, Balanced Accuracy: 0.472\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=98.23141, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=101.25, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=102.5, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=91.20127, gamma=0.0102, Balanced Accuracy: 0.474\n",
            "--- Generation 56 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.96737, coef0=1.60001, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.65684, coef0=1.79552, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.67782, coef0=1.85737, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.64835, coef0=2.85932, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=98.23141, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=101.25, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=102.5, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=91.20127, gamma=0.0102, Balanced Accuracy: 0.474\n",
            "--- Generation 57 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.96737, coef0=1.60001, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.65684, coef0=1.79552, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.67782, coef0=1.85737, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.64835, coef0=2.85932, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100.36571, gamma=0.00993, Balanced Accuracy: 0.475\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=98.23141, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=101.25, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=102.5, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "--- Generation 58 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.96737, coef0=1.60001, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.65684, coef0=1.79552, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.67782, coef0=1.85737, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.64835, coef0=2.85932, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.7072, coef0=1.73105, degree=3, Balanced Accuracy: 0.473\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100.36571, gamma=0.00993, Balanced Accuracy: 0.475\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=98.23141, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=101.25, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=102.5, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "--- Generation 59 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.96737, coef0=1.60001, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.95108, coef0=1.73, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.65684, coef0=1.79552, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.67782, coef0=1.85737, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.64835, coef0=2.85932, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100.36571, gamma=0.00993, Balanced Accuracy: 0.475\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=98.23141, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=101.25, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=102.5, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "--- Generation 60 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.96737, coef0=1.60001, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.95108, coef0=1.73, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.65684, coef0=1.79552, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.67782, coef0=1.85737, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.64835, coef0=2.85932, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.99148, coef0=2.45178, degree=3, Balanced Accuracy: 0.473\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100.36571, gamma=0.00993, Balanced Accuracy: 0.475\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=98.23141, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=101.25, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=96.99438, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "--- Generation 61 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.96737, coef0=1.60001, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.95108, coef0=1.73, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.65684, coef0=1.79552, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=5.20721, coef0=1.35153, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.67782, coef0=1.85737, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.64835, coef0=2.85932, degree=3, Balanced Accuracy: 0.473\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100.36571, gamma=0.00993, Balanced Accuracy: 0.475\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=98.23141, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=101.25, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=96.99438, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "--- Generation 62 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.96737, coef0=1.60001, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.95108, coef0=1.73, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.65684, coef0=1.79552, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=5.20721, coef0=1.35153, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.67782, coef0=1.85737, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.64835, coef0=2.85932, degree=3, Balanced Accuracy: 0.473\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100.36571, gamma=0.00993, Balanced Accuracy: 0.475\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=98.23141, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=101.25, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=96.99438, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "--- Generation 63 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.95922, coef0=1.62338, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.96737, coef0=1.60001, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.95108, coef0=1.73, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.65684, coef0=1.79552, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=5.20721, coef0=1.35153, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.67782, coef0=1.85737, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100.36571, gamma=0.00993, Balanced Accuracy: 0.475\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=98.23141, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=101.25, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=96.99438, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "--- Generation 64 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.95922, coef0=1.62338, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.96737, coef0=1.60001, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.95108, coef0=1.73, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.65684, coef0=1.79552, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=5.20721, coef0=1.35153, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.67782, coef0=1.85737, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100.36571, gamma=0.00993, Balanced Accuracy: 0.475\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=98.23141, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=101.25, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=96.99438, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "--- Generation 65 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.95922, coef0=1.62338, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.96737, coef0=1.60001, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.95108, coef0=1.73, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.65684, coef0=1.79552, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=5.20721, coef0=1.35153, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.67782, coef0=1.85737, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100.36571, gamma=0.00993, Balanced Accuracy: 0.475\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=98.23141, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=101.25, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=96.99438, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "--- Generation 66 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.95922, coef0=1.62338, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.96737, coef0=1.60001, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.95108, coef0=1.73, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.65684, coef0=1.79552, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=5.20721, coef0=1.35153, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.67782, coef0=1.85737, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100.36571, gamma=0.00993, Balanced Accuracy: 0.475\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=98.23141, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=101.25, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=96.99438, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "--- Generation 67 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.95922, coef0=1.62338, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.96737, coef0=1.60001, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.95108, coef0=1.73, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.65684, coef0=1.79552, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=5.20721, coef0=1.35153, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.67782, coef0=1.85737, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.36417, coef0=1.17236, degree=3, Balanced Accuracy: 0.473\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100.36571, gamma=0.00993, Balanced Accuracy: 0.475\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=98.23141, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=101.25, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=96.99438, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "--- Generation 68 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.95922, coef0=1.62338, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.96737, coef0=1.60001, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.95108, coef0=1.73, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.65684, coef0=1.79552, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=5.20721, coef0=1.35153, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.95412, coef0=1.5714, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.67782, coef0=1.85737, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100.36571, gamma=0.00993, Balanced Accuracy: 0.475\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=98.23141, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=101.25, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "Params: C=96.99438, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "--- Generation 69 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.95922, coef0=1.62338, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.96737, coef0=1.60001, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.95108, coef0=1.73, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.65684, coef0=1.79552, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=5.20721, coef0=1.35153, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.95412, coef0=1.5714, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.67782, coef0=1.85737, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=2.80335, coef0=2.64504, degree=3, Balanced Accuracy: 0.473\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100.36571, gamma=0.00993, Balanced Accuracy: 0.475\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=98.23141, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=95.57732, gamma=0.0103, Balanced Accuracy: 0.475\n",
            "Params: C=101.25, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "--- Generation 70 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.95922, coef0=1.62338, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.96737, coef0=1.60001, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.95108, coef0=1.73, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.65684, coef0=1.79552, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=5.20721, coef0=1.35153, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=5.05189, coef0=1.34625, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.6978, coef0=1.45027, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=4.95412, coef0=1.5714, degree=3, Balanced Accuracy: 0.473\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100.36571, gamma=0.00993, Balanced Accuracy: 0.475\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=98.23141, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=95.57732, gamma=0.0103, Balanced Accuracy: 0.475\n",
            "Params: C=101.25, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "Params: C=86.49955, gamma=0.01056, Balanced Accuracy: 0.475\n",
            "--- Generation 71 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.95922, coef0=1.62338, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.96737, coef0=1.60001, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.95108, coef0=1.73, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.94294, coef0=1.795, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.65684, coef0=1.79552, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=5.20721, coef0=1.35153, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=5.05189, coef0=1.34625, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.6978, coef0=1.45027, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100.36571, gamma=0.00993, Balanced Accuracy: 0.475\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=98.23141, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=99.29856, gamma=0.00995, Balanced Accuracy: 0.475\n",
            "Params: C=95.57732, gamma=0.0103, Balanced Accuracy: 0.475\n",
            "Params: C=101.25, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "--- Generation 72 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.95922, coef0=1.62338, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.96737, coef0=1.60001, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.95108, coef0=1.73, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.94294, coef0=1.795, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.65684, coef0=1.79552, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=5.20721, coef0=1.35153, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=5.05189, coef0=1.34625, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.6978, coef0=1.45027, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=100.36571, gamma=0.00993, Balanced Accuracy: 0.475\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=98.23141, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=99.29856, gamma=0.00995, Balanced Accuracy: 0.475\n",
            "Params: C=95.57732, gamma=0.0103, Balanced Accuracy: 0.475\n",
            "Params: C=101.25, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=90.78893, gamma=0.01016, Balanced Accuracy: 0.475\n",
            "--- Generation 73 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.95922, coef0=1.62338, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.96737, coef0=1.60001, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.95108, coef0=1.73, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.94294, coef0=1.795, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.65684, coef0=1.79552, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=5.20721, coef0=1.35153, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=5.05189, coef0=1.34625, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.6978, coef0=1.45027, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=97.67828, gamma=0.01015, Balanced Accuracy: 0.475\n",
            "Params: C=100.36571, gamma=0.00993, Balanced Accuracy: 0.475\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=98.23141, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=99.29856, gamma=0.00995, Balanced Accuracy: 0.475\n",
            "Params: C=95.57732, gamma=0.0103, Balanced Accuracy: 0.475\n",
            "Params: C=101.25, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "--- Generation 74 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.95922, coef0=1.62338, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.96737, coef0=1.60001, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.95108, coef0=1.73, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.94294, coef0=1.795, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.65684, coef0=1.79552, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=5.20721, coef0=1.35153, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=5.05189, coef0=1.34625, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.6978, coef0=1.45027, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=97.67828, gamma=0.01015, Balanced Accuracy: 0.475\n",
            "Params: C=100.36571, gamma=0.00993, Balanced Accuracy: 0.475\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=98.23141, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=99.29856, gamma=0.00995, Balanced Accuracy: 0.475\n",
            "Params: C=95.57732, gamma=0.0103, Balanced Accuracy: 0.475\n",
            "Params: C=101.25, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "--- Generation 75 ---\n",
            "Processing poly models...\n",
            "Training models for kernel: poly\n",
            "Updated poly population with new children:\n",
            "Params: C=3.95922, coef0=1.62338, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.96737, coef0=1.60001, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.95108, coef0=1.73, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.94294, coef0=1.795, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.65684, coef0=1.79552, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=5.20721, coef0=1.35153, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=5.05189, coef0=1.34625, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.6978, coef0=1.45027, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Processing rbf models...\n",
            "Training models for kernel: rbf\n",
            "Updated rbf population with new children:\n",
            "Params: C=97.67828, gamma=0.01015, Balanced Accuracy: 0.475\n",
            "Params: C=100.36571, gamma=0.00993, Balanced Accuracy: 0.475\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=98.23141, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=99.29856, gamma=0.00995, Balanced Accuracy: 0.475\n",
            "Params: C=95.57732, gamma=0.0103, Balanced Accuracy: 0.475\n",
            "Params: C=101.25, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Final results after 75 generations:\n",
            "Top results for poly kernel:\n",
            "Params: C=3.95922, coef0=1.62338, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.96737, coef0=1.60001, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.95108, coef0=1.73, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.94294, coef0=1.795, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.65684, coef0=1.79552, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=5.20721, coef0=1.35153, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=5.05189, coef0=1.34625, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=3.93479, coef0=1.86, degree=3, Balanced Accuracy: 0.474\n",
            "Params: C=4.6978, coef0=1.45027, degree=3, Balanced Accuracy: 0.473\n",
            "Params: C=3.15378, coef0=2.37686, degree=3, Balanced Accuracy: 0.473\n",
            "Top results for rbf kernel:\n",
            "Params: C=97.67828, gamma=0.01015, Balanced Accuracy: 0.475\n",
            "Params: C=100.36571, gamma=0.00993, Balanced Accuracy: 0.475\n",
            "Params: C=96.46282, gamma=0.01008, Balanced Accuracy: 0.475\n",
            "Params: C=98.23141, gamma=0.00998, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00988, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.00994, Balanced Accuracy: 0.475\n",
            "Params: C=100, gamma=0.01, Balanced Accuracy: 0.475\n",
            "Params: C=99.29856, gamma=0.00995, Balanced Accuracy: 0.475\n",
            "Params: C=95.57732, gamma=0.0103, Balanced Accuracy: 0.475\n",
            "Params: C=101.25, gamma=0.00994, Balanced Accuracy: 0.475\n"
          ]
        }
      ],
      "source": [
        "#FIX RUN GENETIC ALGORITHM METHOD\n",
        "#Fix tol in model_train method - just for poly\n",
        "\n",
        "X_train, X_discard, y_train, y_discard = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=0.98, random_state=5, stratify=y_train_full)\n",
        "\n",
        "pca = PCA(n_components=31)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_val_pca = pca.transform(X_val)\n",
        "\n",
        "# Both starting param_grids based off of what was successful in experiments farther above.\n",
        "rbf_param_grid = {\n",
        "    'C': [10, 40, 70, 100],\n",
        "    'gamma': ['scale', 'auto', 0.01, 0.025, 0.05],\n",
        "    'kernel': ['rbf'],\n",
        "    'class_weight': ['balanced']\n",
        "}\n",
        "\n",
        "poly_param_grid = {\n",
        "    'C': [0.3, 1, 10, 30],\n",
        "    'coef0': [1.0, 7.0, 15.0],\n",
        "    'degree': [3, 4],\n",
        "    'kernel': ['poly'],\n",
        "    'class_weight': ['balanced']\n",
        "}\n",
        "\n",
        "# # Dummy grid - for use when we wanted to focus on running code for just one of the kernel types\n",
        "# rbf_param_grid = {\n",
        "#     'C': [1],\n",
        "#     'gamma': [0.01],\n",
        "#     'kernel': ['rbf'],\n",
        "#     'class_weight': ['balanced']\n",
        "# }\n",
        "\n",
        "# # Dummy grid\n",
        "# poly_param_grid = {\n",
        "#     'C': [0.001],\n",
        "#     'coef0': [0.0],\n",
        "#     'degree': [2],\n",
        "#     'kernel': ['poly'],\n",
        "#     'class_weight': ['balanced']\n",
        "# }\n",
        "\n",
        "# Create an individual for each hyperparameter permutation\n",
        "def generate_population(rbf_param_grid, poly_param_grid):\n",
        "    populations = {'poly': [], 'rbf': []}\n",
        "\n",
        "    for params in ParameterGrid(rbf_param_grid):\n",
        "        populations['rbf'].append(params)\n",
        "\n",
        "    for params in ParameterGrid(poly_param_grid):\n",
        "        populations['poly'].append(params)\n",
        "\n",
        "    return populations\n",
        "\n",
        "# Does exactly what the names says\n",
        "def train_evaluate_single_model(params):\n",
        "    start_time = time.time()\n",
        "    model = svm.SVC(**params)\n",
        "    model.fit(X_train_pca, y_train)\n",
        "    y_pred = model.predict(X_val_pca)\n",
        "    balanced_acc = balanced_accuracy_score(y_val, y_pred)\n",
        "    return {'params': params, 'balanced_accuracy': balanced_acc}\n",
        "\n",
        "# This was an addition we made unfortunately quite late in the project timeline that helped\n",
        "# greatly speed up processing time by parallelizing the model training.\n",
        "def train_and_evaluate_models(populations):\n",
        "    kernel_results = {}\n",
        "    for kernel_type, param_list in populations.items():\n",
        "        print(f\"Training models for kernel: {kernel_type}\")\n",
        "        num_cores = multiprocessing.cpu_count() - 2\n",
        "        results = Parallel(n_jobs=num_cores)(delayed(train_evaluate_single_model)(\n",
        "            params) for params in param_list)\n",
        "        sorted_results = sorted(results, key=lambda x: x['balanced_accuracy'], reverse=True)\n",
        "        kernel_results[kernel_type] = sorted_results\n",
        "    return kernel_results\n",
        "\n",
        "# Simply generates a random permutation from the starting grids\n",
        "def generate_random_individual(kernel_type, param_grids):\n",
        "    params = param_grids[kernel_type]\n",
        "    if kernel_type == 'rbf':\n",
        "        return {\n",
        "            'kernel': 'rbf',\n",
        "            'C': random.choice(params['C']),\n",
        "            'gamma': random.choice(params['gamma']),\n",
        "            'class_weight': 'balanced'\n",
        "        }\n",
        "    elif kernel_type == 'poly':\n",
        "        return {\n",
        "            'kernel': 'poly',\n",
        "            'C': random.choice(params['C']),\n",
        "            'coef0': random.choice(params['coef0']),\n",
        "            'degree': random.choice(params['degree']),\n",
        "            'class_weight': 'balanced'\n",
        "        }\n",
        "\n",
        "# How we selected the, generally, best models from the population with room for variation\n",
        "def select_parents(sorted_parents):\n",
        "    fraction_to_pick = 0.25\n",
        "    num_parents_to_select = int(len(sorted_parents) * fraction_to_pick)\n",
        "    selected_parents = []\n",
        "    selection_probability = 0.85\n",
        "\n",
        "    # The best hyperparameter combos have a high, but not guaranteed chance to be\n",
        "    # picked for parents of the next generation. Still chance for less optimal\n",
        "    # parameters to be picked for the sake of diversity.\n",
        "    for parent in sorted_parents:\n",
        "        if len(selected_parents) < num_parents_to_select:\n",
        "            if np.random.rand() < selection_probability:\n",
        "                selected_parents.append(parent['params'])\n",
        "                selection_probability *= 0.85\n",
        "                if selection_probability < 0.05:\n",
        "                    selection_probability = 0.05\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    # Generate a random individual based on the kernel type\n",
        "    # Ensures there will always be some diversity in parent pool if it becomes filled\n",
        "    # with too many variations on the same local optima configuration.\n",
        "    kernel_type = sorted_parents[0]['params']['kernel']\n",
        "    random_individual = generate_random_individual(kernel_type, param_grids)\n",
        "\n",
        "    # Ensure we have even number of parents to pair off\n",
        "    if len(selected_parents) % 2 == 0:\n",
        "        selected_parents[-1] = random_individual\n",
        "    else:\n",
        "        selected_parents.append(random_individual)\n",
        "\n",
        "    return selected_parents\n",
        "\n",
        "\n",
        "# Creates a child combination made from the elements of its parents hyperparameters\n",
        "def poly_crossover(parents):\n",
        "    children = []\n",
        "    for i in range(0, len(parents), 2):\n",
        "        parent1 = parents[i]\n",
        "        parent2 = parents[i + 1] if i + 1 < len(parents) else parents[0]\n",
        "\n",
        "        child_params = {\n",
        "            'C': (parent1['C'] + parent2['C']) / 2,\n",
        "            'coef0': (parent1['coef0'] + parent2['coef0']) / 2,\n",
        "            'degree': random.choice([parent1['degree'], parent2['degree']]),\n",
        "            'kernel': 'poly',\n",
        "            'class_weight': 'balanced'\n",
        "        }\n",
        "        children.append({'params': child_params})\n",
        "    return children\n",
        "\n",
        "\n",
        "# Both mutate functions feature \"common\" mutations that mutate hyperparamaters very slightly, a set of more\n",
        "# extreme mutations that are more rare but affect the values even more, and finally the most rare but most\n",
        "# extreme mutations that cause very large jumps in values.\n",
        "def poly_mutate(children):\n",
        "    for child in children:\n",
        "        # Common but minor mutations\n",
        "        if random.random() < 0.6:\n",
        "            new_c = child['params']['C'] * (1 + 0.025 * random.choice([-1, 1]))\n",
        "            child['params']['C'] = min(new_c, 50)\n",
        "        if random.random() < 0.6:\n",
        "            new_coef0 = child['params']['coef0'] * (1 + 0.025 * random.choice([-1, 1]))\n",
        "            child['params']['coef0'] = min(new_coef0, 20)\n",
        "        if random.random() < 0.3:\n",
        "            new_degree = max(2, min(6, child['params']['degree'] + random.choice([-1, 1])))\n",
        "            child['params']['degree'] = new_degree\n",
        "\n",
        "        # Moderate mutations - more rare\n",
        "        if random.random() < 0.3:\n",
        "            new_c = child['params']['C'] * (1 + 0.25 * random.choice([-1, 1]))\n",
        "            child['params']['C'] = min(new_c, 50)\n",
        "        if random.random() < 0.3:\n",
        "            new_coef0 = child['params']['coef0'] * (1 + 0.25 * random.choice([-1, 1]))\n",
        "            child['params']['coef0'] = min(new_coef0, 20)\n",
        "        if random.random() < 0.15:\n",
        "            new_degree = max(2, min(6, child['params']['degree'] + random.choice([-2, 2])))\n",
        "            child['params']['degree'] = new_degree\n",
        "        if random.random() < 0.15:\n",
        "            new_c = child['params']['C'] + 5\n",
        "            child['params']['C'] = min(new_c, 50)\n",
        "\n",
        "        # Extreme mutations - most rare\n",
        "        if random.random() < 0.15:\n",
        "            new_c = child['params']['C'] * (1 + 0.67 * random.choice([-1, 1]))\n",
        "            child['params']['C'] = min(new_c, 50)  # Cap C\n",
        "        if random.random() < 0.15:\n",
        "            new_coef0 = child['params']['coef0'] * (1 + 0.67 * random.choice([-1, 1]))\n",
        "            child['params']['coef0'] = min(new_coef0, 20)\n",
        "\n",
        "        child['params']['class_weight'] = 'balanced'\n",
        "\n",
        "    return children\n",
        "\n",
        "# Creates a child combination made from the elements of its parents hyperparameters\n",
        "def rbf_crossover(parents):\n",
        "    children = []\n",
        "    for i in range(0, len(parents), 2):\n",
        "        parent1 = parents[i]\n",
        "        parent2 = parents[i+1] if i+1 < len(parents) else parents[0]\n",
        "\n",
        "        if isinstance(parent1['gamma'], str) or isinstance(parent2['gamma'], str):\n",
        "            gamma_value = random.choice([parent1['gamma'], parent2['gamma']])\n",
        "        else:\n",
        "            gamma_value = (parent1['gamma'] + parent2['gamma']) / 2\n",
        "\n",
        "        child_params = {\n",
        "            'C': (parent1['C'] + parent2['C']) / 2,\n",
        "            'gamma': gamma_value,\n",
        "            'kernel': 'rbf',\n",
        "            'class_weight': 'balanced'\n",
        "        }\n",
        "        children.append({'params': child_params})\n",
        "    return children\n",
        "\n",
        "# Both mutate functions feature \"common\" mutations that mutate hyperparamaters very slightly, a set of more\n",
        "# extreme mutations that are more rare but affect the values even more, and finally the most rare but most\n",
        "# extreme mutations that cause very large jumps in values.\n",
        "def rbf_mutate(children):\n",
        "    for child in children:\n",
        "        # Common but minor mutations\n",
        "        if random.random() < 0.6:\n",
        "            new_c = child['params']['C'] * (1 + 0.025 * random.choice([-1, 1]))\n",
        "            child['params']['C'] = min(new_c, 150)\n",
        "        if random.random() < 0.6:\n",
        "            if isinstance(child['params']['gamma'], str) and child['params']['gamma'] in ['scale', 'auto']:\n",
        "                child['params']['gamma'] = 'auto' if child['params']['gamma'] == 'scale' else 'scale'\n",
        "            else:\n",
        "                child['params']['gamma'] = float(child['params']['gamma']) * (1 + 0.025 * random.choice([-1, 1]))\n",
        "\n",
        "        # Moderate mutations - more rare\n",
        "        if random.random() < 0.3:\n",
        "            new_c = child['params']['C'] * (1 + 0.25 * random.choice([-1, 1]))\n",
        "            child['params']['C'] = min(new_c, 150)\n",
        "        if random.random() < 0.3:\n",
        "            if isinstance(child['params']['gamma'], str) and child['params']['gamma'] in ['scale', 'auto']:\n",
        "                child['params']['gamma'] = 'auto' if child['params']['gamma'] == 'scale' else 'scale'\n",
        "            else:\n",
        "                child['params']['gamma'] = float(child['params']['gamma']) * (1 + 0.25 * random.choice([-1, 1]))\n",
        "\n",
        "        # Extreme mutations - most rare\n",
        "        if random.random() < 0.15:\n",
        "            new_c = child['params']['C'] * (1 + 0.67 * random.choice([-1, 1]))\n",
        "            child['params']['C'] = min(new_c, 150)\n",
        "        if random.random() < 0.15:\n",
        "            if isinstance(child['params']['gamma'], str) and child['params']['gamma'] in ['scale', 'auto']:\n",
        "                child['params']['gamma'] = 'auto' if child['params']['gamma'] == 'scale' else 'scale'\n",
        "            else:\n",
        "                child['params']['gamma'] = float(child['params']['gamma']) * (1 + 0.67 * random.choice([-1, 1]))\n",
        "\n",
        "        if isinstance(child['params']['gamma'], float) and random.random() < 0.2:\n",
        "            child['params']['gamma'] = random.choice(['auto', 'scale'])\n",
        "        if isinstance(child['params']['gamma'], str) and random.random() < 0.2:\n",
        "            child['params']['gamma'] = random.choice([0.01, 0.025, 0.05])\n",
        "\n",
        "        child['params']['class_weight'] = 'balanced'\n",
        "\n",
        "    return children\n",
        "\n",
        "# Below is the function that ensures new children being added to population are unique combinations of\n",
        "# hyperparameters before training the models and then combining the children with the general population\n",
        "# and removing the weakest contenders from the pool to maintain a constant population.\n",
        "def integrate_children(kernel_type, full_population, children):\n",
        "    # Adds one direct variation of the current best build to the new child pool\n",
        "    best_individual = full_population[0]['params']\n",
        "    if kernel_type == 'poly':\n",
        "        variation = create_variation_poly(best_individual)\n",
        "    else:\n",
        "        variation = create_variation_rbf(best_individual)\n",
        "    children.append({'params': variation})\n",
        "\n",
        "    # Filters/mutates children - ensures no duplicate build is being trained in next step\n",
        "    existing_configs = set(json.dumps(child['params'], sort_keys=True) for child in full_population)\n",
        "    unique_children = []\n",
        "    for child in children:\n",
        "        child_config_str = json.dumps(child['params'], sort_keys=True)\n",
        "        while child_config_str in existing_configs:\n",
        "            child = poly_mutate([child])[0] if kernel_type == 'poly' else rbf_mutate([child])[0]\n",
        "            child_config_str = json.dumps(child['params'], sort_keys=True)\n",
        "        unique_children.append(child)\n",
        "        existing_configs.add(child_config_str)\n",
        "\n",
        "    # Train/evaluate new children, add to current population, remove worst performing\n",
        "    # individuals from population to maintain constant population size\n",
        "    evaluated_children = train_and_evaluate_models({kernel_type: [child['params'] for child in unique_children]})\n",
        "    combined_population = full_population + evaluated_children[kernel_type]\n",
        "    combined_population.sort(key=lambda x: x['balanced_accuracy'], reverse=True)\n",
        "    new_population = combined_population[:len(full_population)]\n",
        "    return new_population\n",
        "\n",
        "# Below is our function for updating our json file with the results of each generation\n",
        "save_path = 'Genetic_Algo_Results_throwaway.json'  # Adjust path as necessary\n",
        "def update_results_file(kernel_results, generation):\n",
        "    if not os.path.exists(save_path):\n",
        "        with open(save_path, 'w') as file:\n",
        "            json.dump([], file)\n",
        "\n",
        "    with open(save_path, 'r+') as file:\n",
        "        file.seek(0)\n",
        "        existing_data = json.load(file)\n",
        "        existing_data.append({\n",
        "            'generation': generation,\n",
        "            'results': kernel_results\n",
        "        })\n",
        "        file.seek(0)\n",
        "        file.truncate()\n",
        "        json.dump(existing_data, file, indent=4)\n",
        "\n",
        "# Below is just a short function to make the output prints less visually cluttered.\n",
        "def format_params(params):\n",
        "    filtered_params = {param_key: param_value for param_key, param_value in params.items() if param_key not in ['class_weight', 'kernel']}\n",
        "\n",
        "    def format_value(val):\n",
        "        if isinstance(val, float):\n",
        "            return f\"{val:.5f}\".rstrip('0').rstrip('.')\n",
        "        return val\n",
        "\n",
        "    return ', '.join(f\"{key}={format_value(value)}\" for key, value in filtered_params.items())\n",
        "\n",
        "# Both of these create_variation functions create a variation of the best individual in their respective\n",
        "# populations. This is called once per population per generation and each time it's called, its mutation\n",
        "# rate is increasd a bit further.\n",
        "def create_variation_rbf(best_individual):\n",
        "    global mutation_rate_rbf\n",
        "    new_individual = best_individual.copy()\n",
        "    new_c = new_individual['C'] * (1 + mutation_rate_rbf * random.choice([-1, 1]))\n",
        "    new_individual['C'] = min(new_c, 150)\n",
        "    if isinstance(new_individual['gamma'], float):\n",
        "        new_individual['gamma'] *= (1 + mutation_rate_rbf * random.choice([-1, 1]))\n",
        "    elif isinstance(new_individual['gamma'], str):\n",
        "        new_individual['gamma'] = 'auto' if new_individual['gamma'] == 'scale' else 'scale'\n",
        "    mutation_rate_rbf += 0.00667\n",
        "    return new_individual\n",
        "\n",
        "def create_variation_poly(best_individual):\n",
        "    global mutation_rate_poly\n",
        "    new_individual = best_individual.copy()\n",
        "    new_c = new_individual['C'] * (1 + mutation_rate_poly * random.choice([-1, 1]))\n",
        "    new_individual['C'] = min(new_c, 50)\n",
        "    new_coef0 = new_individual['coef0'] * (1 + mutation_rate_poly * random.choice([-1, 1]))\n",
        "    new_individual['coef0'] = min(new_coef0, 20)\n",
        "    degree_change = random.choice([-1, 0, 1])\n",
        "    new_individual['degree'] = max(2, new_individual['degree'] + degree_change)\n",
        "    mutation_rate_poly += 0.00667\n",
        "    return new_individual\n",
        "\n",
        "\n",
        "# The core function that ties it all together and runs through the training and evolution process.\n",
        "def run_genetic_algorithm(generations, initial_populations):\n",
        "    kernel_results = train_and_evaluate_models(initial_populations)\n",
        "    for generation in range(1, generations + 1):\n",
        "        print(f\"--- Generation {generation} ---\")\n",
        "        for kernel_type in ['poly', 'rbf']:\n",
        "            print(f\"Processing {kernel_type} models...\")\n",
        "            if kernel_type == 'poly':\n",
        "                selected_parents = select_parents(kernel_results[kernel_type])\n",
        "                random.shuffle(selected_parents)\n",
        "                children = poly_crossover(selected_parents)\n",
        "                mutated_children = poly_mutate(children)\n",
        "            elif kernel_type == 'rbf':\n",
        "                selected_parents = select_parents(kernel_results[kernel_type])\n",
        "                random.shuffle(selected_parents)\n",
        "                children = rbf_crossover(selected_parents)\n",
        "                mutated_children = rbf_mutate(children)\n",
        "\n",
        "            kernel_results[kernel_type] = integrate_children(kernel_type, kernel_results[kernel_type], mutated_children)\n",
        "            update_results_file(kernel_results, generation)\n",
        "\n",
        "            print(f\"Updated {kernel_type} population with new children:\")\n",
        "            for model in kernel_results[kernel_type][:10]:  # Show top 10\n",
        "                formatted_params = format_params(model['params'])\n",
        "                print(f\"Params: {formatted_params}, Balanced Accuracy: {model['balanced_accuracy']:.3f}\")\n",
        "\n",
        "    return kernel_results\n",
        "\n",
        "\n",
        "GENERATIONS = 75\n",
        "mutation_rate_rbf = .35\n",
        "mutation_rate_poly = .35\n",
        "\n",
        "param_grids = {'rbf': rbf_param_grid, 'poly': poly_param_grid}\n",
        "initial_populations = generate_population(rbf_param_grid, poly_param_grid)\n",
        "final_results = run_genetic_algorithm(GENERATIONS, initial_populations)\n",
        "\n",
        "print(f\"Final results after {GENERATIONS} generations:\")\n",
        "for kernel_type, results in final_results.items():\n",
        "    print(f\"Top results for {kernel_type} kernel:\")\n",
        "    for result in results[:10]:  # Show top 10\n",
        "        formatted_params = format_params(result['params'])\n",
        "        print(f\"Params: {formatted_params}, Balanced Accuracy: {result['balanced_accuracy']:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsOnRtMYdJKn"
      },
      "source": [
        "Before we go into the final results, we need to discuss the litany of changes that were required to give us a more robust output. Many rapid fire tests with 1-2% of the population were done until we started seeing some more promising results. One problem from the very start was that the population soon became a bunch of near clones of the top models with essentially no progress being made in improving accuracy. Fighting these stagnant, barely varied top results was a constant throughout the refinement process. Mutation rates for children began as low as 3-4% and when they would trigger, they would only changing values by 5%. While these were good for fine tuning some numbers, they were far too infrequent to meaningfully affect the population and the combinations of parents' values during crossover was apparently not performing too well the majority of the time so there was not a very wide diversity of individuals beyond the starting top models.\n",
        "\n",
        "One of the first changes we made was bumping the mutation rates up to 10-20% and we started seeing some very small but positive gains to the top accuracy of the best models and we started to see a bit more diversity. We made it so no duplicate of parameters already in the population could be added to the population as that wasn't really helping and was something we should have done from the start. Still saw many very similar models at the top of the list at this point so we also made sure to add one randomly generated set of parameters to the parents list every time those were being picked. This would ensure that even if the majority of the population started settling into a local optima, there would always be a chance for a parent with vastly different hyperparameters to mix things up. We also started shuffling the parents before crossover to encourage more diversity otherwise the top 3-4 models would just keep having a large portion of the same children over and over.\n",
        "\n",
        "Variety was increasing but the top models kept looking too similar to each other as soon as perhaps 15-30 generations had passed and the rest of the generations would generate no meanginful gain or differences. We decided to crank the mutation rate into high gear at this point. Instead of one 10-20% set of mutations that affected parameters by 5%, we decided to split mutations into 3 categories. 1. Common - Now a 60% chance for most parameters to be shifted by 2.5%. This would help fine tune good parameters to find their local optima. 2. Moderate - 30% chance for most parameters to shift by 25%. Both this category and the next were about helping the algorithm generate changes that could hopefully break free of local optima values and start exploring new spaces. 3. Extreme - 15% chance for most parameters to shift by 67%. There is some more minutae to the details of how the mutation happens if you wish to look further into the rbf_mutate() or poly_mutate() code but this gives you the general idea of our changes to mutation rates and the reasoning for them.\n",
        "\n",
        "This again gave small gains and definitely lent itself to some more diversity but there was one last change we made that finally propelled this section of code into a state we were happy with. This was the addition of the create_variation_rbf/poly functions which, in addition to the children already being created each generation, would add one additional child to the pool and that individual would be based off of the parameters of the very best model in each respective population. At first, these variation functions would just randomly alter each hyperparameter by 5% and they were meant as an augmented way of ensuring that the top model got fine tuned since it was the most promising. However, we found that the variations of the top model would settle on wherever they were going to generally land quite quickly (usually no later than generation 20) so eventually these functions were just creating extra model training time for not really much benefit. Instead of deactivating them after X generations, we wondered what would happen if we had them augment the percentage that they changed the numbers every time the function was called. This way, we could still fine tune the model in the early generations and once that purpose was served, they would serve as yet another way to explore values that could hopefully move beyond local optima. We eventually landed on the starting mutation values being boosted up to 35% instead of 5% and each generation of 75 would add an additional 0.667% to that 35% eventually landing at 85% in the last generation. With these values, our tests with low percentage of the total dataset would generate and retain a high diversity of different hyperparameter combinations that would stick around in the top models many generations later than all tests before. Prior to this last addition, most runs would settle into a state where all the top 10 models are just very small variations of each other usually within the first 20-30 generations. With these new numbers, there's usually at least 2 or 3 distinct variations in the top 10 population for the majority of the run and definitely 2 or 3 throughout the full population by the end.\n",
        "\n",
        "At this point, we were much more pleased with the results as they seemed to suggest we were more fully exploring all the options and no longer just immediately falling into the closest local optima. Additionally, we wanted to see this diversity in hyperparameter combinations because at the end of all of this, we want to use sklearn.ensemble's VotingClassifier to see if we can squeeze just a little bit more accuracy out of all the hyperparameter combos we worked so hard to find."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBcnSEsm6mPi"
      },
      "source": [
        "Below we have the results from running the genetic algorithm above using 50% of the training data, 31 PCs, focusing on only 'rbf' kernels (please ignore the lone, garbage poly kernel). You can see the top model of the final generation only has a 0.1% increase over the original which is unfortunately, not hugely impressive. However, we can see that all models in the population now beat everying in generation 1 except some ties with the original 1st place model. In fact, as early as generation 8, we already have a large variety of models that are all within just a 0.3% max difference in terms of accuracy when compared to our final model. It is this diversity that we want to leverage for our final ensemble vote and although we definitely want to pick some representatives from our fittest generation 75, we were open to trying models anywhere between generation 8-75 for the sake of rounding out the diversity in our ensemble vote and since they were all so close in performance. We will show the hyperparameter combinations we chose further down with the VotingClassifier code.\n",
        "\n",
        "I have edited the print code below to only show the first 10 generations (since that's when the most changes occur) and then only every 5th generation after that to make for easier browsing to get a quick idea of how hyperparameters were changing. If you would like to see the entire printout, just comment out the line starting with \"if generation < 10\" and shift-tab everything below it once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie-3jSGp6mkS",
        "outputId": "e15f2389-98b4-4d23-bdce-043d0f3e3bb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generation 1 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=0.001, coef0=0, degree=2, Balanced Accuracy: 0.340\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=40, gamma=0.025, Balanced Accuracy: 0.643\n",
            "Params: C=38, gamma=0.02375, Balanced Accuracy: 0.642\n",
            "Params: C=40, gamma=scale, Balanced Accuracy: 0.642\n",
            "Params: C=100, gamma=0.025, Balanced Accuracy: 0.641\n",
            "Params: C=70, gamma=scale, Balanced Accuracy: 0.641\n",
            "Params: C=100, gamma=scale, Balanced Accuracy: 0.641\n",
            "Params: C=40, gamma=auto, Balanced Accuracy: 0.640\n",
            "Params: C=85.3125, gamma=0.0321, Balanced Accuracy: 0.639\n",
            "Params: C=70, gamma=0.025, Balanced Accuracy: 0.639\n",
            "Params: C=71.75, gamma=auto, Balanced Accuracy: 0.639\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 2 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=0.001, coef0=0, degree=2, Balanced Accuracy: 0.340\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=40, gamma=0.025, Balanced Accuracy: 0.643\n",
            "Params: C=37.7332, gamma=0.02642, Balanced Accuracy: 0.642\n",
            "Params: C=38, gamma=0.02375, Balanced Accuracy: 0.642\n",
            "Params: C=40, gamma=scale, Balanced Accuracy: 0.642\n",
            "Params: C=100, gamma=0.025, Balanced Accuracy: 0.641\n",
            "Params: C=70, gamma=scale, Balanced Accuracy: 0.641\n",
            "Params: C=100, gamma=scale, Balanced Accuracy: 0.641\n",
            "Params: C=40, gamma=auto, Balanced Accuracy: 0.640\n",
            "Params: C=55, gamma=0.02188, Balanced Accuracy: 0.640\n",
            "Params: C=85.3125, gamma=0.0321, Balanced Accuracy: 0.639\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 3 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=0.001, coef0=0, degree=2, Balanced Accuracy: 0.340\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=40, gamma=0.025, Balanced Accuracy: 0.643\n",
            "Params: C=37.7332, gamma=0.02642, Balanced Accuracy: 0.642\n",
            "Params: C=38, gamma=0.02375, Balanced Accuracy: 0.642\n",
            "Params: C=40, gamma=scale, Balanced Accuracy: 0.642\n",
            "Params: C=100, gamma=0.025, Balanced Accuracy: 0.641\n",
            "Params: C=37.4664, gamma=0.02342, Balanced Accuracy: 0.641\n",
            "Params: C=70, gamma=scale, Balanced Accuracy: 0.641\n",
            "Params: C=100, gamma=scale, Balanced Accuracy: 0.641\n",
            "Params: C=40, gamma=auto, Balanced Accuracy: 0.640\n",
            "Params: C=55.35, gamma=auto, Balanced Accuracy: 0.640\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 4 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=0.001, coef0=0, degree=2, Balanced Accuracy: 0.340\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=40, gamma=0.025, Balanced Accuracy: 0.643\n",
            "Params: C=37.76487, gamma=scale, Balanced Accuracy: 0.642\n",
            "Params: C=37.7332, gamma=0.02642, Balanced Accuracy: 0.642\n",
            "Params: C=38, gamma=0.02375, Balanced Accuracy: 0.642\n",
            "Params: C=37.89493, gamma=0.02642, Balanced Accuracy: 0.642\n",
            "Params: C=40, gamma=scale, Balanced Accuracy: 0.642\n",
            "Params: C=42.8004, gamma=0.02325, Balanced Accuracy: 0.642\n",
            "Params: C=100, gamma=0.025, Balanced Accuracy: 0.641\n",
            "Params: C=37.4664, gamma=0.02342, Balanced Accuracy: 0.641\n",
            "Params: C=70, gamma=scale, Balanced Accuracy: 0.641\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 5 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=0.001, coef0=0, degree=2, Balanced Accuracy: 0.340\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=40, gamma=0.025, Balanced Accuracy: 0.643\n",
            "Params: C=37.76487, gamma=scale, Balanced Accuracy: 0.642\n",
            "Params: C=37.7332, gamma=0.02642, Balanced Accuracy: 0.642\n",
            "Params: C=38, gamma=0.02375, Balanced Accuracy: 0.642\n",
            "Params: C=38.94747, gamma=0.02507, Balanced Accuracy: 0.642\n",
            "Params: C=37.89493, gamma=0.02642, Balanced Accuracy: 0.642\n",
            "Params: C=40, gamma=scale, Balanced Accuracy: 0.642\n",
            "Params: C=42.8004, gamma=0.02325, Balanced Accuracy: 0.642\n",
            "Params: C=100, gamma=0.025, Balanced Accuracy: 0.641\n",
            "Params: C=37.4664, gamma=0.02342, Balanced Accuracy: 0.641\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 6 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=0.001, coef0=0, degree=2, Balanced Accuracy: 0.340\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=40, gamma=0.025, Balanced Accuracy: 0.643\n",
            "Params: C=37.76487, gamma=scale, Balanced Accuracy: 0.642\n",
            "Params: C=37.7332, gamma=0.02642, Balanced Accuracy: 0.642\n",
            "Params: C=38, gamma=0.02375, Balanced Accuracy: 0.642\n",
            "Params: C=38.94747, gamma=0.02507, Balanced Accuracy: 0.642\n",
            "Params: C=29.98125, gamma=scale, Balanced Accuracy: 0.642\n",
            "Params: C=37.89493, gamma=0.02642, Balanced Accuracy: 0.642\n",
            "Params: C=40, gamma=scale, Balanced Accuracy: 0.642\n",
            "Params: C=42.8004, gamma=0.02325, Balanced Accuracy: 0.642\n",
            "Params: C=100, gamma=0.025, Balanced Accuracy: 0.641\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 7 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=0.001, coef0=0, degree=2, Balanced Accuracy: 0.340\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=39.43558, gamma=0.02502, Balanced Accuracy: 0.643\n",
            "Params: C=40, gamma=0.025, Balanced Accuracy: 0.643\n",
            "Params: C=37.76487, gamma=scale, Balanced Accuracy: 0.642\n",
            "Params: C=37.7332, gamma=0.02642, Balanced Accuracy: 0.642\n",
            "Params: C=38, gamma=0.02375, Balanced Accuracy: 0.642\n",
            "Params: C=38.94747, gamma=0.02507, Balanced Accuracy: 0.642\n",
            "Params: C=29.98125, gamma=scale, Balanced Accuracy: 0.642\n",
            "Params: C=37.89493, gamma=0.02642, Balanced Accuracy: 0.642\n",
            "Params: C=40, gamma=scale, Balanced Accuracy: 0.642\n",
            "Params: C=42.8004, gamma=0.02325, Balanced Accuracy: 0.642\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 8 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=0.001, coef0=0, degree=2, Balanced Accuracy: 0.340\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=39.43558, gamma=0.02502, Balanced Accuracy: 0.643\n",
            "Params: C=40, gamma=0.025, Balanced Accuracy: 0.643\n",
            "Params: C=37.76487, gamma=scale, Balanced Accuracy: 0.642\n",
            "Params: C=37.7332, gamma=0.02642, Balanced Accuracy: 0.642\n",
            "Params: C=38, gamma=0.02375, Balanced Accuracy: 0.642\n",
            "Params: C=38.94747, gamma=0.02507, Balanced Accuracy: 0.642\n",
            "Params: C=29.98125, gamma=scale, Balanced Accuracy: 0.642\n",
            "Params: C=37.89493, gamma=0.02642, Balanced Accuracy: 0.642\n",
            "Params: C=40, gamma=scale, Balanced Accuracy: 0.642\n",
            "Params: C=42.8004, gamma=0.02325, Balanced Accuracy: 0.642\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 9 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=0.001, coef0=0, degree=2, Balanced Accuracy: 0.340\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=39.43558, gamma=0.02502, Balanced Accuracy: 0.643\n",
            "Params: C=40, gamma=0.025, Balanced Accuracy: 0.643\n",
            "Params: C=37.76487, gamma=scale, Balanced Accuracy: 0.642\n",
            "Params: C=37.7332, gamma=0.02642, Balanced Accuracy: 0.642\n",
            "Params: C=38, gamma=0.02375, Balanced Accuracy: 0.642\n",
            "Params: C=38.94747, gamma=0.02507, Balanced Accuracy: 0.642\n",
            "Params: C=29.98125, gamma=scale, Balanced Accuracy: 0.642\n",
            "Params: C=67.73689, gamma=scale, Balanced Accuracy: 0.642\n",
            "Params: C=37.89493, gamma=0.02642, Balanced Accuracy: 0.642\n",
            "Params: C=40, gamma=scale, Balanced Accuracy: 0.642\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 10 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=0.001, coef0=0, degree=2, Balanced Accuracy: 0.340\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=39.43558, gamma=0.02502, Balanced Accuracy: 0.643\n",
            "Params: C=39.71779, gamma=0.02502, Balanced Accuracy: 0.643\n",
            "Params: C=40, gamma=0.025, Balanced Accuracy: 0.643\n",
            "Params: C=35.09648, gamma=0.02777, Balanced Accuracy: 0.642\n",
            "Params: C=37.76487, gamma=scale, Balanced Accuracy: 0.642\n",
            "Params: C=37.7332, gamma=0.02642, Balanced Accuracy: 0.642\n",
            "Params: C=38, gamma=0.02375, Balanced Accuracy: 0.642\n",
            "Params: C=38.94747, gamma=0.02507, Balanced Accuracy: 0.642\n",
            "Params: C=29.98125, gamma=scale, Balanced Accuracy: 0.642\n",
            "Params: C=67.73689, gamma=scale, Balanced Accuracy: 0.642\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 15 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=0.001, coef0=0, degree=2, Balanced Accuracy: 0.340\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=33.02623, gamma=scale, Balanced Accuracy: 0.643\n",
            "Params: C=39.43558, gamma=0.02502, Balanced Accuracy: 0.643\n",
            "Params: C=39.71779, gamma=0.02502, Balanced Accuracy: 0.643\n",
            "Params: C=40, gamma=0.025, Balanced Accuracy: 0.643\n",
            "Params: C=35.09648, gamma=0.02777, Balanced Accuracy: 0.642\n",
            "Params: C=37.76487, gamma=scale, Balanced Accuracy: 0.642\n",
            "Params: C=37.7332, gamma=0.02642, Balanced Accuracy: 0.642\n",
            "Params: C=38, gamma=0.02375, Balanced Accuracy: 0.642\n",
            "Params: C=38.94747, gamma=0.02507, Balanced Accuracy: 0.642\n",
            "Params: C=29.98125, gamma=scale, Balanced Accuracy: 0.642\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 20 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=0.001, coef0=0, degree=2, Balanced Accuracy: 0.340\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=33.02623, gamma=scale, Balanced Accuracy: 0.643\n",
            "Params: C=39.43558, gamma=0.02502, Balanced Accuracy: 0.643\n",
            "Params: C=39.71779, gamma=0.02502, Balanced Accuracy: 0.643\n",
            "Params: C=40, gamma=0.025, Balanced Accuracy: 0.643\n",
            "Params: C=35.09648, gamma=0.02777, Balanced Accuracy: 0.642\n",
            "Params: C=37.76487, gamma=scale, Balanced Accuracy: 0.642\n",
            "Params: C=37.7332, gamma=0.02642, Balanced Accuracy: 0.642\n",
            "Params: C=38, gamma=0.02375, Balanced Accuracy: 0.642\n",
            "Params: C=38.94747, gamma=0.02507, Balanced Accuracy: 0.642\n",
            "Params: C=36.60953, gamma=0.02708, Balanced Accuracy: 0.642\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 25 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=0.001, coef0=0, degree=2, Balanced Accuracy: 0.340\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=33.02623, gamma=scale, Balanced Accuracy: 0.643\n",
            "Params: C=39.43558, gamma=0.02502, Balanced Accuracy: 0.643\n",
            "Params: C=39.71779, gamma=0.02502, Balanced Accuracy: 0.643\n",
            "Params: C=40, gamma=0.025, Balanced Accuracy: 0.643\n",
            "Params: C=35.09648, gamma=0.02777, Balanced Accuracy: 0.642\n",
            "Params: C=37.76487, gamma=scale, Balanced Accuracy: 0.642\n",
            "Params: C=37.7332, gamma=0.02642, Balanced Accuracy: 0.642\n",
            "Params: C=38, gamma=0.02375, Balanced Accuracy: 0.642\n",
            "Params: C=38.94747, gamma=0.02507, Balanced Accuracy: 0.642\n",
            "Params: C=66.51312, gamma=scale, Balanced Accuracy: 0.642\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 30 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=0.001, coef0=0, degree=2, Balanced Accuracy: 0.340\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=33.90043, gamma=scale, Balanced Accuracy: 0.643\n",
            "Params: C=36.51312, gamma=0.02438, Balanced Accuracy: 0.643\n",
            "Params: C=33.02623, gamma=scale, Balanced Accuracy: 0.643\n",
            "Params: C=39.43558, gamma=0.02502, Balanced Accuracy: 0.643\n",
            "Params: C=39.71779, gamma=0.02502, Balanced Accuracy: 0.643\n",
            "Params: C=40, gamma=0.025, Balanced Accuracy: 0.643\n",
            "Params: C=35.8048, gamma=0.02705, Balanced Accuracy: 0.643\n",
            "Params: C=35.09648, gamma=0.02777, Balanced Accuracy: 0.642\n",
            "Params: C=37.76487, gamma=scale, Balanced Accuracy: 0.642\n",
            "Params: C=36.51312, gamma=0.025, Balanced Accuracy: 0.642\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 35 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=0.001, coef0=0, degree=2, Balanced Accuracy: 0.340\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=34.51066, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=33.90043, gamma=scale, Balanced Accuracy: 0.643\n",
            "Params: C=37.11423, gamma=0.025, Balanced Accuracy: 0.643\n",
            "Params: C=36.51312, gamma=0.02438, Balanced Accuracy: 0.643\n",
            "Params: C=33.02623, gamma=scale, Balanced Accuracy: 0.643\n",
            "Params: C=39.43558, gamma=0.02502, Balanced Accuracy: 0.643\n",
            "Params: C=39.71779, gamma=0.02502, Balanced Accuracy: 0.643\n",
            "Params: C=40, gamma=0.025, Balanced Accuracy: 0.643\n",
            "Params: C=35.8048, gamma=0.02705, Balanced Accuracy: 0.643\n",
            "Params: C=39.71779, gamma=0.02563, Balanced Accuracy: 0.643\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 40 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=0.001, coef0=0, degree=2, Balanced Accuracy: 0.340\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=34.51066, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=34.61266, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=33.90043, gamma=scale, Balanced Accuracy: 0.643\n",
            "Params: C=37.11423, gamma=0.025, Balanced Accuracy: 0.643\n",
            "Params: C=37.30014, gamma=0.02498, Balanced Accuracy: 0.643\n",
            "Params: C=36.51312, gamma=0.02438, Balanced Accuracy: 0.643\n",
            "Params: C=33.02623, gamma=scale, Balanced Accuracy: 0.643\n",
            "Params: C=39.43558, gamma=0.02502, Balanced Accuracy: 0.643\n",
            "Params: C=39.71779, gamma=0.02502, Balanced Accuracy: 0.643\n",
            "Params: C=40, gamma=0.025, Balanced Accuracy: 0.643\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 45 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=0.001, coef0=0, degree=2, Balanced Accuracy: 0.340\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=34.51066, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=34.61266, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=33.90043, gamma=scale, Balanced Accuracy: 0.643\n",
            "Params: C=37.11423, gamma=0.025, Balanced Accuracy: 0.643\n",
            "Params: C=37.30014, gamma=0.02498, Balanced Accuracy: 0.643\n",
            "Params: C=36.51312, gamma=0.02438, Balanced Accuracy: 0.643\n",
            "Params: C=33.02623, gamma=scale, Balanced Accuracy: 0.643\n",
            "Params: C=39.43558, gamma=0.02502, Balanced Accuracy: 0.643\n",
            "Params: C=39.71779, gamma=0.02502, Balanced Accuracy: 0.643\n",
            "Params: C=40, gamma=0.025, Balanced Accuracy: 0.643\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 50 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=0.001, coef0=0, degree=2, Balanced Accuracy: 0.340\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=33.81945, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=34.51066, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=34.61266, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=34.56166, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=33.90043, gamma=scale, Balanced Accuracy: 0.643\n",
            "Params: C=37.11423, gamma=0.025, Balanced Accuracy: 0.643\n",
            "Params: C=37.30014, gamma=0.02498, Balanced Accuracy: 0.643\n",
            "Params: C=36.51312, gamma=0.02438, Balanced Accuracy: 0.643\n",
            "Params: C=33.02623, gamma=scale, Balanced Accuracy: 0.643\n",
            "Params: C=39.43558, gamma=0.02502, Balanced Accuracy: 0.643\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 55 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=0.001, coef0=0, degree=2, Balanced Accuracy: 0.340\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=33.81945, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=34.51066, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=34.61266, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=34.56166, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=33.90043, gamma=scale, Balanced Accuracy: 0.643\n",
            "Params: C=37.11423, gamma=0.025, Balanced Accuracy: 0.643\n",
            "Params: C=37.30014, gamma=0.02498, Balanced Accuracy: 0.643\n",
            "Params: C=36.51312, gamma=0.02438, Balanced Accuracy: 0.643\n",
            "Params: C=33.36065, gamma=scale, Balanced Accuracy: 0.643\n",
            "Params: C=33.02623, gamma=scale, Balanced Accuracy: 0.643\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 60 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=0.001, coef0=0, degree=2, Balanced Accuracy: 0.340\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=33.81945, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=34.51066, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=34.61266, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=34.56166, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=33.90043, gamma=scale, Balanced Accuracy: 0.643\n",
            "Params: C=37.11423, gamma=0.025, Balanced Accuracy: 0.643\n",
            "Params: C=37.30014, gamma=0.02498, Balanced Accuracy: 0.643\n",
            "Params: C=36.51312, gamma=0.02438, Balanced Accuracy: 0.643\n",
            "Params: C=33.36065, gamma=scale, Balanced Accuracy: 0.643\n",
            "Params: C=33.02623, gamma=scale, Balanced Accuracy: 0.643\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 65 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=0.001, coef0=0, degree=2, Balanced Accuracy: 0.340\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=34.16505, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=33.81945, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=34.51066, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=34.61266, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=34.56166, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=33.90043, gamma=scale, Balanced Accuracy: 0.643\n",
            "Params: C=37.11423, gamma=0.025, Balanced Accuracy: 0.643\n",
            "Params: C=37.30014, gamma=0.02498, Balanced Accuracy: 0.643\n",
            "Params: C=36.51312, gamma=0.02438, Balanced Accuracy: 0.643\n",
            "Params: C=33.36065, gamma=scale, Balanced Accuracy: 0.643\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 70 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=0.001, coef0=0, degree=2, Balanced Accuracy: 0.340\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=34.16505, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=33.81945, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=34.51066, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=34.61266, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=34.56166, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=34.58716, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=33.90043, gamma=scale, Balanced Accuracy: 0.643\n",
            "Params: C=33.85994, gamma=scale, Balanced Accuracy: 0.643\n",
            "Params: C=37.11423, gamma=0.025, Balanced Accuracy: 0.643\n",
            "Params: C=37.30014, gamma=0.02498, Balanced Accuracy: 0.643\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 75 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=0.001, coef0=0, degree=2, Balanced Accuracy: 0.340\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=34.23105, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=34.16505, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=33.81945, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=34.51066, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=34.61266, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=34.56166, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=34.58716, gamma=scale, Balanced Accuracy: 0.644\n",
            "Params: C=33.90043, gamma=scale, Balanced Accuracy: 0.643\n",
            "Params: C=33.85994, gamma=scale, Balanced Accuracy: 0.643\n",
            "Params: C=37.11423, gamma=0.025, Balanced Accuracy: 0.643\n",
            "\n",
            "----------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "folder_path = '/content/drive/My Drive/Experimentation Results/'\n",
        "file_path = folder_path + 'Genetic_Algo_Results_rbf_half.json'\n",
        "with open(file_path, 'r') as file:\n",
        "    data = json.load(file)\n",
        "# The above is for the sake of getting some useful output saved to this document\n",
        "# by putting the documents in my google drive.\n",
        "# REMOVE BEFORE TURNING IN AS IT WON'T WORK FOR OTHERS\n",
        "# Json loading below should work fine provided we put the jsons in the\n",
        "# correct folder with the notebook before turning in. Must test.\n",
        "\n",
        "# with open('Genetic_Algo_Results_rbf_half.json', 'r') as file:\n",
        "#     data = json.load(file)\n",
        "\n",
        "# Repeat of format_params() function in the genetic algorithm - Didn't want to rerun whole GA algorithm to load this function on kernel restart.\n",
        "# Makes output significantly easier to visually digest.\n",
        "def format_params(params):\n",
        "    filtered_params = {param_key: param_value for param_key, param_value in params.items() if param_key not in ['class_weight', 'kernel']}\n",
        "\n",
        "    def format_value(val):\n",
        "        if isinstance(val, float):\n",
        "            return f\"{val:.5f}\".rstrip('0').rstrip('.')\n",
        "        return val\n",
        "\n",
        "    return ', '.join(f\"{key}={format_value(value)}\" for key, value in filtered_params.items())\n",
        "\n",
        "for entry in data:\n",
        "    generation = entry['generation']\n",
        "    results = entry['results']\n",
        "\n",
        "    if generation < 10 or generation % 5 == 0: # Comment out if you want full printout\n",
        "      print(f\"Generation {generation} results:\")\n",
        "\n",
        "      for kernel_type, models in results.items():\n",
        "          print(f\"\\nTop results for {kernel_type} kernel:\")\n",
        "          for model in models[:10]: # Remove [:10] if you want all models in each generation\n",
        "              formatted_params = format_params(model['params'])\n",
        "              balanced_accuracy = model['balanced_accuracy']\n",
        "              print(f\"Params: {formatted_params}, Balanced Accuracy: {balanced_accuracy:.3f}\")\n",
        "\n",
        "      print(\"\\n\" + \"-\"*40 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aWb-6W39uQ_"
      },
      "source": [
        "Below we have the results from the 15% of training data run for the poly kernels. Had to stop a run at 35 generations at one point, wrote some new code to resume the run and ended up overwriting the 35 gen run with useless test data. Already a bit pressed for time, we had to be satisfied with a 65 generation run for the printout below.\n",
        "\n",
        "Again, not a hugely impressive accuracy gain (0.2%) but the combinations of hyperparameters appear to be quite a bit more varied throughout the discovery process.\n",
        "\n",
        "We have included 2 additional files whose names are below. They were generated before we had the create_variation_rbf/poly() methods up and running and ran for 100 generations. The 2 files we have already preloaded and discussed basically arrive at similar, if not better, solutions but they do so quicker and with better accuracies. We have included them in case you are curious but also because we found just a few unique hyperparameter combinations that we will mention and use in the VotingClassifier section farther below and just wanted to include the data from which we got those combos. Also, a top 10 was copy-pasted from the overwritten 35th generation data before it was lost and there was one combination of hyperparameters we did salvage from that so we included that as well.\n",
        "\n",
        "Backup_Genetic_Algo_Results_rbf_half.json  \n",
        "Backup_Genetic_Algo_Results_10_percent.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hE25pzC9ulY",
        "outputId": "26316c4a-1fe2-4992-aba0-36c7ff3800fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generation 1 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=1, coef0=15, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=10, coef0=15, degree=3, Balanced Accuracy: 0.578\n",
            "Params: C=0.3, coef0=7, degree=4, Balanced Accuracy: 0.576\n",
            "Params: C=0.3, coef0=15, degree=4, Balanced Accuracy: 0.576\n",
            "Params: C=10, coef0=1, degree=3, Balanced Accuracy: 0.576\n",
            "Params: C=30, coef0=7, degree=3, Balanced Accuracy: 0.575\n",
            "Params: C=3.76594, coef0=4, degree=4, Balanced Accuracy: 0.575\n",
            "Params: C=30, coef0=15, degree=3, Balanced Accuracy: 0.575\n",
            "Params: C=10, coef0=1, degree=4, Balanced Accuracy: 0.574\n",
            "Params: C=1, coef0=7, degree=4, Balanced Accuracy: 0.573\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=1, gamma=0.01, Balanced Accuracy: 0.478\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 2 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=1, coef0=15, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=10, coef0=15, degree=3, Balanced Accuracy: 0.578\n",
            "Params: C=0.3, coef0=7, degree=4, Balanced Accuracy: 0.576\n",
            "Params: C=0.3, coef0=15, degree=4, Balanced Accuracy: 0.576\n",
            "Params: C=10, coef0=1, degree=3, Balanced Accuracy: 0.576\n",
            "Params: C=30, coef0=7, degree=3, Balanced Accuracy: 0.575\n",
            "Params: C=3.76594, coef0=4, degree=4, Balanced Accuracy: 0.575\n",
            "Params: C=30, coef0=15, degree=3, Balanced Accuracy: 0.575\n",
            "Params: C=10, coef0=1, degree=4, Balanced Accuracy: 0.574\n",
            "Params: C=1, coef0=7, degree=4, Balanced Accuracy: 0.573\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=1, gamma=0.01, Balanced Accuracy: 0.478\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 3 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=1, coef0=15, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=10, coef0=15, degree=3, Balanced Accuracy: 0.578\n",
            "Params: C=0.3, coef0=7, degree=4, Balanced Accuracy: 0.576\n",
            "Params: C=0.3, coef0=15, degree=4, Balanced Accuracy: 0.576\n",
            "Params: C=10, coef0=1, degree=3, Balanced Accuracy: 0.576\n",
            "Params: C=30, coef0=7, degree=3, Balanced Accuracy: 0.575\n",
            "Params: C=3.76594, coef0=4, degree=4, Balanced Accuracy: 0.575\n",
            "Params: C=30, coef0=15, degree=3, Balanced Accuracy: 0.575\n",
            "Params: C=10, coef0=1, degree=4, Balanced Accuracy: 0.574\n",
            "Params: C=1, coef0=7, degree=4, Balanced Accuracy: 0.573\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=1, gamma=0.01, Balanced Accuracy: 0.478\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 4 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=1, coef0=15, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=10, coef0=15, degree=3, Balanced Accuracy: 0.578\n",
            "Params: C=0.3, coef0=7, degree=4, Balanced Accuracy: 0.576\n",
            "Params: C=0.3, coef0=15, degree=4, Balanced Accuracy: 0.576\n",
            "Params: C=10, coef0=1, degree=3, Balanced Accuracy: 0.576\n",
            "Params: C=30, coef0=7, degree=3, Balanced Accuracy: 0.575\n",
            "Params: C=3.76594, coef0=4, degree=4, Balanced Accuracy: 0.575\n",
            "Params: C=30, coef0=15, degree=3, Balanced Accuracy: 0.575\n",
            "Params: C=0.3, coef0=13.40625, degree=4, Balanced Accuracy: 0.574\n",
            "Params: C=10, coef0=1, degree=4, Balanced Accuracy: 0.574\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=1, gamma=0.01, Balanced Accuracy: 0.478\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 5 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=1, coef0=15, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=10, coef0=15, degree=3, Balanced Accuracy: 0.578\n",
            "Params: C=0.3, coef0=7, degree=4, Balanced Accuracy: 0.576\n",
            "Params: C=0.3, coef0=15, degree=4, Balanced Accuracy: 0.576\n",
            "Params: C=10, coef0=1, degree=3, Balanced Accuracy: 0.576\n",
            "Params: C=20, coef0=3.63, degree=3, Balanced Accuracy: 0.576\n",
            "Params: C=30, coef0=7, degree=3, Balanced Accuracy: 0.575\n",
            "Params: C=0.62332, coef0=9.3498, degree=4, Balanced Accuracy: 0.575\n",
            "Params: C=3.76594, coef0=4, degree=4, Balanced Accuracy: 0.575\n",
            "Params: C=30, coef0=15, degree=3, Balanced Accuracy: 0.575\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=1, gamma=0.01, Balanced Accuracy: 0.478\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 6 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=1, coef0=15, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=10, coef0=15, degree=3, Balanced Accuracy: 0.578\n",
            "Params: C=0.3, coef0=7, degree=4, Balanced Accuracy: 0.576\n",
            "Params: C=0.3, coef0=15, degree=4, Balanced Accuracy: 0.576\n",
            "Params: C=10, coef0=1, degree=3, Balanced Accuracy: 0.576\n",
            "Params: C=20, coef0=3.63, degree=3, Balanced Accuracy: 0.576\n",
            "Params: C=30, coef0=7, degree=3, Balanced Accuracy: 0.575\n",
            "Params: C=0.62332, coef0=9.3498, degree=4, Balanced Accuracy: 0.575\n",
            "Params: C=3.76594, coef0=4, degree=4, Balanced Accuracy: 0.575\n",
            "Params: C=30, coef0=15, degree=3, Balanced Accuracy: 0.575\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=1, gamma=0.01, Balanced Accuracy: 0.478\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 7 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=1, coef0=15, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=10, coef0=15, degree=3, Balanced Accuracy: 0.578\n",
            "Params: C=0.3, coef0=7, degree=4, Balanced Accuracy: 0.576\n",
            "Params: C=0.3, coef0=15, degree=4, Balanced Accuracy: 0.576\n",
            "Params: C=10, coef0=1, degree=3, Balanced Accuracy: 0.576\n",
            "Params: C=20.5, coef0=15, degree=3, Balanced Accuracy: 0.576\n",
            "Params: C=20, coef0=3.63, degree=3, Balanced Accuracy: 0.576\n",
            "Params: C=30, coef0=7, degree=3, Balanced Accuracy: 0.575\n",
            "Params: C=0.62332, coef0=9.3498, degree=4, Balanced Accuracy: 0.575\n",
            "Params: C=3.76594, coef0=4, degree=4, Balanced Accuracy: 0.575\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=1, gamma=0.01, Balanced Accuracy: 0.478\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 8 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=1, coef0=15, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=10, coef0=15, degree=3, Balanced Accuracy: 0.578\n",
            "Params: C=0.3, coef0=7, degree=4, Balanced Accuracy: 0.576\n",
            "Params: C=0.3, coef0=15, degree=4, Balanced Accuracy: 0.576\n",
            "Params: C=10, coef0=1, degree=3, Balanced Accuracy: 0.576\n",
            "Params: C=20.5, coef0=15, degree=3, Balanced Accuracy: 0.576\n",
            "Params: C=20, coef0=3.63, degree=3, Balanced Accuracy: 0.576\n",
            "Params: C=30, coef0=7, degree=3, Balanced Accuracy: 0.575\n",
            "Params: C=0.62332, coef0=9.3498, degree=4, Balanced Accuracy: 0.575\n",
            "Params: C=3.76594, coef0=4, degree=4, Balanced Accuracy: 0.575\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=1, gamma=0.01, Balanced Accuracy: 0.478\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 9 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=1, coef0=15, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=10, coef0=15, degree=3, Balanced Accuracy: 0.578\n",
            "Params: C=0.3, coef0=7, degree=4, Balanced Accuracy: 0.576\n",
            "Params: C=0.3, coef0=15, degree=4, Balanced Accuracy: 0.576\n",
            "Params: C=10, coef0=1, degree=3, Balanced Accuracy: 0.576\n",
            "Params: C=20, coef0=4, degree=3, Balanced Accuracy: 0.576\n",
            "Params: C=20.5, coef0=15, degree=3, Balanced Accuracy: 0.576\n",
            "Params: C=20, coef0=3.63, degree=3, Balanced Accuracy: 0.576\n",
            "Params: C=30, coef0=7, degree=3, Balanced Accuracy: 0.575\n",
            "Params: C=0.62332, coef0=9.3498, degree=4, Balanced Accuracy: 0.575\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=1, gamma=0.01, Balanced Accuracy: 0.478\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 10 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=1, coef0=15, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=10, coef0=15, degree=3, Balanced Accuracy: 0.578\n",
            "Params: C=0.3, coef0=7, degree=4, Balanced Accuracy: 0.576\n",
            "Params: C=0.3, coef0=15, degree=4, Balanced Accuracy: 0.576\n",
            "Params: C=10, coef0=1, degree=3, Balanced Accuracy: 0.576\n",
            "Params: C=20, coef0=4, degree=3, Balanced Accuracy: 0.576\n",
            "Params: C=20.5, coef0=15, degree=3, Balanced Accuracy: 0.576\n",
            "Params: C=20, coef0=3.63, degree=3, Balanced Accuracy: 0.576\n",
            "Params: C=30, coef0=7, degree=3, Balanced Accuracy: 0.575\n",
            "Params: C=0.62332, coef0=9.3498, degree=4, Balanced Accuracy: 0.575\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=1, gamma=0.01, Balanced Accuracy: 0.478\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 15 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=1.4167, coef0=8.7495, degree=4, Balanced Accuracy: 0.581\n",
            "Params: C=1, coef0=15, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=10, coef0=15, degree=3, Balanced Accuracy: 0.578\n",
            "Params: C=1.23856, coef0=14.84344, degree=4, Balanced Accuracy: 0.578\n",
            "Params: C=15.80931, coef0=9.23115, degree=3, Balanced Accuracy: 0.578\n",
            "Params: C=19.5, coef0=8.2, degree=3, Balanced Accuracy: 0.577\n",
            "Params: C=14.99367, coef0=12.43453, degree=3, Balanced Accuracy: 0.577\n",
            "Params: C=20.75625, coef0=9.2625, degree=3, Balanced Accuracy: 0.576\n",
            "Params: C=0.3, coef0=7, degree=4, Balanced Accuracy: 0.576\n",
            "Params: C=0.3, coef0=15, degree=4, Balanced Accuracy: 0.576\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=1, gamma=0.01, Balanced Accuracy: 0.478\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 20 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=1.4167, coef0=8.7495, degree=4, Balanced Accuracy: 0.581\n",
            "Params: C=2.05429, coef0=4.81179, degree=4, Balanced Accuracy: 0.580\n",
            "Params: C=1, coef0=15, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=10, coef0=15, degree=3, Balanced Accuracy: 0.578\n",
            "Params: C=1.23856, coef0=14.84344, degree=4, Balanced Accuracy: 0.578\n",
            "Params: C=1.48896, coef0=7.61516, degree=4, Balanced Accuracy: 0.578\n",
            "Params: C=15.80931, coef0=9.23115, degree=3, Balanced Accuracy: 0.578\n",
            "Params: C=13.31902, coef0=13.63898, degree=3, Balanced Accuracy: 0.577\n",
            "Params: C=19.5, coef0=8.2, degree=3, Balanced Accuracy: 0.577\n",
            "Params: C=14.99367, coef0=12.43453, degree=3, Balanced Accuracy: 0.577\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=1, gamma=0.01, Balanced Accuracy: 0.478\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 25 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=1.4167, coef0=8.7495, degree=4, Balanced Accuracy: 0.581\n",
            "Params: C=2.05429, coef0=4.81179, degree=4, Balanced Accuracy: 0.580\n",
            "Params: C=1, coef0=15, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=1.41651, coef0=8.18233, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=10, coef0=15, degree=3, Balanced Accuracy: 0.578\n",
            "Params: C=1.23856, coef0=14.84344, degree=4, Balanced Accuracy: 0.578\n",
            "Params: C=0.69407, coef0=13.21244, degree=4, Balanced Accuracy: 0.578\n",
            "Params: C=1.48896, coef0=7.61516, degree=4, Balanced Accuracy: 0.578\n",
            "Params: C=15.80931, coef0=9.23115, degree=3, Balanced Accuracy: 0.578\n",
            "Params: C=13.31902, coef0=13.63898, degree=3, Balanced Accuracy: 0.577\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=1, gamma=0.01, Balanced Accuracy: 0.478\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 30 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=1.4167, coef0=8.7495, degree=4, Balanced Accuracy: 0.581\n",
            "Params: C=2.05429, coef0=4.81179, degree=4, Balanced Accuracy: 0.580\n",
            "Params: C=1, coef0=15, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=1.41651, coef0=8.18233, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=10, coef0=15, degree=3, Balanced Accuracy: 0.578\n",
            "Params: C=2.17713, coef0=4.05312, degree=4, Balanced Accuracy: 0.578\n",
            "Params: C=1.23856, coef0=14.84344, degree=4, Balanced Accuracy: 0.578\n",
            "Params: C=0.69407, coef0=13.21244, degree=4, Balanced Accuracy: 0.578\n",
            "Params: C=1.48896, coef0=7.61516, degree=4, Balanced Accuracy: 0.578\n",
            "Params: C=15.80931, coef0=9.23115, degree=3, Balanced Accuracy: 0.578\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=1, gamma=0.01, Balanced Accuracy: 0.478\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 35 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=1.4167, coef0=8.7495, degree=4, Balanced Accuracy: 0.581\n",
            "Params: C=2.05429, coef0=4.81179, degree=4, Balanced Accuracy: 0.580\n",
            "Params: C=1, coef0=15, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=1.32763, coef0=8.84735, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=1.41651, coef0=8.18233, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=10, coef0=15, degree=3, Balanced Accuracy: 0.578\n",
            "Params: C=2.17713, coef0=4.05312, degree=4, Balanced Accuracy: 0.578\n",
            "Params: C=2.11571, coef0=4.43245, degree=4, Balanced Accuracy: 0.578\n",
            "Params: C=1.23856, coef0=14.84344, degree=4, Balanced Accuracy: 0.578\n",
            "Params: C=0.69407, coef0=13.21244, degree=4, Balanced Accuracy: 0.578\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=1, gamma=0.01, Balanced Accuracy: 0.478\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 40 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=1.4167, coef0=8.7495, degree=4, Balanced Accuracy: 0.581\n",
            "Params: C=2.05429, coef0=4.81179, degree=4, Balanced Accuracy: 0.580\n",
            "Params: C=0.59013, coef0=13.8544, degree=4, Balanced Accuracy: 0.580\n",
            "Params: C=1, coef0=15, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=1.32763, coef0=8.84735, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=0.7713, coef0=11.01836, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=1.41651, coef0=8.18233, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=10, coef0=15, degree=3, Balanced Accuracy: 0.578\n",
            "Params: C=2.17713, coef0=4.05312, degree=4, Balanced Accuracy: 0.578\n",
            "Params: C=2.11571, coef0=4.43245, degree=4, Balanced Accuracy: 0.578\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=1, gamma=0.01, Balanced Accuracy: 0.478\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 45 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=1.4167, coef0=8.7495, degree=4, Balanced Accuracy: 0.581\n",
            "Params: C=2.05429, coef0=4.81179, degree=4, Balanced Accuracy: 0.580\n",
            "Params: C=0.59013, coef0=13.8544, degree=4, Balanced Accuracy: 0.580\n",
            "Params: C=1, coef0=15, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=1.32763, coef0=8.84735, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=11.47375, coef0=12.13475, degree=3, Balanced Accuracy: 0.579\n",
            "Params: C=0.7713, coef0=11.01836, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=1.38119, coef0=8.67756, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=1.41651, coef0=8.18233, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=10, coef0=15, degree=3, Balanced Accuracy: 0.578\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=1, gamma=0.01, Balanced Accuracy: 0.478\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 50 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=1.4167, coef0=8.7495, degree=4, Balanced Accuracy: 0.581\n",
            "Params: C=2.05429, coef0=4.81179, degree=4, Balanced Accuracy: 0.580\n",
            "Params: C=0.59013, coef0=13.8544, degree=4, Balanced Accuracy: 0.580\n",
            "Params: C=1, coef0=15, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=1.32763, coef0=8.84735, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=11.47375, coef0=12.13475, degree=3, Balanced Accuracy: 0.579\n",
            "Params: C=0.7713, coef0=11.01836, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=1.32055, coef0=8.76246, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=1.38119, coef0=8.67756, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=1.41651, coef0=8.18233, degree=4, Balanced Accuracy: 0.579\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=1, gamma=0.01, Balanced Accuracy: 0.478\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 55 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=1.4167, coef0=8.7495, degree=4, Balanced Accuracy: 0.581\n",
            "Params: C=2.05429, coef0=4.81179, degree=4, Balanced Accuracy: 0.580\n",
            "Params: C=0.59013, coef0=13.8544, degree=4, Balanced Accuracy: 0.580\n",
            "Params: C=1, coef0=15, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=1.32763, coef0=8.84735, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=11.47375, coef0=12.13475, degree=3, Balanced Accuracy: 0.579\n",
            "Params: C=0.7713, coef0=11.01836, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=1.32055, coef0=8.76246, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=1.38119, coef0=8.67756, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=1.66801, coef0=8.53708, degree=4, Balanced Accuracy: 0.579\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=1, gamma=0.01, Balanced Accuracy: 0.478\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 60 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=1.4167, coef0=8.7495, degree=4, Balanced Accuracy: 0.581\n",
            "Params: C=2.05429, coef0=4.81179, degree=4, Balanced Accuracy: 0.580\n",
            "Params: C=0.59013, coef0=13.8544, degree=4, Balanced Accuracy: 0.580\n",
            "Params: C=1, coef0=15, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=1.32055, coef0=8.98152, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=1.32763, coef0=8.84735, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=11.47375, coef0=12.13475, degree=3, Balanced Accuracy: 0.579\n",
            "Params: C=0.7713, coef0=11.01836, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=1.32055, coef0=8.76246, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=1.38119, coef0=8.67756, degree=4, Balanced Accuracy: 0.579\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=1, gamma=0.01, Balanced Accuracy: 0.478\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Generation 65 results:\n",
            "\n",
            "Top results for poly kernel:\n",
            "Params: C=1.4167, coef0=8.7495, degree=4, Balanced Accuracy: 0.581\n",
            "Params: C=2.05429, coef0=4.81179, degree=4, Balanced Accuracy: 0.580\n",
            "Params: C=0.59013, coef0=13.8544, degree=4, Balanced Accuracy: 0.580\n",
            "Params: C=1, coef0=15, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=1.33441, coef0=10.82645, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=1.32055, coef0=8.98152, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=1.32763, coef0=8.84735, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=11.47375, coef0=12.13475, degree=3, Balanced Accuracy: 0.579\n",
            "Params: C=0.7713, coef0=11.01836, degree=4, Balanced Accuracy: 0.579\n",
            "Params: C=1.32055, coef0=8.76246, degree=4, Balanced Accuracy: 0.579\n",
            "\n",
            "Top results for rbf kernel:\n",
            "Params: C=1, gamma=0.01, Balanced Accuracy: 0.478\n",
            "\n",
            "----------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "folder_path = '/content/drive/My Drive/Experimentation Results/'\n",
        "file_path = folder_path + 'Genetic_Algo_Results_poly_15_percent.json'\n",
        "with open(file_path, 'r') as file:\n",
        "    data = json.load(file)\n",
        "# The above is for the sake of getting some useful output saved to this document\n",
        "# by putting the documents in my google drive.\n",
        "# REMOVE BEFORE TURNING IN AS IT WON'T WORK FOR OTHERS\n",
        "# Json loading below should work fine provided we put the jsons in the\n",
        "# correct folder with the notebook before turning in. Must test.\n",
        "\n",
        "# with open('Genetic_Algo_Results_poly_15_percent.json', 'r') as file:\n",
        "#     data = json.load(file)\n",
        "\n",
        "for entry in data:\n",
        "    generation = entry['generation']\n",
        "    results = entry['results']\n",
        "\n",
        "    if generation < 10 or generation % 5 == 0: # Comment out if you want full printout\n",
        "      print(f\"Generation {generation} results:\")\n",
        "\n",
        "      for kernel_type, models in results.items():\n",
        "          print(f\"\\nTop results for {kernel_type} kernel:\")\n",
        "          for model in models[:10]:  # Can delete [:10] if you want a more extensive printout\n",
        "              formatted_params = format_params(model['params'])\n",
        "              balanced_accuracy = model['balanced_accuracy']\n",
        "              print(f\"Params: {formatted_params}, Balanced Accuracy: {balanced_accuracy:.3f}\")\n",
        "\n",
        "      print(\"\\n\" + \"-\"*40 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xmp1jg4OHHz6"
      },
      "outputs": [],
      "source": [
        "#DUPE CODE ONLY AROUND FOR WHEN I'M MESSIN WITH THE ENSEMBLE CODE BELOW\n",
        "#RETURN TO DELETE\n",
        "\n",
        "X_encode_map = {'x':1, 'o': 2, 'b': 0}\n",
        "X_encoded_dataframes = X.replace(X_encode_map)\n",
        "X_encoded = X_encoded_dataframes.values\n",
        "\n",
        "y_encode_map = {\"win\": 1, \"loss\": 2, \"draw\": 0}\n",
        "y_encoded_dataframes = y.replace({\"class\": y_encode_map})\n",
        "y_encoded = y_encoded_dataframes['class'].values\n",
        "\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X_encoded, y_encoded, test_size=0.15, random_state=5, stratify=y_encoded)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_val_std = scaler.fit_transform(X_train_val)\n",
        "\n",
        "X_train_full, X_val, y_train_full, y_val = train_test_split(\n",
        "    X_train_val_std, y_train_val, test_size=0.1765, random_state=5, stratify=y_train_val)\n",
        "    #0.1765 gives us 15% of our entire dataset as validation sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qepVrHg7HWPF"
      },
      "source": [
        "Finally we reach the culmination of our hyperparameter search efforts below where we use sklearn.ensemble's VotingClassifier to get the most out of all the various hyperparameter combinations we found. We have put comments in the code to indicate where we got the various combinations from. Our goal was to use as many high-performing, largely unique combinations as our experiments could find to work together and help compensate for each other's weaknesses.\n",
        "\n",
        "We initially tried a soft vote set up but the accuracy was at least 10% lower than when we switched it to a hard vote set up. None of the accuracies we've generated throughout this project suggest that any of the models are reaching a very high certainty in their predictions so we suspect that a probability based approach like soft voting is just not working very well when none of the probabilities are particularly high.\n",
        "\n",
        "We began with an unweighted approach at first but wondered if we could get just a little bit more accuracy by using a weighted approach to favor the votes from the more accurate models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9w7uc-0HI8E"
      },
      "outputs": [],
      "source": [
        "# X_train_full, X_discard, y_train_full, y_discard = train_test_split(\n",
        "#     X_train_full, y_train_full, test_size=49/50, random_state=5, stratify=y_train_full)\n",
        "\n",
        "\n",
        "model_configs = [\n",
        "    # From parameterGrid search for poly\n",
        "    {'C': 50, 'class_weight': 'balanced', 'coef0': 3.0, 'degree': 4, 'kernel': 'poly'},\n",
        "    {'C': 1, 'class_weight': 'balanced', 'coef0': 10.0, 'degree': 4, 'kernel': 'poly'},\n",
        "    {'C': 10, 'class_weight': 'balanced', 'coef0': 10.0, 'degree': 3, 'kernel': 'poly'},\n",
        "    {'C': 10, 'class_weight': 'balanced', 'coef0': 10.0, 'degree': 4, 'kernel': 'poly'},\n",
        "    {'C': 1, 'class_weight': 'balanced', 'coef0': 3.0, 'degree': 4, 'kernel': 'poly'},\n",
        "\n",
        "    # From 15% genetic algo run with just poly\n",
        "    {'C': 1.4167, 'class_weight': 'balanced', 'coef0': 8.7495, 'degree': 4, 'kernel': 'poly'},\n",
        "    {'C': 2.05429, 'class_weight': 'balanced', 'coef0': 4.81179, 'degree': 4, 'kernel': 'poly'},\n",
        "    {'C': 0.59013, 'class_weight': 'balanced', 'coef0': 13.8544, 'degree': 4, 'kernel': 'poly'},\n",
        "    {'C': 11.47375, 'class_weight': 'balanced', 'coef0': 12.13475, 'degree': 3, 'kernel': 'poly'},\n",
        "    {'C': 15.80931, 'class_weight': 'balanced', 'coef0': 9.23115, 'degree': 3, 'kernel': 'poly'},\n",
        "\n",
        "    # From lost 15% genetic algo run with just poly\n",
        "    {'C': 0.42989, 'class_weight': 'balanced', 'coef0': 20, 'degree': 4, 'kernel': 'poly'},\n",
        "\n",
        "    # From backup 10% genetic algo run\n",
        "    {'C': 0.28213, 'class_weight': 'balanced', 'coef0': 18.11885, 'degree': 4, 'kernel': 'poly'},\n",
        "\n",
        "    # From parameterGrid search for rbf\n",
        "    {'C': 100, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'},\n",
        "    {'C': 100, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'},\n",
        "    {'C': 100, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf'},\n",
        "\n",
        "    # From 50% genetic algo run with just rbf\n",
        "    {'C': 34.23105, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'},\n",
        "    {'C': 37.11423, 'class_weight': 'balanced', 'gamma': 0.025, 'kernel': 'rbf'},\n",
        "    {'C': 67.25533, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'},\n",
        "\n",
        "    # From backup 50% genetic algo run with just rbf\n",
        "    {'C': 24.42528, 'class_weight': 'balanced', 'gamma': 'auto', 'kernel': 'rbf'}\n",
        "]\n",
        "\n",
        "# Again taking advantage of parallel processing to speed up the training process\n",
        "def train_model(config):\n",
        "    model = svm.SVC(**config)\n",
        "    model.fit(X_train_full, y_train_full)\n",
        "    return model\n",
        "\n",
        "num_cores = multiprocessing.cpu_count() - 2\n",
        "trained_models = Parallel(n_jobs=num_cores)(delayed(train_model)(config) for config in model_configs)\n",
        "\n",
        "estimators = [(f'model_{i}', model) for i, model in enumerate(trained_models)]\n",
        "voting_classifier = VotingClassifier(estimators=estimators, voting='hard')\n",
        "voting_classifier.fit(X_train_full, y_train_full)\n",
        "\n",
        "print(\"\\nBalanced Accuracy for Individual Models:\")\n",
        "validation_scores = []\n",
        "for i, model in enumerate(trained_models):\n",
        "    y_pred = model.predict(X_val)\n",
        "    balanced_acc = balanced_accuracy_score(y_val, y_pred)\n",
        "    validation_scores.append(balanced_acc)\n",
        "    print(f\"Model {i + 1}: Balanced Accuracy = {balanced_acc:.4f}\")\n",
        "\n",
        "# Non-weighted prediction first\n",
        "non_weighted_preds = voting_classifier.predict(X_val)\n",
        "non_weighted_score = balanced_accuracy_score(y_val, non_weighted_preds)\n",
        "print(f'Non-Weighted Voting Ensemble Balanced Accuracy: {non_weighted_score:.4f}')\n",
        "\n",
        "# Give the more accurate models some more weight to hopefully further increase accuracy\n",
        "total_score = sum(validation_scores)\n",
        "weights = [score / total_score for score in validation_scores]\n",
        "voting_classifier.set_params(weights=weights)\n",
        "\n",
        "weighted_preds = voting_classifier.predict(X_val)\n",
        "weighted_score = balanced_accuracy_score(y_val, weighted_preds)\n",
        "print(f'Weighted Voting Ensemble Balanced Accuracy: {weighted_score:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7ijF55soEAX"
      },
      "source": [
        "TALK ABOUT RESULTS ABOVE IF WE CHOOSE TO RUN IT (POTENTIALLY UNLIKELY GIVEN TIME CONSTRAINTS) OR USE THIS SECTION TO LINK IMAGES YOU GOT FROM RUNNING IT ON YOUR LAPTOP. In results, usually have the ensemble vote beat all but the very best model(s).\n",
        "\n",
        "\n",
        "Below we have one last piece of optimization. We have quite a few hyperparameter combinations we ended up choosing (19) and while we did our best to pick the most unique ones, sometimes it helps to have some additional math behind your decision. What the code below does is that it gets predictions from all the models and then it generates a correlation matrix between the predictions of all the models. It then prints out any pairs of models that generate extremely similar (over 0.95 correlation value) predictions to one another. If two models end up being incredibly similar to one another, we wanted to pick the better of the two of them. Although two similar models could double up on correct predictions, they could also double on on incorrect predictions and we wanted each model to serve as a unique voice (not two) in deciding any given outcome to keep our numbers more accurate.\n",
        "\n",
        "So once the code above has been run, we can then run the code below to find out which of our models are too similar to one another. For every pair of models, we look at the accuracies above and, whichever of the similar models has the lower accuracy, we comment it out of the code above. Once all similar models have been commented out, we can then run the code above once more to get a slightly more accurate prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NStopiTaoEWc"
      },
      "outputs": [],
      "source": [
        "def compute_prediction_correlations(models):\n",
        "    preds = [model.predict(X_val) for model in models]\n",
        "    correlation_matrix = np.corrcoef(preds)\n",
        "    return correlation_matrix\n",
        "\n",
        "correlation_matrix = compute_prediction_correlations(trained_models)\n",
        "\n",
        "# Identify redundant models\n",
        "threshold = 0.95\n",
        "redundant_pairs = np.where(np.abs(correlation_matrix) > threshold)\n",
        "redundant_pairs = [(i, j) for i, j in zip(*redundant_pairs) if i != j and i < j]\n",
        "\n",
        "print('Redundant model pairs:')\n",
        "for i, j in redundant_pairs:\n",
        "    print(f'Model {i+1} and Model {j+1} are redundant')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "un47ZaVsyOU2"
      },
      "source": [
        "PUT FINAL RESULTS FROM CLASSIFIER HERE\n",
        "\n",
        "Above we can finally see the final accuracies of all of our models as tested by the validation test sets we established at the very beginning of our code. Below, we can see the results from our full data, no PCA baseline run using the validation test sets (degree 5/6 omitted).\n",
        "\n",
        "Balanced accuracy for 2 degree: 0.6009  \n",
        "Balanced accuracy for 3 degree: 0.6137  \n",
        "Balanced accuracy for 4 degree: 0.6049   \n",
        "Balanced accuracy for auto as gamma value: 0.6578  \n",
        "Balanced accuracy for scale as gamma value: 0.6575  \n",
        "\n",
        "COMMENTARY HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcNBCj71l-XX"
      },
      "source": [
        "We now arrive at the final test of our progress. Below is the code we used for our baseline at the beginning of the project but it has been modified to run with the X_test and y_test data we set aside at the very beginning of this process. More discussion below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWIW5XHjl_TH",
        "outputId": "fae89481-4a3d-4d92-b598-d7135946559f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Following results use the original data (no PCA).\n",
            "Balanced accuracy for 2 degree: 0.4846\n",
            "Balanced accuracy for 3 degree: 0.4031\n",
            "Balanced accuracy for 4 degree: 0.3484\n",
            "Balanced accuracy for auto as gamma value: 0.4547\n",
            "Balanced accuracy for scale as gamma value: 0.4546\n",
            "Total time for components None: 32m 50.6s\n"
          ]
        }
      ],
      "source": [
        "pca_components = [None]\n",
        "results_baseline = defaultdict(dict)\n",
        "total_time_per_component = []\n",
        "\n",
        "for components in pca_components:\n",
        "    component_start_time = time.time()\n",
        "\n",
        "    if components is not None:\n",
        "        print(f\"\\nFollowing results use {components} principal components:\")\n",
        "        pca = PCA(n_components=components)\n",
        "        X_train_pca = pca.fit_transform(X_train_full)\n",
        "        X_test_pca = pca.transform(X_test)\n",
        "        X_new_train = X_train_pca\n",
        "        X_new_test = X_test_pca\n",
        "    else:\n",
        "        print(\"Following results use the original data (no PCA).\")\n",
        "        X_new_train = X_train_full\n",
        "        X_new_test = X_test\n",
        "\n",
        "    poly_results = defaultdict(tuple)\n",
        "\n",
        "    for degree in range(2, 5):\n",
        "        svc_poly = svm.SVC(kernel='poly', degree=degree, C=1.0, coef0=0.0, class_weight='balanced')\n",
        "        svc_poly.fit(X_new_train, y_train_full)\n",
        "        y_pred_poly = svc_poly.predict(X_new_test)\n",
        "        report = classification_report(y_test, y_pred_poly)\n",
        "        balanced_accuracy = balanced_accuracy_score(y_test, y_pred_poly)\n",
        "        poly_results[degree] = (balanced_accuracy, report)\n",
        "        print(f\"Balanced accuracy for {degree} degree: {balanced_accuracy:.4f}\")\n",
        "\n",
        "    rbf_results = defaultdict(tuple)\n",
        "    gamma_values = [\"auto\", \"scale\"]\n",
        "\n",
        "    for gamma in gamma_values:\n",
        "        svc_rbf = svm.SVC(kernel='rbf', C=1.0, gamma=gamma, class_weight='balanced')\n",
        "        svc_rbf.fit(X_new_train, y_train_full)\n",
        "        y_pred_rbf = svc_rbf.predict(X_new_test)\n",
        "        report = classification_report(y_test, y_pred_rbf)\n",
        "        balanced_accuracy = balanced_accuracy_score(y_test, y_pred_rbf)\n",
        "        rbf_results[gamma] = (balanced_accuracy, report)\n",
        "        print(f\"Balanced accuracy for {gamma} as gamma value: {balanced_accuracy:.4f}\")\n",
        "\n",
        "    results_baseline[components] = {'poly': poly_results, 'rbf': rbf_results}\n",
        "\n",
        "    elapsed_time = time.time() - component_start_time\n",
        "    total_time_per_component.append(elapsed_time)\n",
        "    minutes, seconds = divmod(elapsed_time, 60)\n",
        "    print(f\"Total time for components {components}: {int(minutes)}m {seconds:.1f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd9nOPiVzYiY"
      },
      "source": [
        "As we can see above, these accuracies are quite different from the ones we found using our validation test sets below:\n",
        "\n",
        "Balanced accuracy for 2 degree: 0.6009  \n",
        "Balanced accuracy for 3 degree: 0.6137  \n",
        "Balanced accuracy for 4 degree: 0.6049   \n",
        "Balanced accuracy for auto as gamma value: 0.6578  \n",
        "Balanced accuracy for scale as gamma value: 0.6575  \n",
        "\n",
        "This suggests X_test/y_test is likely composed of a much different distribution of classes/data than our validation sets so this will serve as a good demonstration of whether or not the models we found are generalizable. Below is the code we can use to test the SVMs and VotingClassifer we trained above to see how well they perform on this unseen dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWrQGMYv2UxN"
      },
      "outputs": [],
      "source": [
        "print(\"\\nBalanced Accuracy for Individual Models on Test Set:\")\n",
        "test_scores = []\n",
        "for i, model in enumerate(trained_models):\n",
        "    test_pred = model.predict(X_test)\n",
        "    test_balanced_acc = balanced_accuracy_score(y_test, test_pred)\n",
        "    test_scores.append(test_balanced_acc)\n",
        "    print(f\"Model {i + 1}: Test Balanced Accuracy = {test_balanced_acc:.4f}\")\n",
        "\n",
        "non_weighted_test_preds = voting_classifier.predict(X_test)\n",
        "non_weighted_test_score = balanced_accuracy_score(y_test, non_weighted_test_preds)\n",
        "print(f'Non-Weighted Voting Ensemble Test Balanced Accuracy: {non_weighted_test_score:.4f}')\n",
        "\n",
        "total_test_score = sum(test_scores)\n",
        "test_weights = [score / total_test_score for score in test_scores]\n",
        "voting_classifier.set_params(weights=test_weights)\n",
        "\n",
        "weighted_test_preds = voting_classifier.predict(X_test)\n",
        "weighted_test_score = balanced_accuracy_score(y_test, weighted_test_preds)\n",
        "print(f'Weighted Voting Ensemble Test Balanced Accuracy: {weighted_test_score:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7eyayFL2ttt"
      },
      "source": [
        "# Conclusion of SVM section\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMJZI2y7rgQx"
      },
      "source": [
        "# Neural Network\n",
        "\n",
        "Using the same connect 4 dataset from UCIML, let's see how a basic neural network (NN) performs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xV1L9zz5r33-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import  Sequential\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import  Dense, BatchNormalization, Dropout, Conv2D, MaxPooling2D, Flatten\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "import csv\n",
        "from ucimlrepo import fetch_ucirepo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Avzt792psAS-"
      },
      "source": [
        "## Load dataset\n",
        "Load the dataset and encode the non-numerical attributes with one hot encoding. Then make a train/test split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDcyARwMr6L2",
        "outputId": "231d602d-4381-4d7e-edc2-7f09d2983df4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original data\n",
            "  a1 a2 a3 a4 a5 a6 b1 b2 b3 b4  ... f3 f4 f5 f6 g1 g2 g3 g4 g5 g6\n",
            "0  b  b  b  b  b  b  b  b  b  b  ...  b  b  b  b  b  b  b  b  b  b\n",
            "1  b  b  b  b  b  b  b  b  b  b  ...  b  b  b  b  b  b  b  b  b  b\n",
            "2  b  b  b  b  b  b  o  b  b  b  ...  b  b  b  b  b  b  b  b  b  b\n",
            "\n",
            "[3 rows x 42 columns]\n",
            "  class\n",
            "0   win\n",
            "1   win\n",
            "2   win\n",
            "\n",
            "encoded data\n",
            "encoded Labels:  ['draw' 'loss' 'win']\n",
            "[[0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            "  1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
            "  1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
            "  1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
            "  1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0.\n",
            "  1. 0. 0. 1. 0. 0.]]\n",
            "[[0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "connect_4 = fetch_ucirepo(id=26)\n",
        "\n",
        "X = connect_4.data.features\n",
        "y = connect_4.data.targets\n",
        "\n",
        "# print first example from data set\n",
        "print(\"original data\")\n",
        "print(X[:3])\n",
        "print(y[:3])\n",
        "print()\n",
        "\n",
        "feature_encoder = OneHotEncoder()\n",
        "X_encoded = feature_encoder.fit_transform(X).toarray()\n",
        "\n",
        "label_encoder = OneHotEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y.values.reshape(-1, 1)).toarray()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# print first example from training set\n",
        "print(\"encoded data\")\n",
        "encoded_labels = label_encoder.categories_[0]\n",
        "print(\"encoded Labels: \", encoded_labels)\n",
        "print(X_train[:1])\n",
        "print(y_train[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mxasSdEvOnq"
      },
      "outputs": [],
      "source": [
        "def fit_model(model, X_train, y_train, X_test, y_test, num_epochs):\n",
        "    model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    checkpoint = ModelCheckpoint('model.keras', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=num_epochs, batch_size=64, callbacks=[checkpoint])\n",
        "\n",
        "    loss, accuracy = model.evaluate(X_test, y_test)\n",
        "    print(f'Loss: {loss}, Accuracy: {accuracy}')\n",
        "\n",
        "    print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8jGRzo4s20z"
      },
      "source": [
        "## Build the model\n",
        "Let's start with a very basic model, with a few hidden layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_bjbD58sXOq",
        "outputId": "e9db16f3-cf98-4cd0-8f9c-d321de71e210"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "843/845 [============================>.] - ETA: 0s - loss: 0.5481 - accuracy: 0.7807\n",
            "Epoch 1: val_accuracy improved from -inf to 0.81098, saving model to model.keras\n",
            "845/845 [==============================] - 5s 4ms/step - loss: 0.5479 - accuracy: 0.7808 - val_loss: 0.4730 - val_accuracy: 0.8110\n",
            "Epoch 2/20\n",
            "831/845 [============================>.] - ETA: 0s - loss: 0.4425 - accuracy: 0.8218\n",
            "Epoch 2: val_accuracy improved from 0.81098 to 0.82749, saving model to model.keras\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.4418 - accuracy: 0.8220 - val_loss: 0.4328 - val_accuracy: 0.8275\n",
            "Epoch 3/20\n",
            "835/845 [============================>.] - ETA: 0s - loss: 0.3974 - accuracy: 0.8398\n",
            "Epoch 3: val_accuracy improved from 0.82749 to 0.82941, saving model to model.keras\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.3976 - accuracy: 0.8398 - val_loss: 0.4248 - val_accuracy: 0.8294\n",
            "Epoch 4/20\n",
            "845/845 [==============================] - ETA: 0s - loss: 0.3678 - accuracy: 0.8512\n",
            "Epoch 4: val_accuracy improved from 0.82941 to 0.83763, saving model to model.keras\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.3678 - accuracy: 0.8512 - val_loss: 0.4022 - val_accuracy: 0.8376\n",
            "Epoch 5/20\n",
            "838/845 [============================>.] - ETA: 0s - loss: 0.3426 - accuracy: 0.8615\n",
            "Epoch 5: val_accuracy improved from 0.83763 to 0.84229, saving model to model.keras\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.3423 - accuracy: 0.8617 - val_loss: 0.3901 - val_accuracy: 0.8423\n",
            "Epoch 6/20\n",
            "834/845 [============================>.] - ETA: 0s - loss: 0.3207 - accuracy: 0.8693\n",
            "Epoch 6: val_accuracy improved from 0.84229 to 0.85398, saving model to model.keras\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.3204 - accuracy: 0.8693 - val_loss: 0.3735 - val_accuracy: 0.8540\n",
            "Epoch 7/20\n",
            "835/845 [============================>.] - ETA: 0s - loss: 0.2989 - accuracy: 0.8780\n",
            "Epoch 7: val_accuracy did not improve from 0.85398\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.2992 - accuracy: 0.8779 - val_loss: 0.3844 - val_accuracy: 0.8444\n",
            "Epoch 8/20\n",
            "843/845 [============================>.] - ETA: 0s - loss: 0.2789 - accuracy: 0.8880\n",
            "Epoch 8: val_accuracy did not improve from 0.85398\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.2790 - accuracy: 0.8879 - val_loss: 0.3750 - val_accuracy: 0.8533\n",
            "Epoch 9/20\n",
            "844/845 [============================>.] - ETA: 0s - loss: 0.2591 - accuracy: 0.8943\n",
            "Epoch 9: val_accuracy did not improve from 0.85398\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.2592 - accuracy: 0.8943 - val_loss: 0.3930 - val_accuracy: 0.8532\n",
            "Epoch 10/20\n",
            "836/845 [============================>.] - ETA: 0s - loss: 0.2419 - accuracy: 0.9000\n",
            "Epoch 10: val_accuracy did not improve from 0.85398\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.2419 - accuracy: 0.8998 - val_loss: 0.3976 - val_accuracy: 0.8529\n",
            "Epoch 11/20\n",
            "832/845 [============================>.] - ETA: 0s - loss: 0.2216 - accuracy: 0.9092\n",
            "Epoch 11: val_accuracy improved from 0.85398 to 0.85406, saving model to model.keras\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.2213 - accuracy: 0.9093 - val_loss: 0.4032 - val_accuracy: 0.8541\n",
            "Epoch 12/20\n",
            "837/845 [============================>.] - ETA: 0s - loss: 0.2027 - accuracy: 0.9175\n",
            "Epoch 12: val_accuracy did not improve from 0.85406\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.2032 - accuracy: 0.9173 - val_loss: 0.4238 - val_accuracy: 0.8480\n",
            "Epoch 13/20\n",
            "841/845 [============================>.] - ETA: 0s - loss: 0.1848 - accuracy: 0.9250\n",
            "Epoch 13: val_accuracy did not improve from 0.85406\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.1849 - accuracy: 0.9250 - val_loss: 0.4353 - val_accuracy: 0.8478\n",
            "Epoch 14/20\n",
            "831/845 [============================>.] - ETA: 0s - loss: 0.1682 - accuracy: 0.9325\n",
            "Epoch 14: val_accuracy did not improve from 0.85406\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.1684 - accuracy: 0.9323 - val_loss: 0.5057 - val_accuracy: 0.8417\n",
            "Epoch 15/20\n",
            "844/845 [============================>.] - ETA: 0s - loss: 0.1552 - accuracy: 0.9373\n",
            "Epoch 15: val_accuracy did not improve from 0.85406\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.1552 - accuracy: 0.9373 - val_loss: 0.4721 - val_accuracy: 0.8510\n",
            "Epoch 16/20\n",
            "836/845 [============================>.] - ETA: 0s - loss: 0.1391 - accuracy: 0.9443\n",
            "Epoch 16: val_accuracy did not improve from 0.85406\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.1393 - accuracy: 0.9443 - val_loss: 0.5037 - val_accuracy: 0.8504\n",
            "Epoch 17/20\n",
            "837/845 [============================>.] - ETA: 0s - loss: 0.1252 - accuracy: 0.9514\n",
            "Epoch 17: val_accuracy did not improve from 0.85406\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.1255 - accuracy: 0.9513 - val_loss: 0.5420 - val_accuracy: 0.8390\n",
            "Epoch 18/20\n",
            "834/845 [============================>.] - ETA: 0s - loss: 0.1141 - accuracy: 0.9557\n",
            "Epoch 18: val_accuracy did not improve from 0.85406\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.1140 - accuracy: 0.9558 - val_loss: 0.5818 - val_accuracy: 0.8517\n",
            "Epoch 19/20\n",
            "830/845 [============================>.] - ETA: 0s - loss: 0.1039 - accuracy: 0.9610\n",
            "Epoch 19: val_accuracy did not improve from 0.85406\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.1046 - accuracy: 0.9608 - val_loss: 0.6027 - val_accuracy: 0.8458\n",
            "Epoch 20/20\n",
            "830/845 [============================>.] - ETA: 0s - loss: 0.0992 - accuracy: 0.9620\n",
            "Epoch 20: val_accuracy did not improve from 0.85406\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.0995 - accuracy: 0.9619 - val_loss: 0.6544 - val_accuracy: 0.8444\n",
            "423/423 [==============================] - 1s 2ms/step - loss: 0.6544 - accuracy: 0.8444\n",
            "Loss: 0.6543635725975037, Accuracy: 0.8443605899810791\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_100 (Dense)           (None, 128)               16256     \n",
            "                                                                 \n",
            " dense_101 (Dense)           (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_102 (Dense)           (None, 512)               131584    \n",
            "                                                                 \n",
            " dense_103 (Dense)           (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_104 (Dense)           (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_105 (Dense)           (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 345475 (1.32 MB)\n",
            "Trainable params: 345475 (1.32 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Dense(128, input_shape=(X_train.shape[1],)),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(y_train.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "fit_model(model, X_train, y_train, X_test, y_test, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h1Wptlmtcd_"
      },
      "source": [
        "## Can we do better?\n",
        "As we saw above, our model tended to overfit the data near the end. Let's add some dropout layers, this will regularize the model's fit, reducing the tendency to overfit the data, and hopefully reaching a more accurate fit.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyIEqbdytWmQ",
        "outputId": "d9170117-ed54-4ff1-fa58-5768ba52dd81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "834/845 [============================>.] - ETA: 0s - loss: 0.6762 - accuracy: 0.7269\n",
            "Epoch 1: val_accuracy improved from -inf to 0.76125, saving model to model.keras\n",
            "845/845 [==============================] - 5s 4ms/step - loss: 0.6762 - accuracy: 0.7270 - val_loss: 0.6297 - val_accuracy: 0.7612\n",
            "Epoch 2/20\n",
            "842/845 [============================>.] - ETA: 0s - loss: 0.5866 - accuracy: 0.7679\n",
            "Epoch 2: val_accuracy improved from 0.76125 to 0.78404, saving model to model.keras\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.5866 - accuracy: 0.7679 - val_loss: 0.5651 - val_accuracy: 0.7840\n",
            "Epoch 3/20\n",
            "838/845 [============================>.] - ETA: 0s - loss: 0.5606 - accuracy: 0.7785\n",
            "Epoch 3: val_accuracy improved from 0.78404 to 0.79196, saving model to model.keras\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.5606 - accuracy: 0.7784 - val_loss: 0.5232 - val_accuracy: 0.7920\n",
            "Epoch 4/20\n",
            "836/845 [============================>.] - ETA: 0s - loss: 0.5496 - accuracy: 0.7835\n",
            "Epoch 4: val_accuracy improved from 0.79196 to 0.79811, saving model to model.keras\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.5494 - accuracy: 0.7835 - val_loss: 0.5042 - val_accuracy: 0.7981\n",
            "Epoch 5/20\n",
            "842/845 [============================>.] - ETA: 0s - loss: 0.5345 - accuracy: 0.7891\n",
            "Epoch 5: val_accuracy improved from 0.79811 to 0.80721, saving model to model.keras\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.5347 - accuracy: 0.7890 - val_loss: 0.4831 - val_accuracy: 0.8072\n",
            "Epoch 6/20\n",
            "832/845 [============================>.] - ETA: 0s - loss: 0.5248 - accuracy: 0.7926\n",
            "Epoch 6: val_accuracy improved from 0.80721 to 0.80928, saving model to model.keras\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.5248 - accuracy: 0.7928 - val_loss: 0.4865 - val_accuracy: 0.8093\n",
            "Epoch 7/20\n",
            "838/845 [============================>.] - ETA: 0s - loss: 0.5167 - accuracy: 0.7960\n",
            "Epoch 7: val_accuracy improved from 0.80928 to 0.81091, saving model to model.keras\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.5168 - accuracy: 0.7959 - val_loss: 0.4751 - val_accuracy: 0.8109\n",
            "Epoch 8/20\n",
            "842/845 [============================>.] - ETA: 0s - loss: 0.5105 - accuracy: 0.7992\n",
            "Epoch 8: val_accuracy improved from 0.81091 to 0.81291, saving model to model.keras\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.5102 - accuracy: 0.7994 - val_loss: 0.4763 - val_accuracy: 0.8129\n",
            "Epoch 9/20\n",
            "841/845 [============================>.] - ETA: 0s - loss: 0.5065 - accuracy: 0.7995\n",
            "Epoch 9: val_accuracy improved from 0.81291 to 0.81505, saving model to model.keras\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.5064 - accuracy: 0.7996 - val_loss: 0.4686 - val_accuracy: 0.8151\n",
            "Epoch 10/20\n",
            "838/845 [============================>.] - ETA: 0s - loss: 0.5014 - accuracy: 0.8025\n",
            "Epoch 10: val_accuracy did not improve from 0.81505\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.5012 - accuracy: 0.8025 - val_loss: 0.4697 - val_accuracy: 0.8143\n",
            "Epoch 11/20\n",
            "834/845 [============================>.] - ETA: 0s - loss: 0.4980 - accuracy: 0.8035\n",
            "Epoch 11: val_accuracy improved from 0.81505 to 0.81816, saving model to model.keras\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.4976 - accuracy: 0.8036 - val_loss: 0.4516 - val_accuracy: 0.8182\n",
            "Epoch 12/20\n",
            "841/845 [============================>.] - ETA: 0s - loss: 0.4960 - accuracy: 0.8034\n",
            "Epoch 12: val_accuracy improved from 0.81816 to 0.82430, saving model to model.keras\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.4959 - accuracy: 0.8034 - val_loss: 0.4475 - val_accuracy: 0.8243\n",
            "Epoch 13/20\n",
            "845/845 [==============================] - ETA: 0s - loss: 0.4919 - accuracy: 0.8059\n",
            "Epoch 13: val_accuracy did not improve from 0.82430\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.4919 - accuracy: 0.8059 - val_loss: 0.4548 - val_accuracy: 0.8208\n",
            "Epoch 14/20\n",
            "837/845 [============================>.] - ETA: 0s - loss: 0.4897 - accuracy: 0.8060\n",
            "Epoch 14: val_accuracy did not improve from 0.82430\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.4897 - accuracy: 0.8060 - val_loss: 0.4599 - val_accuracy: 0.8185\n",
            "Epoch 15/20\n",
            "834/845 [============================>.] - ETA: 0s - loss: 0.4893 - accuracy: 0.8061\n",
            "Epoch 15: val_accuracy did not improve from 0.82430\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.4886 - accuracy: 0.8064 - val_loss: 0.4521 - val_accuracy: 0.8184\n",
            "Epoch 16/20\n",
            "845/845 [==============================] - ETA: 0s - loss: 0.4831 - accuracy: 0.8100\n",
            "Epoch 16: val_accuracy improved from 0.82430 to 0.82586, saving model to model.keras\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.4831 - accuracy: 0.8100 - val_loss: 0.4440 - val_accuracy: 0.8259\n",
            "Epoch 17/20\n",
            "845/845 [==============================] - ETA: 0s - loss: 0.4832 - accuracy: 0.8083\n",
            "Epoch 17: val_accuracy did not improve from 0.82586\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.4832 - accuracy: 0.8083 - val_loss: 0.4419 - val_accuracy: 0.8246\n",
            "Epoch 18/20\n",
            "845/845 [==============================] - ETA: 0s - loss: 0.4792 - accuracy: 0.8093\n",
            "Epoch 18: val_accuracy did not improve from 0.82586\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.4792 - accuracy: 0.8093 - val_loss: 0.4646 - val_accuracy: 0.8185\n",
            "Epoch 19/20\n",
            "841/845 [============================>.] - ETA: 0s - loss: 0.4793 - accuracy: 0.8105\n",
            "Epoch 19: val_accuracy did not improve from 0.82586\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.4793 - accuracy: 0.8107 - val_loss: 0.4464 - val_accuracy: 0.8244\n",
            "Epoch 20/20\n",
            "839/845 [============================>.] - ETA: 0s - loss: 0.4780 - accuracy: 0.8120\n",
            "Epoch 20: val_accuracy improved from 0.82586 to 0.82734, saving model to model.keras\n",
            "845/845 [==============================] - 3s 4ms/step - loss: 0.4780 - accuracy: 0.8119 - val_loss: 0.4384 - val_accuracy: 0.8273\n",
            "423/423 [==============================] - 1s 2ms/step - loss: 0.4384 - accuracy: 0.8273\n",
            "Loss: 0.4383678734302521, Accuracy: 0.8273386359214783\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_106 (Dense)           (None, 128)               16256     \n",
            "                                                                 \n",
            " dropout_35 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_107 (Dense)           (None, 256)               33024     \n",
            "                                                                 \n",
            " dropout_36 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_108 (Dense)           (None, 512)               131584    \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_109 (Dense)           (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_110 (Dense)           (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_111 (Dense)           (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 345475 (1.32 MB)\n",
            "Trainable params: 345475 (1.32 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Dense(128, input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.5),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.1),\n",
        "    Dense(y_train.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "fit_model(model, X_train, y_train, X_test, y_test, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcr6fT0hvn_q"
      },
      "source": [
        "# Let's add some layers\n",
        "Okay, since we are still topping out at around the mid 80s for validation accuracy, which is about the same as the SVM, I am lead to think that maybe the dataset is to blame. Just to see if we can get a higher validation accurcy, let's add some more layers, and hope the model has more than enough topology to learn to predict the 43rd attribute of our dataset. With the addition of the new Dense layers, let's add some batch normalization in between each layer. This will help speed up the training process, because the calculations will now be performed with smaller values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yH0O1oKsSdy",
        "outputId": "88a96f85-c2a6-4890-8f3a-668f251a3801"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "840/845 [============================>.] - ETA: 0s - loss: 0.7140 - accuracy: 0.7132\n",
            "Epoch 1: val_accuracy improved from -inf to 0.79611, saving model to model.keras\n",
            "845/845 [==============================] - 10s 7ms/step - loss: 0.7135 - accuracy: 0.7133 - val_loss: 0.5193 - val_accuracy: 0.7961\n",
            "Epoch 2/20\n",
            "840/845 [============================>.] - ETA: 0s - loss: 0.5485 - accuracy: 0.7822\n",
            "Epoch 2: val_accuracy improved from 0.79611 to 0.79951, saving model to model.keras\n",
            "845/845 [==============================] - 6s 7ms/step - loss: 0.5484 - accuracy: 0.7821 - val_loss: 0.4927 - val_accuracy: 0.7995\n",
            "Epoch 3/20\n",
            "839/845 [============================>.] - ETA: 0s - loss: 0.5174 - accuracy: 0.7945\n",
            "Epoch 3: val_accuracy improved from 0.79951 to 0.80780, saving model to model.keras\n",
            "845/845 [==============================] - 6s 7ms/step - loss: 0.5171 - accuracy: 0.7946 - val_loss: 0.4754 - val_accuracy: 0.8078\n",
            "Epoch 4/20\n",
            "841/845 [============================>.] - ETA: 0s - loss: 0.4978 - accuracy: 0.8005\n",
            "Epoch 4: val_accuracy improved from 0.80780 to 0.81491, saving model to model.keras\n",
            "845/845 [==============================] - 6s 7ms/step - loss: 0.4978 - accuracy: 0.8006 - val_loss: 0.4597 - val_accuracy: 0.8149\n",
            "Epoch 5/20\n",
            "840/845 [============================>.] - ETA: 0s - loss: 0.4871 - accuracy: 0.8057\n",
            "Epoch 5: val_accuracy improved from 0.81491 to 0.81690, saving model to model.keras\n",
            "845/845 [==============================] - 6s 7ms/step - loss: 0.4874 - accuracy: 0.8055 - val_loss: 0.4464 - val_accuracy: 0.8169\n",
            "Epoch 6/20\n",
            "843/845 [============================>.] - ETA: 0s - loss: 0.4774 - accuracy: 0.8102\n",
            "Epoch 6: val_accuracy improved from 0.81690 to 0.82031, saving model to model.keras\n",
            "845/845 [==============================] - 6s 7ms/step - loss: 0.4775 - accuracy: 0.8102 - val_loss: 0.4457 - val_accuracy: 0.8203\n",
            "Epoch 7/20\n",
            "838/845 [============================>.] - ETA: 0s - loss: 0.4701 - accuracy: 0.8143\n",
            "Epoch 7: val_accuracy improved from 0.82031 to 0.82179, saving model to model.keras\n",
            "845/845 [==============================] - 6s 7ms/step - loss: 0.4700 - accuracy: 0.8142 - val_loss: 0.4378 - val_accuracy: 0.8218\n",
            "Epoch 8/20\n",
            "838/845 [============================>.] - ETA: 0s - loss: 0.4602 - accuracy: 0.8163\n",
            "Epoch 8: val_accuracy improved from 0.82179 to 0.83496, saving model to model.keras\n",
            "845/845 [==============================] - 6s 7ms/step - loss: 0.4601 - accuracy: 0.8162 - val_loss: 0.4144 - val_accuracy: 0.8350\n",
            "Epoch 9/20\n",
            "840/845 [============================>.] - ETA: 0s - loss: 0.4544 - accuracy: 0.8182\n",
            "Epoch 9: val_accuracy did not improve from 0.83496\n",
            "845/845 [==============================] - 6s 7ms/step - loss: 0.4548 - accuracy: 0.8180 - val_loss: 0.4225 - val_accuracy: 0.8345\n",
            "Epoch 10/20\n",
            "844/845 [============================>.] - ETA: 0s - loss: 0.4478 - accuracy: 0.8210\n",
            "Epoch 10: val_accuracy improved from 0.83496 to 0.83674, saving model to model.keras\n",
            "845/845 [==============================] - 6s 7ms/step - loss: 0.4478 - accuracy: 0.8209 - val_loss: 0.4049 - val_accuracy: 0.8367\n",
            "Epoch 11/20\n",
            "844/845 [============================>.] - ETA: 0s - loss: 0.4402 - accuracy: 0.8244\n",
            "Epoch 11: val_accuracy improved from 0.83674 to 0.84103, saving model to model.keras\n",
            "845/845 [==============================] - 6s 7ms/step - loss: 0.4402 - accuracy: 0.8244 - val_loss: 0.4009 - val_accuracy: 0.8410\n",
            "Epoch 12/20\n",
            "838/845 [============================>.] - ETA: 0s - loss: 0.4368 - accuracy: 0.8258\n",
            "Epoch 12: val_accuracy did not improve from 0.84103\n",
            "845/845 [==============================] - 6s 7ms/step - loss: 0.4364 - accuracy: 0.8260 - val_loss: 0.4092 - val_accuracy: 0.8320\n",
            "Epoch 13/20\n",
            "845/845 [==============================] - ETA: 0s - loss: 0.4329 - accuracy: 0.8267\n",
            "Epoch 13: val_accuracy improved from 0.84103 to 0.84347, saving model to model.keras\n",
            "845/845 [==============================] - 6s 7ms/step - loss: 0.4329 - accuracy: 0.8267 - val_loss: 0.3934 - val_accuracy: 0.8435\n",
            "Epoch 14/20\n",
            "839/845 [============================>.] - ETA: 0s - loss: 0.4285 - accuracy: 0.8281\n",
            "Epoch 14: val_accuracy improved from 0.84347 to 0.84443, saving model to model.keras\n",
            "845/845 [==============================] - 6s 7ms/step - loss: 0.4285 - accuracy: 0.8282 - val_loss: 0.3891 - val_accuracy: 0.8444\n",
            "Epoch 15/20\n",
            "839/845 [============================>.] - ETA: 0s - loss: 0.4225 - accuracy: 0.8298\n",
            "Epoch 15: val_accuracy improved from 0.84443 to 0.84495, saving model to model.keras\n",
            "845/845 [==============================] - 6s 7ms/step - loss: 0.4222 - accuracy: 0.8299 - val_loss: 0.3825 - val_accuracy: 0.8450\n",
            "Epoch 16/20\n",
            "841/845 [============================>.] - ETA: 0s - loss: 0.4204 - accuracy: 0.8311\n",
            "Epoch 16: val_accuracy improved from 0.84495 to 0.84532, saving model to model.keras\n",
            "845/845 [==============================] - 6s 7ms/step - loss: 0.4206 - accuracy: 0.8310 - val_loss: 0.3810 - val_accuracy: 0.8453\n",
            "Epoch 17/20\n",
            "843/845 [============================>.] - ETA: 0s - loss: 0.4129 - accuracy: 0.8347\n",
            "Epoch 17: val_accuracy improved from 0.84532 to 0.84784, saving model to model.keras\n",
            "845/845 [==============================] - 6s 7ms/step - loss: 0.4131 - accuracy: 0.8346 - val_loss: 0.3824 - val_accuracy: 0.8478\n",
            "Epoch 18/20\n",
            "839/845 [============================>.] - ETA: 0s - loss: 0.4093 - accuracy: 0.8356\n",
            "Epoch 18: val_accuracy improved from 0.84784 to 0.85258, saving model to model.keras\n",
            "845/845 [==============================] - 6s 7ms/step - loss: 0.4091 - accuracy: 0.8357 - val_loss: 0.3702 - val_accuracy: 0.8526\n",
            "Epoch 19/20\n",
            "840/845 [============================>.] - ETA: 0s - loss: 0.4082 - accuracy: 0.8367\n",
            "Epoch 19: val_accuracy did not improve from 0.85258\n",
            "845/845 [==============================] - 6s 7ms/step - loss: 0.4084 - accuracy: 0.8367 - val_loss: 0.3712 - val_accuracy: 0.8509\n",
            "Epoch 20/20\n",
            "837/845 [============================>.] - ETA: 0s - loss: 0.4026 - accuracy: 0.8380\n",
            "Epoch 20: val_accuracy improved from 0.85258 to 0.85295, saving model to model.keras\n",
            "845/845 [==============================] - 6s 7ms/step - loss: 0.4027 - accuracy: 0.8379 - val_loss: 0.3703 - val_accuracy: 0.8529\n",
            "423/423 [==============================] - 1s 2ms/step - loss: 0.3703 - accuracy: 0.8529\n",
            "Loss: 0.37031835317611694, Accuracy: 0.8529455065727234\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_112 (Dense)           (None, 1024)              130048    \n",
            "                                                                 \n",
            " batch_normalization_25 (Ba  (None, 1024)              4096      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_113 (Dense)           (None, 512)               524800    \n",
            "                                                                 \n",
            " batch_normalization_26 (Ba  (None, 512)               2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_114 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " batch_normalization_27 (Ba  (None, 512)               2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_115 (Dense)           (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_28 (Ba  (None, 256)               1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_116 (Dense)           (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_29 (Ba  (None, 128)               512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_117 (Dense)           (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1091843 (4.17 MB)\n",
            "Trainable params: 1086979 (4.15 MB)\n",
            "Non-trainable params: 4864 (19.00 KB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Dense(1024, input_shape=(X_train.shape[1],)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(256, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "    Dense(y_train.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "fit_model(model, X_train, y_train, X_test, y_test, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s40oQVpkxZ0o"
      },
      "source": [
        "# Not great\n",
        "\n",
        "Still no big breakthroughs by the looks of it. Let's look at a confusion matrix, and see if we can get any ideas at all about how we could help our model learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "jPmZjPOexZgJ",
        "outputId": "3b9e26cb-5d7a-4235-bcc9-c00a4f776680"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "423/423 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqsAAAIjCAYAAAAk+FJEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABI8klEQVR4nO3dd3RU1d7G8WcSUkghlRogoRN6U0qABClKx4iAiBRBiohIlSJdiiBNQKoUARWUphRBDAFR5KKEIiC9F4HQQg/JvH9wmdcxcE0iyWzw+1mLtZg9++zz24GZPNnZ54zFarVaBQAAABjIydEFAAAAAI9CWAUAAICxCKsAAAAwFmEVAAAAxiKsAgAAwFiEVQAAABiLsAoAAABjEVYBAABgLMIqAAAAjEVYBYCHOHjwoGrVqiUfHx9ZLBYtX778sY5/7NgxWSwWzZ0797GO+ySLiIhQRESEo8sAYBjCKgBjHT58WB06dFDevHnl7u6uTJkyKSwsTBMnTtStW7fS9NytWrXS7t27NXz4cM2fP1/lypVL0/Olp9atW8tisShTpkwP/ToePHhQFotFFotFH374YYrHP3PmjAYPHqwdO3Y8hmoB/NtlcHQBAPAwq1at0ssvvyw3Nze1bNlSxYoV0927d7V582b16tVLe/bs0YwZM9Lk3Ldu3dKWLVvUv39/vfXWW2lyjuDgYN26dUsuLi5pMv7fyZAhg27evKlvvvlGTZo0sXtu4cKFcnd31+3bt1M19pkzZzRkyBCFhISoVKlSyT5u3bp1qTofgKcbYRWAcY4ePapmzZopODhYUVFRyp49u+25zp0769ChQ1q1alWanf/ChQuSJF9f3zQ7h8Vikbu7e5qN/3fc3NwUFhamzz//PElY/eyzz1S3bl0tWbIkXWq5efOmPDw85Orqmi7nA/BkYRsAAOOMHj1a169f1yeffGIXVB/Inz+/unbtant87949DRs2TPny5ZObm5tCQkLUr18/3blzx+64kJAQ1atXT5s3b9azzz4rd3d35c2bV59++qmtz+DBgxUcHCxJ6tWrlywWi0JCQiTd//X5g7//2eDBg2WxWOzavvvuO1WuXFm+vr7y8vJSoUKF1K9fP9vzj9qzGhUVpSpVqsjT01O+vr5q2LCh9u3b99DzHTp0SK1bt5avr698fHzUpk0b3bx589Ff2L9o3ry51qxZoytXrtjatm3bpoMHD6p58+ZJ+l+6dEk9e/ZU8eLF5eXlpUyZMql27drauXOnrU90dLSeeeYZSVKbNm1s2wkezDMiIkLFihXTr7/+qqpVq8rDw8P2dfnrntVWrVrJ3d09yfyff/55+fn56cyZM8meK4AnF2EVgHG++eYb5c2bV5UqVUpW/3bt2mngwIEqU6aMxo8fr/DwcI0cOVLNmjVL0vfQoUNq3LixatasqbFjx8rPz0+tW7fWnj17JEmRkZEaP368JOmVV17R/PnzNWHChBTVv2fPHtWrV0937tzR0KFDNXbsWDVo0EA//vjj/zxu/fr1ev7553X+/HkNHjxY3bt3108//aSwsDAdO3YsSf8mTZooLi5OI0eOVJMmTTR37lwNGTIk2XVGRkbKYrFo6dKltrbPPvtMhQsXVpkyZZL0P3LkiJYvX6569epp3Lhx6tWrl3bv3q3w8HBbcAwNDdXQoUMlSe3bt9f8+fM1f/58Va1a1TZObGysateurVKlSmnChAmqVq3aQ+ubOHGiMmfOrFatWikhIUGSNH36dK1bt06TJk1Sjhw5kj1XAE8wKwAY5OrVq1ZJ1oYNGyar/44dO6ySrO3atbNr79mzp1WSNSoqytYWHBxslWTdtGmTre38+fNWNzc3a48ePWxtR48etUqyjhkzxm7MVq1aWYODg5PUMGjQIOuf307Hjx9vlWS9cOHCI+t+cI45c+bY2kqVKmXNkiWLNTY21ta2c+dOq5OTk7Vly5ZJzvf666/bjfniiy9aAwICHnnOP8/D09PTarVarY0bN7ZWr17darVarQkJCdZs2bJZhwwZ8tCvwe3bt60JCQlJ5uHm5mYdOnSorW3btm1J5vZAeHi4VZJ12rRpD30uPDzcrm3t2rVWSdb333/feuTIEauXl5e1UaNGfztHAE8PVlYBGOXatWuSJG9v72T1X716tSSpe/fudu09evSQpCR7W4sUKaIqVarYHmfOnFmFChXSkSNHUl3zXz3Y67pixQolJiYm65izZ89qx44dat26tfz9/W3tJUqUUM2aNW3z/LOOHTvaPa5SpYpiY2NtX8PkaN68uaKjo3Xu3DlFRUXp3LlzD90CIN3f5+rkdP/bRkJCgmJjY21bHLZv357sc7q5ualNmzbJ6lurVi116NBBQ4cOVWRkpNzd3TV9+vRknwvAk4+wCsAomTJlkiTFxcUlq//x48fl5OSk/Pnz27Vny5ZNvr6+On78uF177ty5k4zh5+eny5cvp7LipJo2baqwsDC1a9dOWbNmVbNmzbR48eL/GVwf1FmoUKEkz4WGhurixYu6ceOGXftf5+Ln5ydJKZpLnTp15O3trUWLFmnhwoV65plnknwtH0hMTNT48eNVoEABubm5KTAwUJkzZ9auXbt09erVZJ8zKCgoRRdTffjhh/L399eOHTv00UcfKUuWLMk+FsCTj7AKwCiZMmVSjhw59Ntvv6XouL9e4PQozs7OD223Wq2pPseD/ZQPZMyYUZs2bdL69ev12muvadeuXWratKlq1qyZpO8/8U/m8oCbm5siIyM1b948LVu27JGrqpI0YsQIde/eXVWrVtWCBQu0du1afffddypatGiyV5Cl+1+flIiJidH58+clSbt3707RsQCefIRVAMapV6+eDh8+rC1btvxt3+DgYCUmJurgwYN27X/88YeuXLliu7L/cfDz87O7cv6Bv67eSpKTk5OqV6+ucePGae/evRo+fLiioqK0YcOGh479oM79+/cnee73339XYGCgPD09/9kEHqF58+aKiYlRXFzcQy9Ke+Crr75StWrV9Mknn6hZs2aqVauWatSokeRrktwfHJLjxo0batOmjYoUKaL27dtr9OjR2rZt22MbH4D5CKsAjNO7d295enqqXbt2+uOPP5I8f/jwYU2cOFHS/V9jS0pyxf64ceMkSXXr1n1sdeXLl09Xr17Vrl27bG1nz57VsmXL7PpdunQpybEPbo7/19tpPZA9e3aVKlVK8+bNswt/v/32m9atW2ebZ1qoVq2ahg0bpsmTJytbtmyP7Ofs7Jxk1fbLL7/U6dOn7doehOqHBfuUevfdd3XixAnNmzdP48aNU0hIiFq1avXIryOApw8fCgDAOPny5dNnn32mpk2bKjQ01O4TrH766Sd9+eWXat26tSSpZMmSatWqlWbMmKErV64oPDxc//nPfzRv3jw1atTokbdFSo1mzZrp3Xff1Ysvvqi3335bN2/e1NSpU1WwYEG7C4yGDh2qTZs2qW7dugoODtb58+f18ccfK2fOnKpcufIjxx8zZoxq166tihUrqm3btrp165YmTZokHx8fDR48+LHN46+cnJz03nvv/W2/evXqaejQoWrTpo0qVaqk3bt3a+HChcqbN69dv3z58snX11fTpk2Tt7e3PD09Vb58eeXJkydFdUVFRenjjz/WoEGDbLfSmjNnjiIiIjRgwACNHj06ReMBeDKxsgrASA0aNNCuXbvUuHFjrVixQp07d1afPn107NgxjR07Vh999JGt76xZszRkyBBt27ZN77zzjqKiotS3b1998cUXj7WmgIAALVu2TB4eHurdu7fmzZunkSNHqn79+klqz507t2bPnq3OnTtrypQpqlq1qqKiouTj4/PI8WvUqKFvv/1WAQEBGjhwoD788ENVqFBBP/74Y4qDXlro16+fevToobVr16pr167avn27Vq1apVy5ctn1c3Fx0bx58+Ts7KyOHTvqlVde0caNG1N0rri4OL3++usqXbq0+vfvb2uvUqWKunbtqrFjx+rnn39+LPMCYDaLNSU78QEAAIB0xMoqAAAAjEVYBQAAgLEIqwAAADAWYRUAAADGIqwCAADAWIRVAAAAGIuwCgAAAGM9lZ9gFXc70dElAE+kx/mZ7sC/ya34BEeXADxxMnslL4aysgoAAABjEVYBAABgLMIqAAAAjEVYBQAAgLEIqwAAADAWYRUAAADGIqwCAADAWIRVAAAAGIuwCgAAAGMRVgEAAGAswioAAACMRVgFAACAsQirAAAAMBZhFQAAAMYirAIAAMBYhFUAAAAYi7AKAAAAYxFWAQAAYCzCKgAAAIxFWAUAAICxCKsAAAAwFmEVAAAAxiKsAgAAwFiEVQAAABiLsAoAAABjEVYBAABgLMIqAAAAjEVYBQAAgLEIqwAAADAWYRUAAADGIqwCAADAWIRVAAAAGIuwCgAAAGMRVgEAAGAswioAAACMRVgFAACAsQirAAAAMBZhFQAAAMYirAIAAMBYhFUAAAAYi7AKAAAAYxFWAQAAYCzCKgAAAIxFWAUAAICxCKsAAAAwFmEVAAAAxiKsAgAAwFiEVQAAABiLsAoAAABjEVYBAABgLMIqAAAAjEVYBQAAgLEIqwAAADAWYRUAAADGIqwCAADAWIRVAAAAGIuwCgAAAGMRVgEAAGAswioAAACMRVgFAACAsQirAAAAMBZhFQAAAMbK4OgCcufOrYiICIWHhysiIkL58uVzdEkAAAAwhMVqtVodWcCCBQu0adMmRUdH69ChQwoKClJ4eLgtvBYoUCDFY8bdTkyDSoGnn8VicXQJwBPpVnyCo0sAnjiZvZK3ZurwsPpnZ8+e1caNG7Vy5UotWrRIiYmJSkhI+RsAYRVIHcIqkDqEVSDlkhtWHb4NQJJu3rypzZs3Kzo6Whs2bFBMTIyKFSumiIgIR5cGAAAAB3L4ymqlSpUUExOj0NBQ297VqlWrys/PL9VjsrIKpA4rq0DqsLIKpFxyV1YdfjeA33//XZ6enipcuLAKFy6s0NDQfxRUAQAA8PRweFiNjY1VVFSUKlSooLVr1yosLExBQUFq3ry5Zs6c6ejyAAAA4EAO3wbwZ1arVb/++qsmT56shQsXcoEVkM7YBgCkDtsAgJR7Yi6w2r59u6KjoxUdHa3NmzcrLi5OxYsXV5cuXRQeHu7o8pAMXy3+XF8t/kJnz5yWJOXNl1/tOrypsMpVJUnt27bU9l+22R0T2bip+g0YLEn6ZsUyDRnY76Fjr4vaLP+AgLQrHnCQ2bOma8P33+nY0SNyc3NXiVKl9fY7PRSSJ6+tz8WLFzRx3Bht3fKTbty4oeCQPGr7RgdVr/m8rc++vXs0acJY7dmzW85OTnquRi1179VHHh6ejpgWkC4unP9DUz8ap59/+kG3b99Wzpy51W/w+ypcpFiSvmNGDNGKJYv1do931aR5S1v7/n17NXXSOP2+5zc5OTsp/Lma6tK9N68dAzl8ZTVDhgwqXbq07d6qVatWlY+Pzz8ak5XV9LUpeoOcnJ2UO3ewrFarVn6zQvPnztbCRUuUL38BtW/bUsHBIerwZhfbMe7uGeXl5SVJun37tq5fj7Mbc8iAfrpz945mfPJpus7l346V1fTzVsd2qlW7jooWLa6EhARN/mi8Dh86qK+WrVRGDw9J0psdXtf1uDj17jtAvn5++nb1Sk3/eJLmf/6VCocW0YXzf6hJZAPVfL62mrdoqRs3bmjs6BEKDMys0eM+cvAM/11YWU0/165d1evNG6tMuWfVqHFT+fr569SJ4wrKmUtBuXLb9d0YtV5zZn6sK5cvq3nLNrawevHCeb3WpKGq16ytJs1f040b1/XR2FEKCMys90dPcMCs/p2emJXVS5cuKVOmTI4uA/9A1Yhqdo87d3lHSxZ/od27dipf/vsf6uDu7q7AwMwPPd7d3V3u7u62x5cvXdK2/2zVgMHD0q5owMEmT5tl93jIsJGqEVFJ+/buUZlyz0iSdu3Yob7vDVKx4iUkSe3ad9Jn8+dq3949KhxaRD9silaGDBnUp/9AOTndvwSh73uD1axxQ508cVy5cgen76SAdLBw7ifKkjWb+g0ebmvLEZQzSb8L5//QhDEjNHbyDPXu2snuuR9/iFaGDC7q3uc922unZ99BatXsRZ06eVw5c/HaMYnDL7AiqD5dEhIStHbNKt26dVMlSpayta9ZvVLVwyuqSWR9TZ44Trdv3XrkGKu+WSH3jO52v+oEnnYPfruQ6U+/WSpRqpTWrV2tq1evKDExUWvXrNKdO3dV7plnJUl3796Vi4uL7ZutJNsPfjExv6Zj9UD6+XHTBhUuUlTv9e6mejWqqE3zl/T10i/t+iQmJmrYgD565bU2ypsvf5Ix4u/GJ3ntuLm7SZJ2xWxP2wkgxRweVhMSEvThhx/q2WefVbZs2eTv72/3B0+GQwcPqEqFsqr0TEmNHD5EY8ZPsr1BvFC7noYNH63ps+apTdv2Wr3yaw3o1/uRY61YvkQv1K5rt9oKPM0SExP14egRKlm6jPIXKGhr/2DMBN27d0/PVamgCuVKaPiwQfpwwiTbiukzz1bQxdiL+nTOJ4qPv6tr165q0oSxkqSLFy44ZC5AWjtz+pSWf7VIuXIHa9zkGWrUuKkmfDhSa75ZbuuzcO4ncnbOoJdfafHQMco8U16xFy/qs09n21470yaNlyTFXryYHtNACjg8rA4ZMkTjxo1T06ZNdfXqVXXv3l2RkZFycnLS4MGD//b4O3fu6Nq1a3Z/7ty5k/aFw05wSIg+W7xUcxcsUuOXm2nwgL46cviQJCmycRNVDKus/AUKqnbd+hry/ihtiFqvUydPJBln184YHT1yWA1fbJzeUwAcZtTwoTp86KBGfjDOrn3qlImKuxanqTPmaMHnX6nFa63Vp1c3HTywX5KUL38BDRk2Ugs+naOwZ0urVrXKyhGUUwEBgXYrRsDTJDExUQULF1GHt95RwcKhahjZRA0aNdbyJYslSb/v26Mvv5iv/kOGP3Ifft58+dV/yHB9sWCuaoSVU8Na4cqeI6f8AwJkcWLvvmkc/m62cOFCzZw5Uz169FCGDBn0yiuvaNasWRo4cKB+/vnnvz1+5MiR8vHxsfszdsyodKgcf+bi4qpcuYMVWqSo3uraXQULFtLnC+c/tO+D/XcnTyQNq8uXfqWChUIVWqRomtYLmOKDEUO1eVO0ps/6VFmzZbO1nzx5Qos+X6hBQ4fr2QoVVbBQYbXv9JaKFCmmLxd9ZutXu259rduwWWvWb1TUDz+rQ6e3dPnyJQXlzOWI6QBpLiAws0Ly5LNrC86TV3+cOytJ2hXzqy5fuqSX6tZQ+LMlFP5sCZ07e0aTx49R43o1bcfUql1PX6/bpGVrorQq6ke93uFNXbl8WTmCeO2YxuEXWJ07d07FixeXJHl5eenq1auSpHr16mnAgAF/e3zfvn3VvXt3u7a7VpfHXyhSJDHRqvj4uw99bv/+3yVJgZntL7i6efOG1q/7Vp3f7v6ww4CnitVq1eiRw7Qhar1mfPKpgnLaXyDyYF/3X1dInZydlJiY9I4nAQGBkqQVy5bI1dVNFSpUSqPKAccqXrK0Thw/atd28sQxZcueQ5L0fJ0GKvdsRbvnu7/VXs/Xqa+6DV5MMp7/f187K1cslaurm56pUDFJHziWw8Nqzpw5dfbsWeXOnVv58uXTunXrVKZMGW3btk1ubm5/e7ybm1uSfty6Kn1NnjhOlSpXUbZsOXTz5g19u3qlfv3lP5o0daZOnTyhb1evVFiVcPn4+Orgwf0aN2aUypQtpwIFC9mNs+7bNUpISFCduvUdNBMg/YwaPlTfrlmpcROnyMPTUxcv3t9j6uXlLXd3d4XkyatcuYM1fOggvdOjt3x8fRUdtV5bt/ykCZOn2cZZ9PkClShZWh4eHtr680+aMG6MunTtLm8uXsVTqumrLdWxTQt9OnuGnqv5vPb+tltfL/1KvfsPliT5+PrKx9fX7pgMGTIoIDBQuUPy2NqWLFqoYiVKK6OHh7Zt/UkfTxirjl26ydub145pHB5WX3zxRX3//fcqX768unTpohYtWuiTTz7RiRMn1K1bN0eXh2S4dClWg97ro4sXLsjLy1sFChbUpKkzVaFimM6dO6v/bN2izxd+qlu3bilrtmx6rkZNtX2jU5Jxvl6+RNWq1+SbLP4Vvlr8uSSp/est7doHDRuhBg0j5eLioo+mTNekCWPVrUsn3bx5U7ly59aQ90epcpX//8CUPbt3a/rHk3Tz5k2F5Mmr/gOGqG79huk6FyA9hRYtrhEfTtT0yRM0d+ZUZc+RU2/3eFe16tRL0Th79/ymT6ZP0a2bN5U7JI969R+kF+o2SKOq8U84/EMB/urnn3/WTz/9pAIFCqh+/dStsLGyCqQOHwoApA4fCgCkXHI/FMChYTU+Pl4dOnTQgAEDlCdPnr8/IJkIq0DqEFaB1CGsAimX3LDq0LsBuLi4aMmSJY4sAQAAAAZz+K2rGjVqpOXLlzu6DAAAABjI4RdYFShQQEOHDtWPP/6osmXLytPT0+75t99+20GVAQAAwNEcfoHV/9qrarFYdOTIkRSPyZ5VIHXYswqkDntWgZR7Ii6wSiuEVSB1CKtA6hBWgZRLblh1yDaAv37i1KNYLBaNHTs2jasBAACAqRwSVmNiYuweb9++Xffu3VOhQvc/0ejAgQNydnZW2bJlHVEeAAAADOGQsLphwwbb38eNGydvb2/NmzdPfn5+kqTLly+rTZs2qlKliiPKAwAAgCEcvmc1KChI69atU9GiRe3af/vtN9WqVUtnzpxJ8ZjsWQVShz2rQOqwZxVIuSfiQwEk6dq1a7pw4UKS9gsXLiguLs4BFQEAAMAUDg+rL774otq0aaOlS5fq1KlTOnXqlJYsWaK2bdsqMjLS0eUBAADAgRy+DeDmzZvq2bOnZs+erfj4eElShgwZ1LZtW40ZMybJhwQkB9sAgNRhGwCQOmwDAFLuibvP6o0bN3T48GFJUr58+VIVUh8grAKpQ1gFUoewCqTcExdWHyfCKpA6hFUgdQirQMo9MRdYAQAAAI9CWAUAAICxCKsAAAAwFmEVAAAAxiKsAgAAwFiEVQAAABiLsAoAAABjEVYBAABgLMIqAAAAjEVYBQAAgLEIqwAAADAWYRUAAADGIqwCAADAWIRVAAAAGIuwCgAAAGMRVgEAAGAswioAAACMRVgFAACAsQirAAAAMBZhFQAAAMYirAIAAMBYhFUAAAAYi7AKAAAAYxFWAQAAYCzCKgAAAIxFWAUAAICxCKsAAAAwFmEVAAAAxiKsAgAAwFiEVQAAABiLsAoAAABjEVYBAABgLMIqAAAAjEVYBQAAgLEIqwAAADAWYRUAAADGIqwCAADAWIRVAAAAGIuwCgAAAGMRVgEAAGAswioAAACMRVgFAACAsQirAAAAMBZhFQAAAMYirAIAAMBYhFUAAAAYi7AKAAAAYxFWAQAAYCzCKgAAAIxFWAUAAICxCKsAAAAwFmEVAAAAxiKsAgAAwFiEVQAAABiLsAoAAABjEVYBAABgLMIqAAAAjJXB0QWkBWdni6NLAJ5I0QcuOLoE4IlUMU+Ao0sAnlqsrAIAAMBYhFUAAAAYi7AKAAAAYxFWAQAAYCzCKgAAAIxFWAUAAICxCKsAAAAwFmEVAAAAxiKsAgAAwFiEVQAAABiLsAoAAABjEVYBAABgLMIqAAAAjEVYBQAAgLEIqwAAADAWYRUAAADGIqwCAADAWIRVAAAAGIuwCgAAAGMRVgEAAGAswioAAACMRVgFAACAsQirAAAAMBZhFQAAAMYirAIAAMBYhFUAAAAYi7AKAAAAYxFWAQAAYCzCKgAAAIxFWAUAAICxCKsAAAAwFmEVAAAAxiKsAgAAwFiEVQAAABiLsAoAAABjEVYBAABgLMIqAAAAjEVYBQAAgLEIqwAAADAWYRUAAADGIqwCAADAWIRVAAAAGIuwCgAAAGMRVgEAAGAswioAAACMRVgFAACAsQirAAAAMBZhFQAAAMYirAIAAMBYhFUAAAAYi7AKAAAAYxFWAQAAYCzCKgAAAIxFWAUAAICxCKsAAAAwFmEVAAAAxiKsAgAAwFiEVQAAABiLsAoAAABjEVYBAABgLMIqAAAAjEVYBQAAgLEIqwAAADBWqsLqDz/8oBYtWqhixYo6ffq0JGn+/PnavHnzYy0OAAAA/24pDqtLlizR888/r4wZMyomJkZ37tyRJF29elUjRox47AUCAADg3yvFYfX999/XtGnTNHPmTLm4uNjaw8LCtH379sdaHAAAAP7dUhxW9+/fr6pVqyZp9/Hx0ZUrVx5HTQAAAICkVITVbNmy6dChQ0naN2/erLx586aqiHnz5mnVqlW2x71795avr68qVaqk48ePp2pMAAAAPPlSHFbfeOMNde3aVVu3bpXFYtGZM2e0cOFC9ezZU506dUpVESNGjFDGjBklSVu2bNGUKVM0evRoBQYGqlu3bqkaEwAAAE++DCk9oE+fPkpMTFT16tV18+ZNVa1aVW5uburZs6e6dOmSqiJOnjyp/PnzS5KWL1+ul156Se3bt1dYWJgiIiJSNSYAAACefCkOqxaLRf3791evXr106NAhXb9+XUWKFJGXl1eqi/Dy8lJsbKxy586tdevWqXv37pIkd3d33bp1K9XjIu19MnO6otZ/p2NHj8jN3V0lS5VW1249FJLn/7eE3LlzR+PGfKC1a1bp7t14VQwLU7/3BikgMFCSdOXKZfV/t5cOHNivq1euyN8/QBHPPae3unb/R/+vAJOsXzJfu37epPOnj8vF1U0hhYup/mudlCUot12/Y/t/06qFM3Xi4F5ZnJwUlKeAOgwYK1c3N0nS0A4v6/KFc3bH1G3RQTUiW9gex/wYpfVL5uvCmZPyyuSrynUi9Vyj5mk/SSCdfTp7pj6eNF5Nm7+mbr366syZ04qsW/OhfYePHqfqNV+QJG3bukUzPp6kw4cOyD1jRtWp30gdO3dVhgwpjkVIB6n+V3F1dVWRIkUeSxE1a9ZUu3btVLp0aR04cEB16tSRJO3Zs0chISGP5RxIG9t/2aamrzRX0WLFde9egiZPHK9O7dtp6YqVyujhIUn68IOR2rxpo0aPmygvLy+NGjFMPd7porkLPpckOVmcFF6tut7s0lV+/v46eeKERg0fqqtXB2nk6LGOnB7w2Bzes0OVa7+oXPlDlZiQoFULp2vakO5696P5cnO/vw3q2P7fNH1YT1WPbKHIdu/I2dlZp48dkpOTxW6s2s3aqkLN+rbHbhk9bH/ft/1nLZgwVJHt3lGhks/qj1PHtHjqaLm4uqlKnZfSZ7JAOti7Z7eWLVms/AUK2dqyZs2mVd9ttOu3fMmXWvjpbFUMqyJJOrj/d3Xv0lGt23bQwGEjdeH8eX0wYogSExL0dvfe6ToHJE+Kw2q1atVksVge+XxUVFSKi5gyZYree+89nTx5UkuWLFFAQIAk6ddff9Urr7yS4vGQfqZMn2X3eMjwkapetZL27t2jsuWeUVxcnJYvXaIRo8fo2fIV7vcZNlKRDepo184dKlGylDL5+KhJs///d86RI0gvN31Fn86Zna5zAdJSh4H2P3g179JPA9o00KnD+5WvaClJ0vLZk1SlTmO7VdK/rrxK98NpJr+Ah57nl41rVfzZKgp7vpEkKTBbDlWPbKGoZZ+pcu3I//n+DTwpbt68oUH9eqvvgCGaM2u6rd3Z2VkBgZnt+m7csF7Va74gDw9PSdL6dWuUv0Ahte3wpiQpV+5gvdW1h957t7vadugsT0/P9JsIkiXFYbVUqVJ2j+Pj47Vjxw799ttvatWqVaqK8PX11eTJk5O0DxkyJFXjwXGuX4+TdP9WZpK0b+8e3bsXrwoVKtn65MmbV9my57CF1b86f/4PRa3/TmXLPZMuNQOOcOvmDUmSh1cmSVLclcs6fnCvylStqYl9O+niudPKGpRbdV5tr7yhJeyO/X7ZQq37cp78MmdVmSo1FF6/iZyd77+d34uPl8t/tww84Orqpiux53X5wjn5Z8meDrMD0taHI99XWJVwPVuhkl1Y/avf9+7Rgf2/q2efAba2u3fvytXN1a6fm5ub7ty5o9/37VHZcs+mWd1InRSH1fHjxz+0ffDgwbp+/Xqqivj222/l5eWlypUrS7q/0jpz5kwVKVJEU6ZMkZ+fX6rGRfpKTEzUh6NGqFTpMspfoKAkKfbiBbm4uMg7Uya7vgEBAYq9eNGurU+v7tq4IUq3b99W1YhqGjj0/XSrHUhPiYmJWj77I+UpXFzZg+/v747944wkae2iOWrQ6k0F5SmgbdHf6uNB7+jdCfOUOUcuSVLVui8pZ95C8vDy1tH9v2nVgum6djlWjdrcv8C1UKlntWLOJB2o9ovyFyuji+dOacPXiyRJ1y7HElbxxPvu29Xa//tezV6w+G/7fr18iULy5FWJUqVtbRUqVdaiz+Zr3ZpVql7rBcXGXtTsGVMlSbEXLqRZ3Ui9FN+66lFatGih2bNT92vbXr166dq1a5Kk3bt3q0ePHqpTp46OHj1qu9jqUe7cuaNr167Z/XnwEbBIXyPfH6pDhw5q1JhxqTq+57t99dnipRo/6WOdOnlSY0ePeswVAmZYMnOczp44qpbdB9varNZESVKlWg1Uvnpd5cxbUC++/rayBOXS1qj/vw91RINmyl+stHKE5FfY843UsPVb+mH1Et2LvytJqlizvirXjtSsEe+qV5PnNLFPR5WuXF2S2AKAJ94f585q3JiRGjx8tNz+8huEv7p9+7bWrVml+o3s92qXrximt97pqQ9GDFHV8qXUpGEdVap8/8OOLE6PLRbhMXpsl71t2bJF7u7uqTr26NGjtou1lixZonr16mnEiBHavn277WKrRxk5cmSS7QL93huo/gMHp6oWpM6o4UP1w8ZofTJvgbJmy2ZrDwjMrPj4eMVdu2a3uhobG2u7G8ADgYGZFRiYWXny5pWPj49eb/mq3ujYSZkzZ0m3eQBpbcnM8dr7yxa99f4k+Qb+///tB3tQs+YKseufNShEly+cf+R4uQsUUWJCgi6dP6csQbllsVhUv2Un1X21va5duSSvTL46uPtXSVJA1hyPf0JAOvp93x5dvhSr1s0b29oSEhK0Y/sv+mrRZ9q0dYecnZ0lSRvWr9Pt27dUp17DJOM0f621XmnRShcvXJB3pkw6e+a0Pp40XkE5c6bbXJB8KQ6rkZGRdo+tVqvOnj2rX375RQMGDHjEUf+bq6urbt68KUlav369WrZsKUny9/e3rbg+St++fZOsviY4uT6iNx43q9WqD0YMU9T36zVzzqdJXuihRYoqQwYXbd26RTVqPi9JOnb0iM6dPfPQ/aoPJCbeX2WKv3s3zWoH0pPVatXSWRO0e+smdR76UZLg6J8lu3z8A3X+9Em79gtnTyq0dPlHjnvm6EFZnJzk5WO/XcrJ2Vm+AfcvNNn+w3qFFCqWpA/wpCn3bEUt/HKFXdv7g/orOE8evda6nS2oSve3AFQJf05+/v4PHctisShzlvs/MH737WplzZZNhQo/nrsc4fFKcVh9cOHMA05OTipUqJCGDh2qWrVqpaqIypUrq3v37goLC9N//vMfLVp0f3/VgQMHlPNvfspxc3NL8quAm/HWVNWBlBv5/lCtWb1S4z+aIk9PT128eH+/j5eXt9zd3eXt7a1GkS9p7OgP5OPjI09PL30w4n2VKFnKFlZ/2LRRl2Ivqmix4vLw8NDhQ4c0fuwYlSpdRjmC+CkXT4clM8bp1x/Wq23fEXLL6KFrl2MlSe4eXnJ1c5PFYlG1hq/o20WzlSMk3/09qxu+1fnTx9W61zBJ929tdfzAXuUvVkZuGT10fP9vWj5nkspWrSUPL29J0vVrV7RzS7TyFy2te/F3tTVqtXZu2aDOwyY5bO7A4+Lp6al8+QvYtblnzCgfH1+79pMnjmvH9l80btK0h46zYN4nqlCpipycLIr+fr0+nTNTw0ePswu7MEeKwmpCQoLatGmj4sWLP9aLniZPnqw333xTX331laZOnaqgoCBJ0po1a/TCCy88tvPg8fty0f17pb7RpqVd+5D3R6hBo/ur8D3f7SsnJyf1fKer7sbfVaVKldV3wEBbX3d3Ny396kt9OHqU4u/eVdZs2fRcjVp6ve0b6TcRII39uHa5JGnKgLft2l95q6+efe7+dqfw+k0UH39XK+ZM1s3r15QjJL86DhqvwGz33xOdM7goZvP3+nbRHCXcuyv/LNkVXr+JIho0tRtz24Zv9fW8jyWrVcGFiqrz0I8UXIAVI/x7rFyxVFmyZlX5imEPfX7Lj5s1d9YMxcffVf6ChTR6/GTbvlWYx2K1WlO0DOnu7q59+/YpT548aVXTP8bKKpA60Qe4EhZIjYp5Hn7fWwCP5ueRvJXsFG8DKFasmI4cOfLYw2pCQoKWL1+uffv2SZKKFi2qBg0asCQPAADwL5bildVvv/1Wffv21bBhw1S2bNkkn/SQ6S/300yOQ4cOqU6dOjp9+rQKFbr/sWn79+9Xrly5tGrVKuXLly9F47GyCqQOK6tA6rCyCqRccldWkx1Whw4dqh49esjb2/v/D/7TPfusVqssFosSEhJSWKpUp04dWa1WLVy4UP7/vWovNjZWLVq0kJOTk1atWvU3I9gjrAKpQ1gFUoewCqTcYw+rzs7OOnv2rO3X9I8SHh6erBP/maenp37++WcVL17crn3nzp0KCwtL8SdjEVaB1CGsAqlDWAVS7rHvWX2QaVMTRv+Om5ub4uLikrRfv35drq7cMxUAAODfKkWfK5ZWH9VXr149tW/fXlu3bpXVapXVatXPP/+sjh07qkGDBmlyTgAAAJgv2dsAnJyc5OPj87eB9dKlSyku4sqVK2rVqpW++eYbubi4SJLi4+PVsGFDzZkzR76+vikaj20AQOqwDQBIHbYBACmXJreuGjJkSJJPsHocfH19tWLFCh06dMi2JzY0NFT58+d/7OcCAADAkyNFK6vnzp1Tlv9+ju4/1b1792T3HTduXIrGZmUVSB1WVoHUYWUVSLnHvrL6uPerxsTEOOS8AAAAeHKk+G4Aj8uGDRse63gAAAB4+iQ7rCYmJqZlHQAAAEASKbp1FQAAAJCeCKsAAAAwFmEVAAAAxiKsAgAAwFiEVQAAABiLsAoAAABjEVYBAABgLMIqAAAAjEVYBQAAgLEIqwAAADAWYRUAAADGIqwCAADAWIRVAAAAGIuwCgAAAGMRVgEAAGAswioAAACMRVgFAACAsQirAAAAMBZhFQAAAMYirAIAAMBYhFUAAAAYi7AKAAAAYxFWAQAAYCzCKgAAAIxFWAUAAICxCKsAAAAwFmEVAAAAxiKsAgAAwFiEVQAAABiLsAoAAABjEVYBAABgLMIqAAAAjEVYBQAAgLEIqwAAADAWYRUAAADGIqwCAADAWIRVAAAAGIuwCgAAAGMRVgEAAGAswioAAACMRVgFAACAsQirAAAAMBZhFQAAAMYirAIAAMBYhFUAAAAYi7AKAAAAYxFWAQAAYCzCKgAAAIxFWAUAAICxCKsAAAAwFmEVAAAAxiKsAgAAwFiEVQAAABiLsAoAAABjEVYBAABgLMIqAAAAjEVYBQAAgLEIqwAAADAWYRUAAADGIqwCAADAWBar1Wp1dBGP2+17jq4AeDIlJD51bwdAuggs38XRJQBPnFsxk5PVj5VVAAAAGIuwCgAAAGMRVgEAAGAswioAAACMRVgFAACAsQirAAAAMBZhFQAAAMYirAIAAMBYhFUAAAAYi7AKAAAAYxFWAQAAYCzCKgAAAIxFWAUAAICxCKsAAAAwFmEVAAAAxiKsAgAAwFiEVQAAABiLsAoAAABjEVYBAABgLMIqAAAAjEVYBQAAgLEIqwAAADAWYRUAAADGIqwCAADAWIRVAAAAGIuwCgAAAGMRVgEAAGAswioAAACMRVgFAACAsQirAAAAMBZhFQAAAMYirAIAAMBYhFUAAAAYi7AKAAAAYxFWAQAAYCzCKgAAAIxFWAUAAICxCKsAAAAwFmEVAAAAxiKsAgAAwFiEVQAAABiLsAoAAABjEVYBAABgLMIqAAAAjEVYBQAAgLEIqwAAADAWYRUAAADGIqwCAADAWIRVAAAAGIuwCgAAAGMRVgEAAGAswioAAACMRVgFAACAsQirAAAAMBZhFQAAAMYirAIAAMBYhFUAAAAYi7AKAAAAYxFWAQAAYCzCKgAAAIxFWAUAAICxCKsAAAAwFmEVAAAAxiKsAgAAwFiEVQAAABiLsAoAAABjEVYBAABgrAyOLuDGjRsaNWqUvv/+e50/f16JiYl2zx85csRBlQEAAMDRHB5W27Vrp40bN+q1115T9uzZZbFYHF0SAAAADOHwsLpmzRqtWrVKYWFhji4FAAAAhnF4WPXz85O/v7+jy8A/8Osv2zR39ifat/c3XbhwQeM/mqLnqtewPW+1WvXx5I+09KsvFRd3TaVKl1H/gYMVHBxiN86mjdGaPnWKDh7YL1c3N5Ur94wmTPo4nWcDpI/Zs6Yrav13Onb0iNzc3VWyZGm93a2HQvLkteu3c0eMpkyaoN9275Kzk5MKFgrVlOmz5O7uLkmaNWOaNm+K1oH9vyuDi4s2/bTNEdMB0oSTk0XvdayjV+o8o6wBmXT2wlXN/2arRs381tZnxpAWeq1BBbvj1v24Vw3f+v/vH36ZPDTu3ZdVp2oxJVqtWv79DvUc/ZVu3Lpr6/NSzdLq1fZ5FcidRRevXNe0LzZq/Kffp/0k8bccHlaHDRumgQMHat68efLw8HB0OUiFW7duqlChQmoU+ZK6d30ryfNzPpmpzxfO17ARoxQUlFNTJk1Up/Zttezr1XJzc5MkrV+3VkMGDVCXd7rp2fIVlHAvQYcOHUjvqQDp5tdftqlJs+YqWqy4EhISNHnieL3ZoZ2WLF+pjP99L9y5I0ZdOr2hNm3b692+78nZ2VkH9u+Xk9P/XxsbH39XNWq9oBIlS2n5siWOmg6QJnq0rqk3GlfRGwPna+/hsypbNLemD26ha9dv6ePPN9r6rf1xjzoMWmB7fOfuPbtx5oxopWyBPqrXabJcMjhr+pAWmjKguVr3mytJqhVWRHOGt1b30V9q/ZZ9Kpwnmz4e2Fy37sRr2qJN6TJXPJrDw+rYsWN1+PBhZc2aVSEhIXJxcbF7fvv27Q6qDMlVuUq4KlcJf+hzVqtVC+d/qjc6dFK15+6vtr4/crSeq1pJUd+vV+06dXXv3j19MGq4uvXspciXXrYdmy9//nSpH3CEKdNm2T0e8v5IVQ+vpL1796hsuWckSWPHjFKz5q+pTbv2tn5/XXnt1PltSdLXy5emccVA+qtQMq9WbtylbzfvkSSdOHtJTV4op3JFg+363b17T3/Exj10jEJ5sur5sKIKe3W0tu89IUnq/sGXWj6pk/qOX6azF66qed1n9U30Ts36arMk6djpWI2ZvU49WtckrBrA4WG1UaNGji4Baej0qVO6ePGCyleoZGvz9vZW8RIltWtnjGrXqat9e/fq/B9/yMnJSU1eaqTYixdVqHBhdevZWwUKFHRg9UD6ibt+/xutj4+PJOlSbKx+27VTderUU+sWzXTq5EmF5Mmjzm93U+kyZR1ZKpBuft55RG1fClP+3Fl06MR5FS8YpIql8qrPWPsfzqqUK6Dj34/UlWs3Fb3tgIZMWalLV29IksqXyKPL127agqokRW3dr8REq54pFqyvN+ySm2sG3fzTlgBJunXnrnJm81Pu7P46cfZS2k8Wj+TwsDpo0CBHl4A0dPHiBUlSQGCAXXtAQIAuXrwoSTp16qQkadqUyerZu49yBAXp07lz1K71a/p61Vr5+Pqma81AektMTNSHH4xQqdJllP+/P6A9eF1MnzpZ7/TorUKFQ7Xy6xXq2K61vlz2jXL/Zc838DT6cM53yuTlrp3L3lNCglXOzhYNmrJSX6z5xdbnu5/2aUXUTh07Hau8OQM1pEt9rZjcSeGtxiox0aqsAZl04ZL9qmtCQqIuXbuprIGZbGOM7hmp+d8U1MZtB5UvV2Z1bVFdkpQ9sw9h1cEcHlb/qTt37ujOnTt2bVZnN9teSJjP+t9767Zr31E1aj0vSRo6fKRqPVdV69Z9q5ebNHNkeUCaGzV8qA4fOqjZ8z6ztVmt918XkS83VcMXX5IkFQ4tov9s3aIVy5aoyzs9HFIrkJ4a1yqjZrWfUet+87T38FmVKBSkMT0b6+yFq1r4zVZJ0pdrf7X133PojHYfPK19K4eoarkCiv5P8q59mL30R+XNGailEzvKJYOzrt24rSmfRWtAp7pJ7v+O9OeQT7Dy9/e3rao9uBvAo/78nZEjR8rHx8fuz5gPRqb1FJBMgYGZJUmxF2Pt2mNjYxUYGHi/T+b7ffLmy2d73tXVVUE5c+nc2bPpVCngGKOGD9UPG6M145NPlTVbNlt7YGAWSVLevPZ7t/PkzcfrAv8aI95ppA/nfKcv1/6qPYfO6PNV2zRpYZR6tan5yGOOnY7Vhctxypfr/veWP2KvKbO/t10fZ2cn+Wfy0B8Xr9na3vtohQLDeqhQnYEKqdFPv+w5Lkk6etr++xfSn0NWVsePHy9v7/v/cSZMmPCPxurbt6+6d+9u12Z1ZlXVFEE5cyowMLO2bt2iwqGhkqTr169r966dernpK5KkIkWLydXVVceOHVWZsuUkSfHx8Tpz5rSyZ8/hsNqBtGS1WvXBiGHaELVeM2d/qqCcOe2ezxEUpMxZsuj4saN27SeOH1OlylXSs1TAYTK6uyrRar+ymZBotbsjxl8FZfFVgI+nzv03iG7ddVR+mTxUOjSXYvbd314T8UxBOTlZtO2343bHJiZadebCVUlSkxfK6uedR3Tx8vXHOSWkgkPCaqtWrWx///777xUREaHw8HDl+9PKWnK5uSX9lf/te4/ojDRx88YNnTjx/xvXT586pd/37ZOPj4+y58ihV19rqZnTpyo4d7CCct6/dVXmLFls92L18vLSy02aaeqUScqWLbty5MihuXM+kSTVev4Fh8wJSGujhg/VmtUrNX7iFHl4etr2d3t5ecvd3V0Wi0UtW7fV9I8nqWChQipYOFQrVyzXsaNHNHrcRNs4Z8+e0bWrV3Xu7FklJiRo/+/7JEm5cueWh4enQ+YGPC6rN+3Wu22f18mzl7X38FmVKpxTb7eopk+X/yxJ8szoqv4d6mj59zt07uI15c0VqOFdG+nwyYv67qf7r4X9R//Q2h/3aMqA5np7+BdyyeCs8X2a6Mu123X2v8E0wNdTL9YorU2/HJS7awa1bFhBkTVKq1a7iY+sDenHYrVarY4s4I033tDGjRt1+PBh5ciRQ+Hh4bbwWqBAgVSNSVhNX9v+s1Xt2rRM0t6g4YsaNmKU7UMBlny5WHFx11S6TFn1GzBIISF5bH3j4+P10YRxWvnNCt25fVvFS5RUrz79lD9/6v4PIHUSEh36dvCvUqZ44Ye2Dx42Qg0aRdoez5k1Q4u/+ExXr11VwYKF1LV7L7u7AQzq30fffL08yTgzZs9TuWfKP/a68XCB5bs4uoSnkpeHmwa9WU8NniupzH5eOnvhqhZ/+6tGzFij+HsJcndz0eJx7VWycE75emfU2QtXtX7L7xr68Uqd/9NFVX6ZPDS+T5P7HwqQeP9DAXqM/tL2oQABvp5aMrGjiubPIYvl/mrs4MnfJFl5xeN1K2Zysvo5PKw+cPr0aW3atEkbN27Uxo0bdeDAAWXPnl2nTp1K8ViEVSB1CKtA6hBWgZRLblh1yAVWD+Pn56eAgAD5+fnJ19dXGTJkUOb/XngDAACAfyeHh9V+/fqpUqVKCggIUJ8+fXT79m316dNH586dU0xMjKPLAwAAgAM5fBuAk5OTMmfOrG7duikyMlIFC/7zTyxiGwCQOmwDAFKHbQBAyiV3G4DDPxQgJiZGGzduVHR0tMaOHStXV1fbRVYRERGPJbwCAADgyeTwldW/2rlzp8aPH6+FCxcqMTFRCQkJKR6DlVUgdVhZBVKHlVUg5Z6YlVWr1aqYmBhFR0crOjpamzdv1rVr11SiRAmFh4c7ujwAAAA4kMPDqr+/v65fv66SJUsqPDxcb7zxhqpUqSJfX19HlwYAAAAHc3hYXbBggapUqaJMmTI5uhQAAAAYxuFhtW7duo4uAQAAAIZy+H1WAQAAgEchrAIAAMBYhFUAAAAYi7AKAAAAYxFWAQAAYCzCKgAAAIxFWAUAAICxCKsAAAAwFmEVAAAAxiKsAgAAwFiEVQAAABiLsAoAAABjEVYBAABgLMIqAAAAjEVYBQAAgLEIqwAAADAWYRUAAADGIqwCAADAWIRVAAAAGIuwCgAAAGMRVgEAAGAswioAAACMRVgFAACAsQirAAAAMBZhFQAAAMYirAIAAMBYhFUAAAAYi7AKAAAAYxFWAQAAYCzCKgAAAIxFWAUAAICxCKsAAAAwFmEVAAAAxiKsAgAAwFiEVQAAABiLsAoAAABjEVYBAABgLMIqAAAAjEVYBQAAgLEIqwAAADAWYRUAAADGIqwCAADAWIRVAAAAGIuwCgAAAGMRVgEAAGAswioAAACMRVgFAACAsQirAAAAMBZhFQAAAMYirAIAAMBYhFUAAAAYi7AKAAAAYxFWAQAAYCzCKgAAAIxFWAUAAICxCKsAAAAwFmEVAAAAxiKsAgAAwFiEVQAAABiLsAoAAABjEVYBAABgLMIqAAAAjEVYBQAAgLEsVqvV6ugi8O9x584djRw5Un379pWbm5ujywGeCLxugNThtfN0IKwiXV27dk0+Pj66evWqMmXK5OhygCcCrxsgdXjtPB3YBgAAAABjEVYBAABgLMIqAAAAjEVYRbpyc3PToEGD2OgOpACvGyB1eO08HbjACgAAAMZiZRUAAADGIqwCAADAWIRVAAAAGIuwisciIiJC77zzjqPLAJ4YvGaA9DF37lz5+vo6ugz8A4RVAADw1GratKkOHDjg6DLwD2RwdAF4+t29e1eurq6OLgMA8C+UMWNGZcyY0dFl4B9gZRUpduPGDbVs2VJeXl7Knj27xo4da/d8SEiIhg0bppYtWypTpkxq3769JOndd99VwYIF5eHhobx582rAgAGKj4+XJF29elXOzs765ZdfJEmJiYny9/dXhQoVbOMuWLBAuXLlSqdZAunn8uXLatmypfz8/OTh4aHatWvr4MGDtuePHz+u+vXry8/PT56enipatKhWr15tO/bVV19V5syZlTFjRhUoUEBz5sxx1FSAdLFy5Ur5+voqISFBkrRjxw5ZLBb16dPH1qddu3Zq0aJFkm0AgwcPVqlSpTR//nyFhITIx8dHzZo1U1xcXHpPA8lEWEWK9erVSxs3btSKFSu0bt06RUdHa/v27XZ9PvzwQ5UsWVIxMTEaMGCAJMnb21tz587V3r17NXHiRM2cOVPjx4+XJPn4+KhUqVKKjo6WJO3evVsWi0UxMTG6fv26JGnjxo0KDw9Pv4kC6aR169b65Zdf9PXXX2vLli2yWq2qU6eO7Ye5zp07686dO9q0aZN2796tDz74QF5eXpKkAQMGaO/evVqzZo327dunqVOnKjAw0JHTAdJclSpVFBcXp5iYGEn3vz8EBgbavoc8aIuIiHjo8YcPH9by5cu1cuVKrVy5Uhs3btSoUaPSoXKkihVIgbi4OKurq6t18eLFtrbY2FhrxowZrV27drVarVZrcHCwtVGjRn871pgxY6xly5a1Pe7evbu1bt26VqvVap0wYYK1adOm1pIlS1rXrFljtVqt1vz581tnzJjxGGcDOE54eLi1a9eu1gMHDlglWX/88UfbcxcvXrRmzJjR9jorXry4dfDgwQ8dp379+tY2bdqkS82AScqUKWMdM2aM1Wq1Whs1amQdPny41dXV1RoXF2c9deqUVZL1wIED1jlz5lh9fHxsxw0aNMjq4eFhvXbtmq2tV69e1vLly6f3FJBMrKwiRQ4fPqy7d++qfPnytjZ/f38VKlTIrl+5cuWSHLto0SKFhYUpW7Zs8vLy0nvvvacTJ07Yng8PD9fmzZuVkJBg+4k4IiJC0dHROnPmjA4dOvTIn5KBJ9W+ffuUIUMGu9dUQECAChUqpH379kmS3n77bb3//vsKCwvToEGDtGvXLlvfTp066YsvvlCpUqXUu3dv/fTTT+k+B8ARwsPDFR0dLavVqh9++EGRkZEKDQ3V5s2btXHjRuXIkUMFChR46LEhISHy9va2Pc6ePbvOnz+fXqUjhQirSBOenp52j7ds2aJXX31VderU0cqVKxUTE6P+/fvr7t27tj5Vq1ZVXFyctm/frk2bNtmF1b974wGeZu3atdORI0f02muvaffu3SpXrpwmTZokSapdu7aOHz+ubt266cyZM6pevbp69uzp4IqBtBcREaHNmzdr586dcnFxUeHChe2+Z/yvbWMuLi52jy0WixITE9O6ZKQSYRUpki9fPrm4uGjr1q22tsuXL//tbUF++uknBQcHq3///ipXrpwKFCig48eP2/Xx9fVViRIlNHnyZNsbT9WqVRUTE6OVK1eyXxVPpdDQUN27d8/uNRUbG6v9+/erSJEitrZcuXKpY8eOWrp0qXr06KGZM2fansucObNatWqlBQsWaMKECZoxY0a6zgFwhAf7VsePH2/7/vAgrEZHR/ObuKcIYRUp4uXlpbZt26pXr16KiorSb7/9ptatW8vJ6X//VypQoIBOnDihL774QocPH9ZHH32kZcuWJekXERGhhQsX2t54/P39FRoaqkWLFhFW8VQqUKCAGjZsqDfeeMO2StSiRQsFBQWpYcOGkqR33nlHa9eu1dGjR7V9+3Zt2LBBoaGhkqSBAwdqxYoVOnTokPbs2aOVK1fangOeZn5+fipRooQWLlxoC6ZVq1bV9u3bdeDAAb5nPEUIq0ixMWPGqEqVKqpfv75q1KihypUrq2zZsv/zmAYNGqhbt2566623VKpUKf3000+2uwT8WXh4uBISEux+Io6IiEjSBjxN5syZo7Jly6pevXqqWLGirFarVq9ebftVZUJCgjp37qzQ0FC98MILKliwoD7++GNJkqurq/r27asSJUqoatWqcnZ21hdffOHI6QDp5q/fM/z9/VWkSBFly5YtybUUeHJZrFar1dFFAAAAAA/DyioAAACMRVgFAACAsQirAAAAMBZhFQAAAMYirAIAAMBYhFUAAAAYi7AKAAAAYxFWAQAAYCzCKgAYpnXr1mrUqJHtcUREhN555510ryM6OloWi0VXrlxJ93MDwAOEVQBIptatW8tischiscjV1VX58+fX0KFDde/evTQ979KlSzVs2LBk9SVgAnjaZHB0AQDwJHnhhRc0Z84c3blzR6tXr1bnzp3l4uKivn372vW7e/euXF1dH8s5/f39H8s4APAkYmUVAFLAzc1N2bJlU3BwsDp16qQaNWro66+/tv3qfvjw4cqRI4cKFSokSTp58qSaNGkiX19f+fv7q2HDhjp27JhtvISEBHXv3l2+vr4KCAhQ7969ZbVa7c75120Ad+7c0bvvvqtcuXLJzc1N+fPn1yeffKJjx46pWrVqkiQ/Pz9ZLBa1bt1akpSYmKiRI0cqT548ypgxo0qWLKmvvvrK7jyrV69WwYIFlTFjRlWrVs2uTgBwFMIqAPwDGTNm1N27dyVJ33//vfbv36/vvvtOK1euVHx8vJ5//nl5e3vrhx9+0I8//igvLy+98MILtmPGjh2ruXPnavbs2dq8ebMuXbqkZcuW/c9ztmzZUp9//rk++ugj7du3T9OnT5eXl5dy5cqlJUuWSJL279+vs2fPauLEiZKkkSNH6tNPP9W0adO0Z88edevWTS1atNDGjRsl3Q/VkZGRql+/vnbs2KF27dqpT58+afVlA4BkYxsAAKSC1WrV999/r7Vr16pLly66cOGCPD09NWvWLNuv/xcsWKDExETNmjVLFotFkjRnzhz5+voqOjpatWrV0oQJE9S3b19FRkZKkqZNm6a1a9c+8rwHDhzQ4sWL9d1336lGjRqSpLx589qef7BlIEuWLPL19ZV0fyV2xIgRWr9+vSpWrGg7ZvPmzZo+fbrCw8M1depU5cuXT2PHjpUkFSpUSLt379YHH3zwGL9qAJByhFUASIGVK1fKy8tL8fHxSkxMVPPmzTV48GB17txZxYsXt9ununPnTh06dEje3t52Y9y+fVuHDx/W1atXdfbsWZUvX972XIYMGVSuXLkkWwEe2LFjh5ydnRUeHp7smg8dOqSbN2+qZs2adu13795V6dKlJUn79u2zq0OSLdgCgCMRVgEgBapVq6apU6fK1dVVOXLkUIYM//826unpadf3+vXrKlu2rBYuXJhknMyZM6fq/BkzZkzxMdevX5ckrVq1SkFBQXbPubm5paoOAEgvhFUASAFPT0/lz58/WX3LlCmjRYsWKUuWLMqUKdND+2TPnl1bt25V1apVJUn37t3Tr7/+qjJlyjy0f/HixZWYmKiNGzfatgH82YOV3YSEBFtbkSJF5ObmphMnTjxyRTY0NFRff/21XdvPP//895MEgDTGBVYAkEZeffVVBQYGqmHDhvrhhx909OhRRUdH6+2339apU6ckSV27dtWoUaO0fPly/f7773rzzTf/5z1SQ0JC1KpVK73++utavny5bczFixdLkoKDg2WxWLRy5UpduHBB169fl7e3t3r27Klu3bpp3rx5Onz4sLZv365JkyZp3rx5kqSOHTvq4MGD6tWrl/bv36/PPvtMc+fOTesvEQD8LcIqAKQRDw8Pbdq0Sblz51ZkZKRCQ0PVtm1b3b5927bS2qNHD7322mtq1aqVKlasKG9vb7344ov/c9ypU6eqcePGevPNN1W4cGG98cYbunHjhiQpKChIQ4YMUZ8+fZQ1a1a99dZbkqRhw4ZpwIABGjlypEJDQ/XCCy9o1apVypMnjyQpd+7cWrJkiZYvX66SJUtq2rRpGjFiRBp+dQAgeSzWR+3iBwAAAByMlVUAAAAYi7AKAAAAYxFWAQAAYCzCKgAAAIxFWAUAAICxCKsAAAAwFmEVAAAAxiKsAgAAwFiEVQAAABiLsAoAAABjEVYBAABgrP8DVKbUgHk60SUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xticks(np.arange(3) + 0.5, ['draw', 'loss', 'win'])\n",
        "plt.yticks(np.arange(3) + 0.5, ['draw', 'loss', 'win'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLR169ZhyNAq"
      },
      "source": [
        "# Balancing the training set\n",
        "\n",
        "As we can see, the model is pretty good at predicting win or loss, but not so great at predicting draws. Another important thing to note, is that there are much fewer wins than any other class. Let's make another attempt at training the previous model, but let's train over a balanced dataset, with the hopes that our model will have more balanced accuracy and overall higher accuracy. To make a balanced dataset (one where each class has about equal representation), we will use undersampling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scxgI4-rzKS-",
        "outputId": "b03410af-667a-43bd-c6de-110df572d328"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original label distribution: {'draw': 5154.0, 'loss': 13294.0, 'win': 35597.0}\n",
            "Resampled label distribution: {'draw': 5154, 'loss': 5154, 'win': 5154}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "connect_4 = fetch_ucirepo(id=26)\n",
        "\n",
        "X = connect_4.data.features\n",
        "y = connect_4.data.targets\n",
        "\n",
        "feature_encoder = OneHotEncoder()\n",
        "X_encoded = feature_encoder.fit_transform(X).toarray()\n",
        "\n",
        "label_encoder = OneHotEncoder(sparse_output=False)\n",
        "y_encoded = label_encoder.fit_transform(y.to_numpy().reshape(-1, 1))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_train_res, y_train_res = rus.fit_resample(X_train, y_train)\n",
        "\n",
        "def get_label_distribution(labels):\n",
        "    label_counts = labels.sum(axis=0)\n",
        "    return dict(zip(label_encoder.categories_[0], label_counts))\n",
        "\n",
        "print(f'Original label distribution: {get_label_distribution(y_train)}')\n",
        "print(f'Resampled label distribution: {get_label_distribution(y_train_res)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mqTZCAH4S1i"
      },
      "source": [
        "# Increase epochs\n",
        "\n",
        "Let's train for 100 epochs, and see if our model will give us the results we want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PESkuyhB0aGI",
        "outputId": "b3812c60-af00-4784-d88d-fc0ffc97cf88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "241/242 [============================>.] - ETA: 0s - loss: 0.6551 - accuracy: 0.7270\n",
            "Epoch 1: val_accuracy improved from -inf to 0.75851, saving model to model.keras\n",
            "242/242 [==============================] - 6s 10ms/step - loss: 0.6546 - accuracy: 0.7272 - val_loss: 0.5287 - val_accuracy: 0.7585\n",
            "Epoch 2/100\n",
            "235/242 [============================>.] - ETA: 0s - loss: 0.5774 - accuracy: 0.7515\n",
            "Epoch 2: val_accuracy improved from 0.75851 to 0.77383, saving model to model.keras\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5780 - accuracy: 0.7510 - val_loss: 0.5030 - val_accuracy: 0.7738\n",
            "Epoch 3/100\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.5544 - accuracy: 0.7605\n",
            "Epoch 3: val_accuracy did not improve from 0.77383\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5544 - accuracy: 0.7605 - val_loss: 0.5499 - val_accuracy: 0.7597\n",
            "Epoch 4/100\n",
            "241/242 [============================>.] - ETA: 0s - loss: 0.5536 - accuracy: 0.7593\n",
            "Epoch 4: val_accuracy improved from 0.77383 to 0.77783, saving model to model.keras\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5538 - accuracy: 0.7591 - val_loss: 0.5133 - val_accuracy: 0.7778\n",
            "Epoch 5/100\n",
            "239/242 [============================>.] - ETA: 0s - loss: 0.5470 - accuracy: 0.7641\n",
            "Epoch 5: val_accuracy did not improve from 0.77783\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5465 - accuracy: 0.7642 - val_loss: 0.5337 - val_accuracy: 0.7645\n",
            "Epoch 6/100\n",
            "239/242 [============================>.] - ETA: 0s - loss: 0.5400 - accuracy: 0.7703\n",
            "Epoch 6: val_accuracy did not improve from 0.77783\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5410 - accuracy: 0.7701 - val_loss: 0.5393 - val_accuracy: 0.7605\n",
            "Epoch 7/100\n",
            "241/242 [============================>.] - ETA: 0s - loss: 0.5356 - accuracy: 0.7693\n",
            "Epoch 7: val_accuracy did not improve from 0.77783\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5356 - accuracy: 0.7693 - val_loss: 0.5337 - val_accuracy: 0.7647\n",
            "Epoch 8/100\n",
            "239/242 [============================>.] - ETA: 0s - loss: 0.5318 - accuracy: 0.7724\n",
            "Epoch 8: val_accuracy improved from 0.77783 to 0.78567, saving model to model.keras\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5311 - accuracy: 0.7728 - val_loss: 0.4988 - val_accuracy: 0.7857\n",
            "Epoch 9/100\n",
            "241/242 [============================>.] - ETA: 0s - loss: 0.5289 - accuracy: 0.7724\n",
            "Epoch 9: val_accuracy did not improve from 0.78567\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5295 - accuracy: 0.7721 - val_loss: 0.5168 - val_accuracy: 0.7727\n",
            "Epoch 10/100\n",
            "237/242 [============================>.] - ETA: 0s - loss: 0.5281 - accuracy: 0.7781\n",
            "Epoch 10: val_accuracy improved from 0.78567 to 0.78604, saving model to model.keras\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5297 - accuracy: 0.7771 - val_loss: 0.5011 - val_accuracy: 0.7860\n",
            "Epoch 11/100\n",
            "236/242 [============================>.] - ETA: 0s - loss: 0.5176 - accuracy: 0.7793\n",
            "Epoch 11: val_accuracy did not improve from 0.78604\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5192 - accuracy: 0.7786 - val_loss: 0.5377 - val_accuracy: 0.7644\n",
            "Epoch 12/100\n",
            "241/242 [============================>.] - ETA: 0s - loss: 0.5122 - accuracy: 0.7814\n",
            "Epoch 12: val_accuracy improved from 0.78604 to 0.80440, saving model to model.keras\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.5125 - accuracy: 0.7811 - val_loss: 0.4513 - val_accuracy: 0.8044\n",
            "Epoch 13/100\n",
            "235/242 [============================>.] - ETA: 0s - loss: 0.5151 - accuracy: 0.7784\n",
            "Epoch 13: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5149 - accuracy: 0.7784 - val_loss: 0.5381 - val_accuracy: 0.7720\n",
            "Epoch 14/100\n",
            "236/242 [============================>.] - ETA: 0s - loss: 0.5037 - accuracy: 0.7874\n",
            "Epoch 14: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5044 - accuracy: 0.7875 - val_loss: 0.5428 - val_accuracy: 0.7699\n",
            "Epoch 15/100\n",
            "240/242 [============================>.] - ETA: 0s - loss: 0.5015 - accuracy: 0.7878\n",
            "Epoch 15: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5027 - accuracy: 0.7876 - val_loss: 0.5002 - val_accuracy: 0.7842\n",
            "Epoch 16/100\n",
            "236/242 [============================>.] - ETA: 0s - loss: 0.5051 - accuracy: 0.7836\n",
            "Epoch 16: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5050 - accuracy: 0.7837 - val_loss: 0.5075 - val_accuracy: 0.7845\n",
            "Epoch 17/100\n",
            "241/242 [============================>.] - ETA: 0s - loss: 0.5042 - accuracy: 0.7862\n",
            "Epoch 17: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5039 - accuracy: 0.7863 - val_loss: 0.5005 - val_accuracy: 0.7837\n",
            "Epoch 18/100\n",
            "241/242 [============================>.] - ETA: 0s - loss: 0.5019 - accuracy: 0.7901\n",
            "Epoch 18: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.5024 - accuracy: 0.7898 - val_loss: 0.5307 - val_accuracy: 0.7676\n",
            "Epoch 19/100\n",
            "240/242 [============================>.] - ETA: 0s - loss: 0.4911 - accuracy: 0.7886\n",
            "Epoch 19: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4900 - accuracy: 0.7894 - val_loss: 0.5306 - val_accuracy: 0.7764\n",
            "Epoch 20/100\n",
            "235/242 [============================>.] - ETA: 0s - loss: 0.4886 - accuracy: 0.7916\n",
            "Epoch 20: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4895 - accuracy: 0.7913 - val_loss: 0.5623 - val_accuracy: 0.7599\n",
            "Epoch 21/100\n",
            "239/242 [============================>.] - ETA: 0s - loss: 0.4909 - accuracy: 0.7945\n",
            "Epoch 21: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4912 - accuracy: 0.7942 - val_loss: 0.5025 - val_accuracy: 0.7819\n",
            "Epoch 22/100\n",
            "239/242 [============================>.] - ETA: 0s - loss: 0.4788 - accuracy: 0.7984\n",
            "Epoch 22: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4807 - accuracy: 0.7978 - val_loss: 0.5776 - val_accuracy: 0.7527\n",
            "Epoch 23/100\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.4828 - accuracy: 0.7952\n",
            "Epoch 23: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4828 - accuracy: 0.7952 - val_loss: 0.4933 - val_accuracy: 0.7960\n",
            "Epoch 24/100\n",
            "235/242 [============================>.] - ETA: 0s - loss: 0.4801 - accuracy: 0.7983\n",
            "Epoch 24: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4816 - accuracy: 0.7976 - val_loss: 0.5113 - val_accuracy: 0.7857\n",
            "Epoch 25/100\n",
            "236/242 [============================>.] - ETA: 0s - loss: 0.4795 - accuracy: 0.7952\n",
            "Epoch 25: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4808 - accuracy: 0.7947 - val_loss: 0.5052 - val_accuracy: 0.7849\n",
            "Epoch 26/100\n",
            "240/242 [============================>.] - ETA: 0s - loss: 0.4754 - accuracy: 0.7984\n",
            "Epoch 26: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4749 - accuracy: 0.7987 - val_loss: 0.5144 - val_accuracy: 0.7801\n",
            "Epoch 27/100\n",
            "238/242 [============================>.] - ETA: 0s - loss: 0.4709 - accuracy: 0.7993\n",
            "Epoch 27: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4715 - accuracy: 0.7993 - val_loss: 0.5492 - val_accuracy: 0.7671\n",
            "Epoch 28/100\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.4652 - accuracy: 0.8021\n",
            "Epoch 28: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4652 - accuracy: 0.8021 - val_loss: 0.5288 - val_accuracy: 0.7816\n",
            "Epoch 29/100\n",
            "241/242 [============================>.] - ETA: 0s - loss: 0.4701 - accuracy: 0.8031\n",
            "Epoch 29: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4704 - accuracy: 0.8030 - val_loss: 0.4888 - val_accuracy: 0.7931\n",
            "Epoch 30/100\n",
            "237/242 [============================>.] - ETA: 0s - loss: 0.4577 - accuracy: 0.8079\n",
            "Epoch 30: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4593 - accuracy: 0.8068 - val_loss: 0.4887 - val_accuracy: 0.7954\n",
            "Epoch 31/100\n",
            "238/242 [============================>.] - ETA: 0s - loss: 0.4582 - accuracy: 0.8077\n",
            "Epoch 31: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4588 - accuracy: 0.8069 - val_loss: 0.5422 - val_accuracy: 0.7732\n",
            "Epoch 32/100\n",
            "236/242 [============================>.] - ETA: 0s - loss: 0.4614 - accuracy: 0.8009\n",
            "Epoch 32: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4619 - accuracy: 0.8011 - val_loss: 0.5459 - val_accuracy: 0.7711\n",
            "Epoch 33/100\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.4609 - accuracy: 0.8076\n",
            "Epoch 33: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4609 - accuracy: 0.8076 - val_loss: 0.4985 - val_accuracy: 0.7906\n",
            "Epoch 34/100\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.4669 - accuracy: 0.8029\n",
            "Epoch 34: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4669 - accuracy: 0.8029 - val_loss: 0.5261 - val_accuracy: 0.7796\n",
            "Epoch 35/100\n",
            "238/242 [============================>.] - ETA: 0s - loss: 0.4594 - accuracy: 0.8050\n",
            "Epoch 35: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4594 - accuracy: 0.8052 - val_loss: 0.5014 - val_accuracy: 0.7919\n",
            "Epoch 36/100\n",
            "237/242 [============================>.] - ETA: 0s - loss: 0.4460 - accuracy: 0.8103\n",
            "Epoch 36: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4468 - accuracy: 0.8096 - val_loss: 0.5372 - val_accuracy: 0.7782\n",
            "Epoch 37/100\n",
            "237/242 [============================>.] - ETA: 0s - loss: 0.4541 - accuracy: 0.8075\n",
            "Epoch 37: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4550 - accuracy: 0.8072 - val_loss: 0.5445 - val_accuracy: 0.7730\n",
            "Epoch 38/100\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.4522 - accuracy: 0.8097\n",
            "Epoch 38: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4522 - accuracy: 0.8097 - val_loss: 0.5256 - val_accuracy: 0.7820\n",
            "Epoch 39/100\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.4508 - accuracy: 0.8108\n",
            "Epoch 39: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4508 - accuracy: 0.8108 - val_loss: 0.5334 - val_accuracy: 0.7795\n",
            "Epoch 40/100\n",
            "241/242 [============================>.] - ETA: 0s - loss: 0.4453 - accuracy: 0.8137\n",
            "Epoch 40: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4454 - accuracy: 0.8137 - val_loss: 0.5345 - val_accuracy: 0.7741\n",
            "Epoch 41/100\n",
            "238/242 [============================>.] - ETA: 0s - loss: 0.4393 - accuracy: 0.8171\n",
            "Epoch 41: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4388 - accuracy: 0.8172 - val_loss: 0.5399 - val_accuracy: 0.7792\n",
            "Epoch 42/100\n",
            "240/242 [============================>.] - ETA: 0s - loss: 0.4450 - accuracy: 0.8146\n",
            "Epoch 42: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4445 - accuracy: 0.8148 - val_loss: 0.5229 - val_accuracy: 0.7846\n",
            "Epoch 43/100\n",
            "237/242 [============================>.] - ETA: 0s - loss: 0.4340 - accuracy: 0.8165\n",
            "Epoch 43: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4364 - accuracy: 0.8155 - val_loss: 0.5177 - val_accuracy: 0.7900\n",
            "Epoch 44/100\n",
            "241/242 [============================>.] - ETA: 0s - loss: 0.4406 - accuracy: 0.8151\n",
            "Epoch 44: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4411 - accuracy: 0.8148 - val_loss: 0.5616 - val_accuracy: 0.7716\n",
            "Epoch 45/100\n",
            "236/242 [============================>.] - ETA: 0s - loss: 0.4304 - accuracy: 0.8190\n",
            "Epoch 45: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4302 - accuracy: 0.8190 - val_loss: 0.5053 - val_accuracy: 0.7928\n",
            "Epoch 46/100\n",
            "241/242 [============================>.] - ETA: 0s - loss: 0.4334 - accuracy: 0.8214\n",
            "Epoch 46: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4334 - accuracy: 0.8214 - val_loss: 0.5496 - val_accuracy: 0.7734\n",
            "Epoch 47/100\n",
            "241/242 [============================>.] - ETA: 0s - loss: 0.4328 - accuracy: 0.8211\n",
            "Epoch 47: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4328 - accuracy: 0.8210 - val_loss: 0.5637 - val_accuracy: 0.7740\n",
            "Epoch 48/100\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.4358 - accuracy: 0.8166\n",
            "Epoch 48: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4358 - accuracy: 0.8166 - val_loss: 0.5691 - val_accuracy: 0.7692\n",
            "Epoch 49/100\n",
            "240/242 [============================>.] - ETA: 0s - loss: 0.4328 - accuracy: 0.8213\n",
            "Epoch 49: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4328 - accuracy: 0.8214 - val_loss: 0.5506 - val_accuracy: 0.7789\n",
            "Epoch 50/100\n",
            "238/242 [============================>.] - ETA: 0s - loss: 0.4271 - accuracy: 0.8210\n",
            "Epoch 50: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.4278 - accuracy: 0.8205 - val_loss: 0.5609 - val_accuracy: 0.7780\n",
            "Epoch 51/100\n",
            "236/242 [============================>.] - ETA: 0s - loss: 0.4228 - accuracy: 0.8198\n",
            "Epoch 51: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4244 - accuracy: 0.8194 - val_loss: 0.5441 - val_accuracy: 0.7764\n",
            "Epoch 52/100\n",
            "236/242 [============================>.] - ETA: 0s - loss: 0.4170 - accuracy: 0.8263\n",
            "Epoch 52: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4188 - accuracy: 0.8255 - val_loss: 0.5342 - val_accuracy: 0.7813\n",
            "Epoch 53/100\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.4190 - accuracy: 0.8263\n",
            "Epoch 53: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4190 - accuracy: 0.8263 - val_loss: 0.5268 - val_accuracy: 0.7869\n",
            "Epoch 54/100\n",
            "241/242 [============================>.] - ETA: 0s - loss: 0.4252 - accuracy: 0.8226\n",
            "Epoch 54: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4254 - accuracy: 0.8224 - val_loss: 0.5599 - val_accuracy: 0.7761\n",
            "Epoch 55/100\n",
            "240/242 [============================>.] - ETA: 0s - loss: 0.4107 - accuracy: 0.8316\n",
            "Epoch 55: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4116 - accuracy: 0.8313 - val_loss: 0.5396 - val_accuracy: 0.7843\n",
            "Epoch 56/100\n",
            "238/242 [============================>.] - ETA: 0s - loss: 0.4244 - accuracy: 0.8202\n",
            "Epoch 56: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4238 - accuracy: 0.8203 - val_loss: 0.5147 - val_accuracy: 0.7964\n",
            "Epoch 57/100\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.4047 - accuracy: 0.8313\n",
            "Epoch 57: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4047 - accuracy: 0.8313 - val_loss: 0.5517 - val_accuracy: 0.7841\n",
            "Epoch 58/100\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.4209 - accuracy: 0.8281\n",
            "Epoch 58: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4209 - accuracy: 0.8281 - val_loss: 0.5344 - val_accuracy: 0.7849\n",
            "Epoch 59/100\n",
            "241/242 [============================>.] - ETA: 0s - loss: 0.4113 - accuracy: 0.8321\n",
            "Epoch 59: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4115 - accuracy: 0.8320 - val_loss: 0.5510 - val_accuracy: 0.7802\n",
            "Epoch 60/100\n",
            "241/242 [============================>.] - ETA: 0s - loss: 0.4115 - accuracy: 0.8299\n",
            "Epoch 60: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4114 - accuracy: 0.8299 - val_loss: 0.5617 - val_accuracy: 0.7793\n",
            "Epoch 61/100\n",
            "241/242 [============================>.] - ETA: 0s - loss: 0.4178 - accuracy: 0.8246\n",
            "Epoch 61: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4185 - accuracy: 0.8242 - val_loss: 0.5565 - val_accuracy: 0.7763\n",
            "Epoch 62/100\n",
            "239/242 [============================>.] - ETA: 0s - loss: 0.4084 - accuracy: 0.8328\n",
            "Epoch 62: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4090 - accuracy: 0.8326 - val_loss: 0.5682 - val_accuracy: 0.7763\n",
            "Epoch 63/100\n",
            "241/242 [============================>.] - ETA: 0s - loss: 0.4074 - accuracy: 0.8355\n",
            "Epoch 63: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4074 - accuracy: 0.8355 - val_loss: 0.5710 - val_accuracy: 0.7761\n",
            "Epoch 64/100\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.4058 - accuracy: 0.8336\n",
            "Epoch 64: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4058 - accuracy: 0.8336 - val_loss: 0.5363 - val_accuracy: 0.7852\n",
            "Epoch 65/100\n",
            "235/242 [============================>.] - ETA: 0s - loss: 0.4009 - accuracy: 0.8342\n",
            "Epoch 65: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4023 - accuracy: 0.8337 - val_loss: 0.5523 - val_accuracy: 0.7769\n",
            "Epoch 66/100\n",
            "240/242 [============================>.] - ETA: 0s - loss: 0.4111 - accuracy: 0.8298\n",
            "Epoch 66: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4117 - accuracy: 0.8295 - val_loss: 0.5670 - val_accuracy: 0.7761\n",
            "Epoch 67/100\n",
            "240/242 [============================>.] - ETA: 0s - loss: 0.3913 - accuracy: 0.8388\n",
            "Epoch 67: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3907 - accuracy: 0.8392 - val_loss: 0.5499 - val_accuracy: 0.7855\n",
            "Epoch 68/100\n",
            "239/242 [============================>.] - ETA: 0s - loss: 0.3972 - accuracy: 0.8362\n",
            "Epoch 68: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3971 - accuracy: 0.8364 - val_loss: 0.6016 - val_accuracy: 0.7641\n",
            "Epoch 69/100\n",
            "240/242 [============================>.] - ETA: 0s - loss: 0.4017 - accuracy: 0.8343\n",
            "Epoch 69: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4016 - accuracy: 0.8342 - val_loss: 0.5557 - val_accuracy: 0.7859\n",
            "Epoch 70/100\n",
            "239/242 [============================>.] - ETA: 0s - loss: 0.3984 - accuracy: 0.8349\n",
            "Epoch 70: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3982 - accuracy: 0.8348 - val_loss: 0.5786 - val_accuracy: 0.7776\n",
            "Epoch 71/100\n",
            "241/242 [============================>.] - ETA: 0s - loss: 0.3940 - accuracy: 0.8345\n",
            "Epoch 71: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3940 - accuracy: 0.8344 - val_loss: 0.5252 - val_accuracy: 0.7958\n",
            "Epoch 72/100\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.4004 - accuracy: 0.8369\n",
            "Epoch 72: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.4004 - accuracy: 0.8369 - val_loss: 0.5746 - val_accuracy: 0.7758\n",
            "Epoch 73/100\n",
            "239/242 [============================>.] - ETA: 0s - loss: 0.3923 - accuracy: 0.8356\n",
            "Epoch 73: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3924 - accuracy: 0.8354 - val_loss: 0.5634 - val_accuracy: 0.7840\n",
            "Epoch 74/100\n",
            "235/242 [============================>.] - ETA: 0s - loss: 0.3918 - accuracy: 0.8394\n",
            "Epoch 74: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3927 - accuracy: 0.8388 - val_loss: 0.5772 - val_accuracy: 0.7840\n",
            "Epoch 75/100\n",
            "241/242 [============================>.] - ETA: 0s - loss: 0.3911 - accuracy: 0.8406\n",
            "Epoch 75: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3908 - accuracy: 0.8408 - val_loss: 0.5895 - val_accuracy: 0.7729\n",
            "Epoch 76/100\n",
            "240/242 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8417\n",
            "Epoch 76: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3827 - accuracy: 0.8416 - val_loss: 0.5814 - val_accuracy: 0.7769\n",
            "Epoch 77/100\n",
            "240/242 [============================>.] - ETA: 0s - loss: 0.3909 - accuracy: 0.8368\n",
            "Epoch 77: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3905 - accuracy: 0.8371 - val_loss: 0.5876 - val_accuracy: 0.7790\n",
            "Epoch 78/100\n",
            "240/242 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8441\n",
            "Epoch 78: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3837 - accuracy: 0.8441 - val_loss: 0.5697 - val_accuracy: 0.7796\n",
            "Epoch 79/100\n",
            "238/242 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.8397\n",
            "Epoch 79: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3885 - accuracy: 0.8395 - val_loss: 0.6112 - val_accuracy: 0.7634\n",
            "Epoch 80/100\n",
            "234/242 [============================>.] - ETA: 0s - loss: 0.3830 - accuracy: 0.8409\n",
            "Epoch 80: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3823 - accuracy: 0.8417 - val_loss: 0.6167 - val_accuracy: 0.7697\n",
            "Epoch 81/100\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.3794 - accuracy: 0.8423\n",
            "Epoch 81: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3794 - accuracy: 0.8423 - val_loss: 0.5788 - val_accuracy: 0.7793\n",
            "Epoch 82/100\n",
            "240/242 [============================>.] - ETA: 0s - loss: 0.3857 - accuracy: 0.8412\n",
            "Epoch 82: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3864 - accuracy: 0.8408 - val_loss: 0.5757 - val_accuracy: 0.7762\n",
            "Epoch 83/100\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.3788 - accuracy: 0.8448\n",
            "Epoch 83: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3788 - accuracy: 0.8448 - val_loss: 0.5630 - val_accuracy: 0.7795\n",
            "Epoch 84/100\n",
            "235/242 [============================>.] - ETA: 0s - loss: 0.3762 - accuracy: 0.8449\n",
            "Epoch 84: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3773 - accuracy: 0.8441 - val_loss: 0.5832 - val_accuracy: 0.7797\n",
            "Epoch 85/100\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.3743 - accuracy: 0.8447\n",
            "Epoch 85: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3743 - accuracy: 0.8447 - val_loss: 0.6059 - val_accuracy: 0.7753\n",
            "Epoch 86/100\n",
            "241/242 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8432\n",
            "Epoch 86: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3830 - accuracy: 0.8431 - val_loss: 0.6166 - val_accuracy: 0.7661\n",
            "Epoch 87/100\n",
            "240/242 [============================>.] - ETA: 0s - loss: 0.3789 - accuracy: 0.8451\n",
            "Epoch 87: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3792 - accuracy: 0.8447 - val_loss: 0.5891 - val_accuracy: 0.7752\n",
            "Epoch 88/100\n",
            "240/242 [============================>.] - ETA: 0s - loss: 0.3702 - accuracy: 0.8484\n",
            "Epoch 88: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3703 - accuracy: 0.8481 - val_loss: 0.5925 - val_accuracy: 0.7748\n",
            "Epoch 89/100\n",
            "241/242 [============================>.] - ETA: 0s - loss: 0.3702 - accuracy: 0.8474\n",
            "Epoch 89: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3706 - accuracy: 0.8472 - val_loss: 0.5965 - val_accuracy: 0.7752\n",
            "Epoch 90/100\n",
            "238/242 [============================>.] - ETA: 0s - loss: 0.3618 - accuracy: 0.8495\n",
            "Epoch 90: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3622 - accuracy: 0.8492 - val_loss: 0.5822 - val_accuracy: 0.7798\n",
            "Epoch 91/100\n",
            "241/242 [============================>.] - ETA: 0s - loss: 0.3793 - accuracy: 0.8434\n",
            "Epoch 91: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3793 - accuracy: 0.8434 - val_loss: 0.5771 - val_accuracy: 0.7804\n",
            "Epoch 92/100\n",
            "240/242 [============================>.] - ETA: 0s - loss: 0.3687 - accuracy: 0.8522\n",
            "Epoch 92: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3687 - accuracy: 0.8520 - val_loss: 0.6181 - val_accuracy: 0.7743\n",
            "Epoch 93/100\n",
            "241/242 [============================>.] - ETA: 0s - loss: 0.3638 - accuracy: 0.8511\n",
            "Epoch 93: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3637 - accuracy: 0.8512 - val_loss: 0.6014 - val_accuracy: 0.7769\n",
            "Epoch 94/100\n",
            "241/242 [============================>.] - ETA: 0s - loss: 0.3744 - accuracy: 0.8447\n",
            "Epoch 94: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3744 - accuracy: 0.8447 - val_loss: 0.5855 - val_accuracy: 0.7832\n",
            "Epoch 95/100\n",
            "239/242 [============================>.] - ETA: 0s - loss: 0.3692 - accuracy: 0.8517\n",
            "Epoch 95: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 9ms/step - loss: 0.3696 - accuracy: 0.8516 - val_loss: 0.6004 - val_accuracy: 0.7719\n",
            "Epoch 96/100\n",
            "240/242 [============================>.] - ETA: 0s - loss: 0.3690 - accuracy: 0.8496\n",
            "Epoch 96: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3684 - accuracy: 0.8498 - val_loss: 0.5723 - val_accuracy: 0.7795\n",
            "Epoch 97/100\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.3659 - accuracy: 0.8530\n",
            "Epoch 97: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3659 - accuracy: 0.8530 - val_loss: 0.6220 - val_accuracy: 0.7700\n",
            "Epoch 98/100\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.3714 - accuracy: 0.8490\n",
            "Epoch 98: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3714 - accuracy: 0.8490 - val_loss: 0.5991 - val_accuracy: 0.7750\n",
            "Epoch 99/100\n",
            "242/242 [==============================] - ETA: 0s - loss: 0.3665 - accuracy: 0.8521\n",
            "Epoch 99: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3665 - accuracy: 0.8521 - val_loss: 0.6260 - val_accuracy: 0.7724\n",
            "Epoch 100/100\n",
            "235/242 [============================>.] - ETA: 0s - loss: 0.3609 - accuracy: 0.8517\n",
            "Epoch 100: val_accuracy did not improve from 0.80440\n",
            "242/242 [==============================] - 2s 8ms/step - loss: 0.3618 - accuracy: 0.8516 - val_loss: 0.6314 - val_accuracy: 0.7704\n",
            "423/423 [==============================] - 1s 2ms/step - loss: 0.6314 - accuracy: 0.7704\n",
            "Loss: 0.6314149498939514, Accuracy: 0.7704262733459473\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_112 (Dense)           (None, 1024)              130048    \n",
            "                                                                 \n",
            " batch_normalization_25 (Ba  (None, 1024)              4096      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_113 (Dense)           (None, 512)               524800    \n",
            "                                                                 \n",
            " batch_normalization_26 (Ba  (None, 512)               2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_114 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " batch_normalization_27 (Ba  (None, 512)               2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_115 (Dense)           (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_28 (Ba  (None, 256)               1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_116 (Dense)           (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_29 (Ba  (None, 128)               512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_117 (Dense)           (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1091843 (4.17 MB)\n",
            "Trainable params: 1086979 (4.15 MB)\n",
            "Non-trainable params: 4864 (19.00 KB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "fit_model(model, X_train_res, y_train_res, X_test, y_test, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EtVDSxw3120i",
        "outputId": "aaf772bc-220a-4846-d191-c8a22718a99d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "423/423 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqsAAAIjCAYAAAAk+FJEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHmElEQVR4nO3dd1xV9ePH8TcgIHsobgW3uEdLUcBvZm7NtjlzNMzcO3furVmOSk2ttFx91dLKwHBlidscOHAPUERRVLi/P/x5v93QAkLuR3s9Hw8fj+6553zu5/D9Ai/OPedcB4vFYhEAAABgIEd7TwAAAAC4H2IVAAAAxiJWAQAAYCxiFQAAAMYiVgEAAGAsYhUAAADGIlYBAABgLGIVAAAAxiJWAQAAYCxiFQDu4dChQ6pbt658fHzk4OCgFStWZOn4x44dk4ODg+bNm5el4z7MwsPDFR4ebu9pADAMsQrAWDExMXrjjTdUrFgx5cyZU97e3goJCdHUqVN1/fr1B/rabdq00e7duzVy5EgtWLBAjz322AN9vezUtm1bOTg4yNvb+55fx0OHDsnBwUEODg6aMGFChsc/ffq0hg4dqh07dmTBbAH82+Ww9wQA4F5Wr16tF198Ua6urmrdurXKly+vmzdvKioqSr1799bevXs1e/bsB/La169f1+bNmzVw4EC98847D+Q1AgMDdf36dTk7Oz+Q8f9Ojhw5lJSUpP/+97966aWXbJ5btGiRcubMqRs3bmRq7NOnT2vYsGEKCgpS5cqV073dunXrMvV6AB5txCoA4xw9elSvvPKKAgMDtX79euXPn9/6XOfOnXX48GGtXr36gb3+hQsXJEm+vr4P7DUcHByUM2fOBzb+33F1dVVISIi++OKLNLH6+eefq2HDhlq6dGm2zCUpKUnu7u5ycXHJltcD8HDhNAAAxhk3bpyuXr2qTz75xCZU7ypRooS6du1qfXz79m2NGDFCxYsXl6urq4KCgjRgwAAlJyfbbBcUFKRGjRopKipKTzzxhHLmzKlixYrps88+s64zdOhQBQYGSpJ69+4tBwcHBQUFSbrz9vnd//6joUOHysHBwWbZ999/r5o1a8rX11eenp4qXbq0BgwYYH3+fuesrl+/XrVq1ZKHh4d8fX3VtGlT7d+//56vd/jwYbVt21a+vr7y8fFRu3btlJSUdP8v7J+0aNFC3377rS5fvmxdtm3bNh06dEgtWrRIs358fLx69eqlChUqyNPTU97e3qpfv7527txpXSciIkKPP/64JKldu3bW0wnu7md4eLjKly+v3377TaGhoXJ3d7d+Xf58zmqbNm2UM2fONPv/7LPPys/PT6dPn073vgJ4eBGrAIzz3//+V8WKFVONGjXStX6HDh00ePBgVa1aVZMnT1ZYWJhGjx6tV155Jc26hw8f1gsvvKBnnnlGEydOlJ+fn9q2bau9e/dKkpo3b67JkydLkl599VUtWLBAU6ZMydD89+7dq0aNGik5OVnDhw/XxIkT1aRJE23cuPEvt/vhhx/07LPP6vz58xo6dKh69OihTZs2KSQkRMeOHUuz/ksvvaTExESNHj1aL730kubNm6dhw4ale57NmzeXg4ODli1bZl32+eefq0yZMqpatWqa9Y8cOaIVK1aoUaNGmjRpknr37q3du3crLCzMGo7BwcEaPny4JKlTp05asGCBFixYoNDQUOs4cXFxql+/vipXrqwpU6aodu3a95zf1KlTFRAQoDZt2iglJUWSNGvWLK1bt07Tp09XgQIF0r2vAB5iFgAwSEJCgkWSpWnTpulaf8eOHRZJlg4dOtgs79Wrl0WSZf369dZlgYGBFkmWDRs2WJedP3/e4urqaunZs6d12dGjRy2SLOPHj7cZs02bNpbAwMA0cxgyZIjljz9OJ0+ebJFkuXDhwn3nffc15s6da11WuXJlS548eSxxcXHWZTt37rQ4OjpaWrduneb1Xn/9dZsxn3vuOUuuXLnu+5p/3A8PDw+LxWKxvPDCC5ann37aYrFYLCkpKZZ8+fJZhg0bds+vwY0bNywpKSlp9sPV1dUyfPhw67Jt27al2be7wsLCLJIsM2fOvOdzYWFhNsvWrl1rkWR5//33LUeOHLF4enpamjVr9rf7CODRwZFVAEa5cuWKJMnLyytd669Zs0aS1KNHD5vlPXv2lKQ057aWLVtWtWrVsj4OCAhQ6dKldeTIkUzP+c/unuu6cuVKpaampmubM2fOaMeOHWrbtq38/f2tyytWrKhnnnnGup9/9Oabb9o8rlWrluLi4qxfw/Ro0aKFIiIidPbsWa1fv15nz5695ykA0p3zXB0d7/zaSElJUVxcnPUUh+3bt6f7NV1dXdWuXbt0rVu3bl298cYbGj58uJo3b66cOXNq1qxZ6X4tAA8/YhWAUby9vSVJiYmJ6Vr/+PHjcnR0VIkSJWyW58uXT76+vjp+/LjN8iJFiqQZw8/PT5cuXcrkjNN6+eWXFRISog4dOihv3rx65ZVXtGTJkr8M17vzLF26dJrngoODdfHiRV27ds1m+Z/3xc/PT5IytC8NGjSQl5eXFi9erEWLFunxxx9P87W8KzU1VZMnT1bJkiXl6uqq3LlzKyAgQLt27VJCQkK6X7NgwYIZuphqwoQJ8vf3144dOzRt2jTlyZMn3dsCePgRqwCM4u3trQIFCmjPnj0Z2u7PFzjdj5OT0z2XWyyWTL/G3fMp73Jzc9OGDRv0ww8/qFWrVtq1a5defvllPfPMM2nW/Sf+yb7c5erqqubNm2v+/Plavnz5fY+qStKoUaPUo0cPhYaGauHChVq7dq2+//57lStXLt1HkKU7X5+MiI6O1vnz5yVJu3fvztC2AB5+xCoA4zRq1EgxMTHavHnz364bGBio1NRUHTp0yGb5uXPndPnyZeuV/VnBz8/P5sr5u/589FaSHB0d9fTTT2vSpEnat2+fRo4cqfXr1+unn36659h353ngwIE0z/3+++/KnTu3PDw8/tkO3EeLFi0UHR2txMTEe16UdtfXX3+t2rVr65NPPtErr7yiunXrqk6dOmm+Jun9wyE9rl27pnbt2qls2bLq1KmTxo0bp23btmXZ+ADMR6wCME6fPn3k4eGhDh066Ny5c2mej4mJ0dSpUyXdeRtbUpor9idNmiRJatiwYZbNq3jx4kpISNCuXbusy86cOaPly5fbrBcfH59m27s3x//z7bTuyp8/vypXrqz58+fbxN+ePXu0bt06634+CLVr19aIESP0wQcfKF++fPddz8nJKc1R26+++kqnTp2yWXY3qu8V9hnVt29fxcbGav78+Zo0aZKCgoLUpk2b+34dATx6+FAAAMYpXry4Pv/8c7388ssKDg62+QSrTZs26auvvlLbtm0lSZUqVVKbNm00e/ZsXb58WWFhYfrll180f/58NWvW7L63RcqMV155RX379tVzzz2nd999V0lJSfroo49UqlQpmwuMhg8frg0bNqhhw4YKDAzU+fPn9eGHH6pQoUKqWbPmfccfP3686tevr+rVq6t9+/a6fv26pk+fLh8fHw0dOjTL9uPPHB0d9d577/3teo0aNdLw4cPVrl071ahRQ7t379aiRYtUrFgxm/WKFy8uX19fzZw5U15eXvLw8NCTTz6pokWLZmhe69ev14cffqghQ4ZYb6U1d+5chYeHa9CgQRo3blyGxgPwcOLIKgAjNWnSRLt27dILL7yglStXqnPnzurXr5+OHTumiRMnatq0adZ1P/74Yw0bNkzbtm1Tt27dtH79evXv319ffvllls4pV65cWr58udzd3dWnTx/Nnz9fo0ePVuPGjdPMvUiRIvr000/VuXNnzZgxQ6GhoVq/fr18fHzuO36dOnX03XffKVeuXBo8eLAmTJigp556Shs3bsxw6D0IAwYMUM+ePbV27Vp17dpV27dv1+rVq1W4cGGb9ZydnTV//nw5OTnpzTff1KuvvqrIyMgMvVZiYqJef/11ValSRQMHDrQur1Wrlrp27aqJEydqy5YtWbJfAMzmYMnImfgAAABANuLIKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIz1SH6CVcyF6/aeAvBQyueT095TAB5KTo4O9p4C8NDJmc4K5cgqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFg57D2BIkWKKDw8XGFhYQoPD1fx4sXtPSUAAAAYwu5HVkeNGqWcOXNq7NixKlmypAoXLqyWLVtqzpw5OnTokL2nBwAAADtysFgsFntP4q4zZ84oMjJSq1at0uLFi5WamqqUlJQMjxNz4foDmB3w6Mvnk9PeUwAeSk6ODvaeAvDQyZnO9/ftfhqAJCUlJSkqKkoRERH66aefFB0drfLlyys8PNzeUwMAAIAd2f3Iao0aNRQdHa3g4GDruauhoaHy8/PL9JgcWQUyhyOrQOZwZBXIuPQeWbX7Oau///67PDw8VKZMGZUpU0bBwcH/KFQBAADw6LB7rMbFxWn9+vV66qmntHbtWoWEhKhgwYJq0aKF5syZY+/pAQAAwI7sfhrAH1ksFv3222/64IMPtGjRIi6wArIZpwEAmcNpAEDGPTQXWG3fvl0RERGKiIhQVFSUEhMTVaFCBXXp0kVhYWH2nh7SISnpmhbMmaFNG35SwqV4FS9VWm907aNSweUlSdeTkjR35lRt/vknJSYkKG+Bgmrywqtq2OxF6xh932mv3Tt+sxm3ftMX1KX3e9m6L0B2+fTjWVr/w/c6dvSIXHPmVKVKVfRu954KKlrMus7SrxbruzWr9Pv+fbp27ZoiN/4iL29vm3H279uraZMnau/e3XJydNR/6tRVzz795O7ukd27BNjNtWtXNWPaVK3/8QfFx8epTHBZ9ek3QOUrVJQk/fD9On215Evt37tXCQmXtfjrFSoTHGznWSO97B6rTzzxhKpUqaKwsDB17NhRoaGh8vHxsfe0kAFTxwzT8SOH1WvQ+8qVO0Dr167WgG5vaubCpcodkFdzpk/Qzu3b1HvQSOXNX0Dbf9msGZNGK1fuAD1VM9w6Tr3GzdWyw9vWxzlzcpQPj67fft2ml15poXLlKyglJUUfTJ2st9/ooKUrVsnN3V2SdOPGDdUIqaUaIbU0feqkNGNcOH9Ob3V8XXXr1VffAe/p2rVrmjB2lIa811/jJ03L7l0C7Gbo4Pd0+NAhjRwzTgEBebR61Td6o0M7LftmjfLmzavr15NUpUpVPftsfQ0bwkGQh43dYzU+Pl7efzpSgIdHcvINbYz8UYNHT1aFytUkSS3bv6VfNm7Q6uVfqU2nd7R/z049Xb+xKlZ9XNKdI6bfrlyqA/v22MSqa86c8s+V2x67AWS7GTM/tnk87P3Rejqshvbt26tqj935XnmtVRtJ0q/btt5zjA2REcqRI4f6DRwsR8c7lyAMGDRULz/fVLGxx1WkSOAD3APADDdu3NCP36/TlOkfWr933urcRZERP+mrLz/XO127q3GTZpKkU6dO2nGmyCy7X2BFqD7cUlJSlJqSIhcXV5vlLq6u2rcrWpIUXL6StkZF6OKFc7JYLNq5fZtOnTiuqk9Ut9nmp++/1SsNw/VWq+c1d+Y03bjBucf490i8mihJGXpn6dbNm3J2draGqnTnjz5J2rH9t/ttBjxSUlJuKyUlRa6utr+HXF1dFR293U6zQlay+5HVlJQUTZ48WUuWLFFsbKxu3rxp83x8fLydZob0cHf3UHD5ivpi3mwVDioqX79civzhO/2+d5fyFywsSXqrez9NGzdcrZ97Vk5OOeTg6KCufQZbj8RKUvgz9ZUnXwH55w7QsZiD+vSjqToVe0zvjUr71ifwqElNTdWEsaNUuUpVlShZKt3bPf7kU5o0Yazmz/1ELVq20vWk65o+ZaIk6eLFCw9quoBRPDw8ValyFc2e+aGKFiumXLly69s1q7Rr5w4VLlLE3tNDFrD7kdVhw4Zp0qRJevnll5WQkKAePXqoefPmcnR01NChQ/92++TkZF25csXmX3Jy8oOfOKx6DRopi6RWzeqq6X+e0Ddff66wOvWsR3u++foL/b53t4aMmappn3yuju/01IeTRit62xbrGPWbvqBqT9ZQ0eIlVbtuQ/V8731t2rBeZ06dsNNeAdlnzMjhijl8SKPHZeyPs+IlSmrY+6O1cP5c1Xi8ip6pXVMFChZSrly55ehg9x/vQLYZOXqcLBaLnqkdqserVNDnCxeoXoOGNu864OFl9yOrixYt0pw5c9SwYUMNHTpUr776qooXL66KFStqy5Ytevfdd/9y+9GjR2vYsGE2y7r0GqCufTiBOrvkL1hY4z74RDeuX1fStavyzx2g0YP7KF+BgkpOvqH5s6frvVGT9ESNUElS0RKlFHPogJZ98ZmqPP7UPccsU7aCJOn0yRPWI7TAo2jMyOH6OTJCH89bqLz58mV4+/oNG6t+w8aKu3hRbu5ucpCDFn02TwUL8X2Df4/CRYro0/kLlZSUpGvXriogII969+ymQnwfPBLs/ifH2bNnVaHCnTDx9PRUQkKCJKlRo0ZavXr1327fv39/JSQk2Px7s2vvBzpn3FtONzf55w5Q4pUr2v7LJj1VM1wpt2/r9u3bcvjTUR4nR0elWlLvO1bMod8liQuu8MiyWCwaM3K4flr/g2Z9Mk8FCxX6R+Plyp1b7u4eWrv2W7m4uuqp6jWyaKbAw8Pd3V0BAXl0JSFBmzdGKbz20/aeErKA3Y+sFipUSGfOnFGRIkVUvHhxrVu3TlWrVtW2bdvSnCx9L66urmlPqk7mwpzs9NvWTbJYLCpUJEinT8Xq0xmTVahIUT3TsKly5HBWhcrV9OmHk+Xq6qo8+Qpo945f9eN3q9SxS09J0plTJ/TT99/q8adqytvHR0djDmn2tAkqX7maipZI//l7wMNkzMjh+nbNKk2eOkPuHh7Wc0w9Pb2st227ePGC4i5e1InYWEnSoUMH5eHhoXz588vHx1eS9OXnC1WpchW5u7try+ZNmjppvLp065HmfqzAo2xj1M+SxaLAokV1IjZWkyeMU1DRYmr6XHNJUsLlyzpz5owuXDgvSTp27KgkKXfu3ModEGC3eSN97P4JVv369ZO3t7cGDBigxYsXq2XLlgoKClJsbKy6d++uMWPGZHhMPsEqe234ca3mzZquixfOycvbRyFhT6tNp3fk4eklSYqPu6h5s6Yp+pfNSrxyRXny5Ve9Js/ruZdbysHBQRfOndX4EQN1/Mhh3bhxXQF58qp66H/0apuOcvfwtPPe/bvwCVbZp2qFMvdcPnTEKDVpducX7MwPp2v2RzP+cp1BA/oqakOEkpKSFFS0mFq1fV2NGjd9cBPHPfEJVva19rs1mjZlks6dPSsfH189/UxddenaXV5ed34PrVy+TIPf659muzfffkdvde6S3dPF/0vvJ1jZPVb/bMuWLdq0aZNKliypxo0bZ2oMYhXIHGIVyBxiFci4hyJWb926pTfeeEODBg1S0aJFs2xcYhXIHGIVyBxiFci49MaqXS+wcnZ21tKlS+05BQAAABjM7ncDaNasmVasWGHvaQAAAMBAdr8bQMmSJTV8+HBt3LhR1apVk4eHh83zf3efVQAAADy67H6B1V+dq+rg4KAjR45keEzOWQUyh3NWgczhnFUg49J7zqrdj6wePXrU3lMAAACAoewSqz169EjXeg4ODpo4ceIDng0AAABMZZdYjY6Otnm8fft23b59W6VLl5YkHTx4UE5OTqpWrZo9pgcAAABD2CVWf/rpJ+t/T5o0SV5eXpo/f778/PwkSZcuXVK7du1Uq1Yte0wPAAAAhrD7BVYFCxbUunXrVK5cOZvle/bsUd26dXX69OkMj8kFVkDmcIEVkDlcYAVk3EPxoQCSdOXKFV24cCHN8gsXLigxMdEOMwIAAIAp7B6rzz33nNq1a6dly5bp5MmTOnnypJYuXar27durefPm9p4eAAAA7MjupwEkJSWpV69e+vTTT3Xr1i1JUo4cOdS+fXuNHz8+zYcEpAenAQCZw2kAQOZwGgCQcek9DcDusXrXtWvXFBMTI0kqXrx4piL1LmIVyBxiFcgcYhXIuIcuVrMSsQpkDrEKZA6xCmTcQ3OBFQAAAHA/xCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWDnsPYEHwcP1kdwt4IFbvPOEvacAPJRaVCli7ykAjyyOrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWJmK1Z9//lktW7ZU9erVderUKUnSggULFBUVlaWTAwAAwL9bhmN16dKlevbZZ+Xm5qbo6GglJydLkhISEjRq1KgsnyAAAAD+vTIcq++//75mzpypOXPmyNnZ2bo8JCRE27dvz9LJAQAA4N8tw7F64MABhYaGplnu4+Ojy5cvZ8WcAAAAAEmZiNV8+fLp8OHDaZZHRUWpWLFimZrE/PnztXr1auvjPn36yNfXVzVq1NDx48czNSYAAAAefhmO1Y4dO6pr167aunWrHBwcdPr0aS1atEi9evXSW2+9lalJjBo1Sm5ubpKkzZs3a8aMGRo3bpxy586t7t27Z2pMAAAAPPxyZHSDfv36KTU1VU8//bSSkpIUGhoqV1dX9erVS126dMnUJE6cOKESJUpIklasWKHnn39enTp1UkhIiMLDwzM1JgAAAB5+GY5VBwcHDRw4UL1799bhw4d19epVlS1bVp6enpmehKenp+Li4lSkSBGtW7dOPXr0kCTlzJlT169fz/S4yB4Xzp/TrOmTtHVzlG7cuKGChYqo3+ARKlO2vCRp7uwZWr/uO50/d1Y5nJ1VukxZdXj7XZUtX9E6xpWEBE0dP0qboiLk6OCo0P/UUZee/eXu7m6v3QKy1OZvvtDBbVGKP3NCOVxcVbBkWYW93EG5ChS2We/UoX3a8NVcnYn5XQ4OjsoTWFwv9R0tZxdXJVw4q40rFil23w5duxwvT79cKhvytGo0bSGnHHcueI3dt1PbvluqMzEHdPNGkvzyFtATDV9SuZCn7bHbwAOXkpKij2ZM1+pV3yju4kUF5MmjJk2fU6c335aDg4MkKe7iRU2ZNEGbN0UpMTFRVas9pn4DBykwMMi+k0e6ZDhW73JxcVHZsmWzZBLPPPOMOnTooCpVqujgwYNq0KCBJGnv3r0KCgrKktfAg5F4JUHvdGilytWe0LipM+Xr66eTJ47Ly9vbuk6hIkHq2nuAChQspOTkZH31xWfq9U4nfb58jXz9/CVJIwb1VfzFC5r4wRzdvn1bY4a/pwmjhmrw++PstWtAljqxf5eqPtNE+YqVliUlRZFLPtWSsf3UfuzHcsl55zSoU4f2acm4/qre+FXVad1Zjo5OOh975H+/cE+fkCU1Vc++3lV+eQvqwomj+u6TybqVfEP/afHG/4+xVwGFi+nJRi/Lw8dPMdFbtHrmOLm6e6hElafstv/AgzL3kzn6avEXGjFqrIqXKKF9e/Zo8Hv95enlpddatpbFYlG3dzsrR44cmjL9Q3l6euqz+fP0Rvt2WvbNag6KPAQcLBaLJSMb1K5d2/qD817Wr1+f4UlcvnxZ7733nk6cOKG33npL9erVkyQNGTJELi4uGjhwYIbGO3vlVobngMyZNX2ydu+K1gdzPkv3NteuXlWD2k9p0oyPVe2Jp3TsaIzavNRUs+Z/aT0au3VTlPp2e0tfr/5RuQPyPKjp40/WHDhj7yn8ayRduazpb7+oFu9NVOEyd95l+GxIFwWVr6bQF9ume5ytq5Yo+sf/6s3JC+67zlfjB8rDx08NOvX6p9PGfbSoUsTeU/jXeuftN5QrVy4NG/G/e7336NpFrjldNXrsBB07dlRNG9bT0pWrVKJESUlSamqq/hMWone79lDzF16019T/9XKm85Bpho+sVq5c2ebxrVu3tGPHDu3Zs0dt2rTJ6HCSJF9fX33wwQdplg8bNixT4yH7bPz5Jz3xVIgG9+uhndt/Ve6APGr2witq/NwL91z/1q1b+u/yr+Tp6aXipUpLkvbu3ilPL29rqEpStSeekqOjo/bt2aXQ2nWyZV+A7JScdE2SlNPDS5J0LeGSzsT8rnIhT2vBsK66fO60chUorNAXX1eh0uXvP871a3Lz9Prr17p+TbkKElN4NFWuXEVLv1qiY8eOKiioqA78/ruio39Trz79JEm3bt6UJLm6uFq3cXR0lIuLi6K3/0asPgQyHKuTJ0++5/KhQ4fq6tWrmZrEd999J09PT9WsWVOSNGPGDM2ZM0dly5bVjBkz5Ofnl6lx8eCdOXVSK5cu1ostWqtlu476fe8eTZs4Ws7OzqrXqKl1vU0/R2j4wN66ceOGcuUO0IQPZsvX987/rvFxF+X3/6cD3JUjRw55efsoPu5idu4OkC0sqan6ceFHKliqnAIKF5UkXb5w56h21LLPVPvVTsobWEJ7or7Xl6P76PUxs+Wfr1CacS6dPaXf1q1Q7f8/BeBe9m+J1NkjB/Xs690eyL4A9vZ6h066evWqmjWqLycnJ6WkpKhL1+5q2KiJJCmoaDHlz19A06ZM1KAhw+Xm5qYFn83TubNndeHCBTvPHumR4VtX3U/Lli316aefZmrb3r1768qVK5Kk3bt3q2fPnmrQoIGOHj1qvdjqfpKTk3XlyhWbf3c/AhYPXmpqqkqWDlanzt1UqnSwmjR/UY2aPa+Vy5bYrFflsSf08aKlmvHJQj1RPURDB/TSpfg4O80asK9186frwsljatL5f6c4WVLvnJFVuXZDVQyrp7xBJfR0y7fkn7+QdkeuTTNGYvxFLRk3QGWeCFXl2g3u+TrH9+3Qt3MmqF777gooFPRA9gWwt7Xffas1q/+r0eMm6suvlmnEqDGaP/dTfbNiuSTJ2dlZk6ZO1/Fjx1SrxhN68rHK2vbLVtWsFSpHx/uf1ghzZFmsbt68WTlz5szUtkePHrVerLV06VI1atRIo0aN0owZM/Ttt9/+5bajR4+Wj4+Pzb/pk8Zmah7IuFy5AxRUrLjNssCgYjp/1vbcRzc3dxUqXETlKlRS30Ej5OTkpNUrl0mS/HPl1qVL8Tbr3759W4lXEuSfK/eD3QEgm30/f7piorfq1QHj5Z0rwLrc0/fOuwu5CwbarJ+rQBFdiTtvsyzx0kV9MaqXCpYqq3rt730v6tj9O7V04iD957U3Vb7WM1m8F4A5Jk8cp9fbd1L9Bg1VslRpNW7STC1bt9EnH8+yrlO2XHktWbZSUVt+1Q8RUfpo9ie6fPmyChUq/BcjwxQZPg2gefPmNo8tFovOnDmjX3/9VYMGDcrUJFxcXJSUlCRJ+uGHH9S6dWtJkr+/v/WI6/30798/zdHXS8lZ1uD4G+UrVVHs8WM2y07GHlfefPn/cjtLaqpu3bpzHlG5CpV0NfGKDuzfq9LB5SRJ0b9uVWpqqs3trYCHmcVi0Q+ffaCDv27UqwMnyDeP7feIT0A+efrlUtyZkzbL48+eVLGKj1sfJ8bfCdV8QSXVoFMvOTim/XkXu2+nvp74nsJf6aDK/2n4YHYIMMSN6zfSHCF1cnJSamra68e9vO6c3338+DHt27tHnbt0zZY54p/JcKz6+PjYPHZ0dFTp0qU1fPhw1a1bN1OTqFmzpnr06KGQkBD98ssvWrx4sSTp4MGDKlQo7Xlaf+Tq6ipXV1ebZUncDSDbvPhqK3Vu30oL5s5W7Tr1tH/vbv13+dfqNWCIJOn69SQt+HS2QkJrK1fuACVcvqTlX32hixfOK/zpZyVJQUWL64nqNTV+5FD17D9Yt2/f0pTxo/SfuvW5EwAeGd/Pm659m9erefdhcsnprquX77yb4OruIWcXVzk4OOiJhi8paul85QksprxFimv3z98r/vQJNXt3sKT/D9WRPeWdO69qt3hDSVcSrOPfPTJ7fN8OLZ04SNXqNlOpx2tZX8cpRw65eXoLeNSEhdfWnNkzlS9/ARUvUUK/79+vBfPnqulzz1vXWbf2W/n5+St//gI6dOiAxo0epdr/qaMaITXtOHOkV4ZuXZWSkqKNGzeqQoUKWXrRU2xsrN5++22dOHFC7777rtq3by9J6t69u1JSUjRt2rQMjcetq7LXpp8jNHvGVJ06cVz5ChTUSy3aWO8GkJycrBHv9dH+vbuVcPmSvH18VaZsebV6vZOCy1WwjnElIUFTxo/Upp//96EA7/YawP3vshm3rnpwxra891vxDTr1UoXQZ62Pt3zzpbb/8I1uXEtUQJFiqv1KR+vdAHZvWKs1syfcc5y+C7+XJK2eNU57fv4+zfOFy1RUi/cm/tPdwH1w6yr7uXbtqmZMm6r1P/6g+Pg4BeTJo/r1G+qNtzrL2cVFkrRo4WeaP/cTxV2MU0BAgBo1aao33nzb+jzsI723rsrwfVZz5syp/fv3q2jRopmZV7YgVoHMIVaBzCFWgYx7YPdZLV++vI4cOZLlsZqSkqIVK1Zo//79kqRy5cqpSZMmcnJyytLXAQAAwMMjw0dWv/vuO/Xv318jRoxQtWrV5OHhYfO8t3fGz4k6fPiwGjRooFOnTql06Ts3ij9w4IAKFy6s1atXq3jx4n8zgi2OrAKZw5FVIHM4sgpkXJafBjB8+HD17NnTeiWdJJuPXbVYLHJwcFBKSkrGZiqpQYMGslgsWrRokfz971wkEBcXp5YtW8rR0VGrV6/O0HjEKpA5xCqQOcQqkHFZHqtOTk46c+aM9W36+wkLC0vfK/+Bh4eHtmzZogoVKtgs37lzp0JCQjL8yVjEKpA5xCqQOcQqkHFZfs7q3abNTIz+HVdXVyUmJqZZfvXqVblwpR4AAMC/Vobunv/Ht/2zUqNGjdSpUydt3bpVFotFFotFW7Zs0ZtvvqkmTZo8kNcEAACA+TJ0N4BSpUr9bbDGx8f/5fP3Mm3aNLVp00bVq1eXs7OzJOnWrVtq2rSppkyZkuHxAAAA8GjIUKwOGzYszSdYZQVfX1+tXLlShw8ftp4TGxwcrBIlSmT5awEAAODhke4LrBwdHXX27FnlyZM1H3/Zo0ePdK87adKkDI3NBVZA5nCBFZA5XGAFZFyWX2CV1eerRkdH2+V1AQAA8PDI8N0AsspPP/2UpeMBAADg0ZPuWE1NTX2Q8wAAAADSyNCtqwAAAIDsRKwCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYDhaLxWLvSWS1bUcT7D0F4KFULI+HvacAPJQK1exm7ykAD53r0R+kaz2OrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYOew9gWvXrmnMmDH68ccfdf78eaWmpto8f+TIETvNDAAAAPZm91jt0KGDIiMj1apVK+XPn18ODg72nhIAAAAMYfdY/fbbb7V69WqFhITYeyoAAAAwjN1j1c/PT/7+/vaeBtLp993btfrrhTp66Hddjr+oboPH6bEa4TbrnIo9qi8/+UC/796u1JQUFShSVF0HjVXuPPkkSevXLNemn9bqWMwB3Ui6pllf/ygPTy+bMVZ+8al2/LJRx48cVI4czpq9dH127SJgF5/NnaOZ06fopVdbqlvv/tblu3fu0KwZU7Vvz245OjmqZKkymjJjtlxz5tSZ06c0d85M/bZtq+LiLip3QB7Vq99IbTp0krOzix33Bsg6BQJ89H7XpqobUk7uOZ0Vc+Ki3hi6UNv3xUqSPNxc9P67TdW4dkX5+3jo2Ok4ffhFpD7+Oso6hqtLDo3p0VwvPltNri459MPm/eo6arHOxydKkvx9PDR3ZBtVKFVQ/j7uuhB/VasidmnwB/9V4rUbdtlv/I/dY3XEiBEaPHiw5s+fL3d3d3tPB38j+cYNFSlaUqF1G2vqiL5pnj93+qRG9OyosGeb6PlWneTm7qGTx4/I2eV/vzhvJt9Qxceqq+Jj1bVk7ox7vs7t27f1RK2nVSK4giLXfvPA9gcwwb69u7Vy6VcqUbKUzfLdO3eoR5c31KpdB/XoO1BOTk46fPCAHBzvXBt7/OgRpaamqs/AISpUuIiOxBzSmBFDdf3GdXXp3tseuwJkKV8vN62f10OR2w6p2Tsf6sKlqypRJECXriRZ1xnb83mFP15K7QZ+puOn41SnerCm9n9JZy4kaHXkbknSuF7Pq37Ncnqtzye6cvW6Jvd7SV9O7KD/tJssSUpNTdWqyF0a9uEqXbyUqGKFAzSl30ua7uOhtgPm2WPX8Qd2j9WJEycqJiZGefPmVVBQkJydnW2e3759u51mhnup9HgNVXq8xn2f/2r+R6r0eIhe7fCudVneAoVs1qn33KuSpH07f7vvOM+36iRJ2rBu1T+ZLmC8pKRrGjawr/oNGqZ5H8+yeW7axLF68ZXX1LpdR+uywKCi1v9+KqSWngqpZX1csFBhxR47puVfLyZW8Ujo2e4ZnTx7SW8MXWhddvx0nM06T1UqqoWrturn3w5Jkj5dtlHtnw/RY+UCtTpyt7w9c6pts+pqO2CeIrcdlCR1GrJQO5cP0hMVgvTL7mO6nHhdc77635HY2DOXNPurn9W9dZ1s2Ev8HbvHarNmzew9BWSR1NRU7fhloxq+0EpjB3TR8ZiDCshXQI1fbpPmVAEAd0wc875q1AzV409Wt4nV+Pg47d2zS3UbNFKntq/p1MkTCgwqqjc6v6tKVardd7yrVxPl7e2THVMHHriGYRX0w6b9WjTuddWsVlKnz1/W7CU/a+7yTdZ1tuw8qkZhFfTZis06fSFBoY+VVMnAPOozcakkqUpwEbk459D6LQes2xw8dk6xZ+L1ZMWi+mX3sTSvmz/AR03/U9kawLAvu8fqkCFD7D0FZJErl+N143qSVi2ZrxfavKlX2nfRzl83a+qIvhow9iMFV6xq7ykCRvl+7Rod+H2/PlmwOM1zp0+elCR9MmuG3unWWyVLl9F3q1bq3Tfba+FXK1W4SGCabU7GHtfXiz/XO916PfC5A9mhaMHc6vhiLU1buF7jPlmnauUCNbHPC7p5O0WL/rtVktRj7FeaMehVxawbqVu3UpRqSdXbI77Qxu0xkqR8ubyVfPOWEq5etxn7fNwV5c3lbbNs/ui2ahRWUe5uLloVuVtvDf88e3YUf8nusfpPJScnKzk52WbZzeRkubi62mlG/14Wi0WSVLV6qOo3byFJCixeSof27dKPq5cRq8AfnDt7RlPGj9HUD+fI9R4/ryyWO/ecbtb8JTVq+pwkqXSZYP36y1atWrlMb3XpbrP+hfPn1P2dN/SfOs+qafMXH/wOANnA0dFB2/fFasgH/5Uk7TxwUuVK5FfHF2paY/XtV8L0RIUgPd91pmLPxKtm1RKa0u/OOas/bT3wV8On0WfCUo2c9a1KBubR8C5NNLZnc3UbvSTL9wsZY5dY9ff318GDB5U7d275+fn95b1V4+Pj/3Ks0aNHa9iwYTbLOrzbV5269b/PFnhQvLx95eTkpIJFitosL1gkSAf27rTTrAAz/b5/ny7Fx6nda/8Ly5SUFO3Y/quWLvlCXyy7c752ULHiNtsFFS2mc2fP2Cy7cOG83unUThUqVVHf94Y+8LkD2eXsxSvaf+SszbLfj55Vs6crS5JyujprWJfGernHHH0XtVeStOfQaVUsXUjdWj2tn7Ye0Nm4K3J1cZaPp5vN0dU8ubx1Lu6Kzdjn4hJ1Li5RB4+d06WEa/pxbg+NmfOdzl60XQ/Zyy6xOnnyZHl53blV0ZQpU/7RWP3791ePHj1slu0+zW0m7CGHs7OKlSqrMydjbZafORVrvW0VgDsee+IpLViywmbZyKEDFRhUTC3btlfBQoWVOyCPYo8ftVknNvaYqtf430VVF86f0zud2ql0cFkNHPq+HB35FG08OjbvOKJSgXlslpUskkexZ+4cyHLO4SQX5xxK/f939u5KSUmVo+OdA2HR+2N189Zt1X6ytFb8uOPOGIF5VCS/v7busv3++iOH/9/exfmhfxP6oWeX/wXatGlj/e8ff/xR4eHhCgsLU/Hixf9iq3tzdXVN8xaaS5zlPmvjn7pxPUnnTp+0Pr5w9rSOxxyUh5e3cufJpwYvtNQHoweqTIUqCq5UTbt+3azoLVEaOO4j6zaX4y8q4VK8zp0+IUk6ceyw3Nw8lCtPXnl63bkw5OL5s7qWeEVxF84qNTVVx2PuXMGZt0Ah5XTjFmd4+Hl4eKh4iZI2y9zc3OXj42Nd/lrrdvp41gyVKFVapUqV0ZpVK3X82FGNHHfndjsXzp9T545tlS9/AXXp3luXL/3vnahcuQOyb2eAB2T6wvX6aV5P9X69rpZ+v12PlwvS68+H6J0RX0iSEq/d0IZfD2lUt2a6fuOWYs/Eq1a1Enqt0RPqO2mZJOnK1Ruat2KzxvZsrviEa0q8dkOT+r6oLTuPWC+uerZmWeXx99Zve4/ralKyyhbPr1Hdm2lTdIw1jGE/DhaLxa5l17FjR0VGRiomJkYFChRQWFiYNV5Lliz59wPcw7ajCVk8S9y1b+dvGtX3rTTLa9VpqDd63blYLnLtN/pm8XzFXzyv/IWK6PlWnVSteph13aULZmv5oo/TjNGpx2CF1m0kSZo1YZh+/mF1mnUGjP1IZSvd/0po/DPF8njYewr/ap07tlXJUqVtPhTgs7lztGzJl7qSkKASpUqrc9ce1rsBrP5muUYOfe+eY23avjdb5ow7CtXsZu8pPLLq1yqv4V2aqESRAB07FadpC9fb3A0gby4vDe/SVHWql5Gft7tiz8Tr02WbNG3h/z5M5u6HArxU7/8/FGDTfnUdvVjn4u58KEDoYyU17J3GKlMsn1ydc+jkuctauX6HJnz6fZoLs5B1rkd/kK717B6rd506dUobNmxQZGSkIiMjdfDgQeXPn18nT578+43/hFgFModYBTKHWAUyLr2xaszJTX5+fsqVK5f8/Pzk6+urHDlyKCCAt7EAAAD+zeweqwMGDFCNGjWUK1cu9evXTzdu3FC/fv109uxZRUdH23t6AAAAsCO7X+I2ZswYBQQEaMiQIWrevLlKlSr19xsBAADgX8HusRodHa3IyEhFRERo4sSJcnFxsV5kFR4eTrwCAAD8ixlzgdVdO3fu1OTJk7Vo0SKlpqYqJSUlw2NwgRWQOVxgBWQOF1gBGZfeC6zsfmTVYrEoOjpaERERioiIUFRUlK5cuaKKFSsqLCzs7wcAAADAI8vuserv76+rV6+qUqVKCgsLU8eOHVWrVi35+vrae2oAAACwM7vH6sKFC1WrVi15e3vbeyoAAAAwjN1jtWHDhvaeAgAAAAxl9/usAgAAAPdDrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACM5WCxWCz2ngT+PZKTkzV69Gj1799frq6u9p4O8FDg+wbIHL53Hg3EKrLVlStX5OPjo4SEBHl7e9t7OsBDge8bIHP43nk0cBoAAAAAjEWsAgAAwFjEKgAAAIxFrCJbubq6asiQIZzoDmQA3zdA5vC982jgAisAAAAYiyOrAAAAMBaxCgAAAGMRqwAAADAWsYosER4erm7dutl7GsBDg+8ZIHvMmzdPvr6+9p4G/gFiFQAAPLJefvllHTx40N7TwD+Qw94TwKPv5s2bcnFxsfc0AAD/Qm5ubnJzc7P3NPAPcGQVGXbt2jW1bt1anp6eyp8/vyZOnGjzfFBQkEaMGKHWrVvL29tbnTp1kiT17dtXpUqVkru7u4oVK6ZBgwbp1q1bkqSEhAQ5OTnp119/lSSlpqbK399fTz31lHXchQsXqnDhwtm0l0D2uXTpklq3bi0/Pz+5u7urfv36OnTokPX548ePq3HjxvLz85OHh4fKlSunNWvWWLd97bXXFBAQIDc3N5UsWVJz5861164A2WLVqlXy9fVVSkqKJGnHjh1ycHBQv379rOt06NBBLVu2THMawNChQ1W5cmUtWLBAQUFB8vHx0SuvvKLExMTs3g2kE7GKDOvdu7ciIyO1cuVKrVu3ThEREdq+fbvNOhMmTFClSpUUHR2tQYMGSZK8vLw0b9487du3T1OnTtWcOXM0efJkSZKPj48qV66siIgISdLu3bvl4OCg6OhoXb16VZIUGRmpsLCw7NtRIJu0bdtWv/76q7755htt3rxZFotFDRo0sP4x17lzZyUnJ2vDhg3avXu3xo4dK09PT0nSoEGDtG/fPn377bfav3+/PvroI+XOndueuwM8cLVq1VJiYqKio6Ml3fn9kDt3buvvkLvLwsPD77l9TEyMVqxYoVWrVmnVqlWKjIzUmDFjsmHmyBQLkAGJiYkWFxcXy5IlS6zL4uLiLG5ubpauXbtaLBaLJTAw0NKsWbO/HWv8+PGWatWqWR/36NHD0rBhQ4vFYrFMmTLF8vLLL1sqVapk+fbbby0Wi8VSokQJy+zZs7NwbwD7CQsLs3Tt2tVy8OBBiyTLxo0brc9dvHjR4ubmZv0+q1ChgmXo0KH3HKdx48aWdu3aZcucAZNUrVrVMn78eIvFYrE0a9bMMnLkSIuLi4slMTHRcvLkSYsky8GDBy1z5861+Pj4WLcbMmSIxd3d3XLlyhXrst69e1uefPLJ7N4FpBNHVpEhMTExunnzpp588knrMn9/f5UuXdpmvcceeyzNtosXL1ZISIjy5csnT09Pvffee4qNjbU+HxYWpqioKKWkpFj/Ig4PD1dERIROnz6tw4cP3/evZOBhtX//fuXIkcPmeypXrlwqXbq09u/fL0l699139f777yskJERDhgzRrl27rOu+9dZb+vLLL1W5cmX16dNHmzZtyvZ9AOwhLCxMERERslgs+vnnn9W8eXMFBwcrKipKkZGRKlCggEqWLHnPbYOCguTl5WV9nD9/fp0/fz67po4MIlbxQHh4eNg83rx5s1577TU1aNBAq1atUnR0tAYOHKibN29a1wkNDVViYqK2b9+uDRs22MTq3/3gAR5lHTp00JEjR9SqVSvt3r1bjz32mKZPny5Jql+/vo4fP67u3bvr9OnTevrpp9WrVy87zxh48MLDwxUVFaWdO3fK2dlZZcqUsfmd8VenjTk7O9s8dnBwUGpq6oOeMjKJWEWGFC9eXM7Oztq6dat12aVLl/72tiCbNm1SYGCgBg4cqMcee0wlS5bU8ePHbdbx9fVVxYoV9cEHH1h/8ISGhio6OlqrVq3ifFU8koKDg3X79m2b76m4uDgdOHBAZcuWtS4rXLiw3nzzTS1btkw9e/bUnDlzrM8FBASoTZs2WrhwoaZMmaLZs2dn6z4A9nD3vNXJkydbfz/cjdWIiAjeiXuEEKvIEE9PT7Vv3169e/fW+vXrtWfPHrVt21aOjn/9f6WSJUsqNjZWX375pWJiYjRt2jQtX748zXrh4eFatGiR9QePv7+/goODtXjxYmIVj6SSJUuqadOm6tixo/UoUcuWLVWwYEE1bdpUktStWzetXbtWR48e1fbt2/XTTz8pODhYkjR48GCtXLlShw8f1t69e7Vq1Srrc8CjzM/PTxUrVtSiRYusYRoaGqrt27fr4MGD/M54hBCryLDx48erVq1aaty4serUqaOaNWuqWrVqf7lNkyZN1L17d73zzjuqXLmyNm3aZL1LwB+FhYUpJSXF5i/i8PDwNMuAR8ncuXNVrVo1NWrUSNWrV5fFYtGaNWusb1WmpKSoc+fOCg4OVr169VSqVCl9+OGHkiQXFxf1799fFStWVGhoqJycnPTll1/ac3eAbPPn3xn+/v4qW7as8uXLl+ZaCjy8HCwWi8XekwAAAADuhSOrAAAAMBaxCgAAAGMRqwAAADAWsQoAAABjEasAAAAwFrEKAAAAYxGrAAAAMBaxCgAAAGMRqwBgmLZt26pZs2bWx+Hh4erWrVu2zyMiIkIODg66fPlytr82ANxFrAJAOrVt21YODg5ycHCQi4uLSpQooeHDh+v27dsP9HWXLVumESNGpGtdAhPAoyaHvScAAA+TevXqae7cuUpOTtaaNWvUuXNnOTs7q3///jbr3bx5Uy4uLlnymv7+/lkyDgA8jDiyCgAZ4Orqqnz58ikwMFBvvfWW6tSpo2+++cb61v3IkSNVoEABlS5dWpJ04sQJvfTSS/L19ZW/v7+aNm2qY8eOWcdLSUlRjx495Ovrq1y5cqlPnz6yWCw2r/nn0wCSk5PVt29fFS5cWK6uripRooQ++eQTHTt2TLVr15Yk+fn5ycHBQW3btpUkpaamavTo0SpatKjc3NxUqVIlff311zavs2bNGpUqVUpubm6qXbu2zTwBwF6IVQD4B9zc3HTz5k1J0o8//qgDBw7o+++/16pVq3Tr1i09++yz8vLy0s8//6yNGzfK09NT9erVs24zceJEzZs3T59++qmioqIUHx+v5cuX/+Vrtm7dWl988YWmTZum/fv3a9asWfL09FThwoW1dOlSSdKBAwd05swZTZ06VZI0evRoffbZZ5o5c6b27t2r7t27q2XLloqMjJR0J6qbN2+uxo0ba8eOHerQoYP69ev3oL5sAJBunAYAAJlgsVj0448/au3aterSpYsuXLggDw8Pffzxx9a3/xcuXKjU1FR9/PHHcnBwkCTNnTtXvr6+ioiIUN26dTVlyhT1799fzZs3lyTNnDlTa9euve/rHjx4UEuWLNH333+vOnXqSJKKFStmff7uKQN58uSRr6+vpDtHYkeNGqUffvhB1atXt24TFRWlWbNmKSwsTB999JGKFy+uiRMnSpJKly6t3bt3a+zYsVn4VQOAjCNWASADVq1aJU9PT926dUupqalq0aKFhg4dqs6dO6tChQo256nu3LlThw8flpeXl80YN27cUExMjBISEnTmzBk9+eST1udy5Mihxx57LM2pAHft2LFDTk5OCgsLS/ecDx8+rKSkJD3zzDM2y2/evKkqVapIkvbv328zD0nWsAUAeyJWASADateurY8++kguLi4qUKCAcuT4349RDw8Pm3WvXr2qatWqadGiRWnGCQgIyNTru7m5ZXibq1evSpJWr16tggUL2jzn6uqaqXkAQHYhVgEgAzw8PFSiRIl0rVu1alUtXrxYefLkkbe39z3XyZ8/v7Zu3arQ0FBJ0u3bt/Xbb7+patWq91y/QoUKSk1NVWRkpPU0gD+6e2Q3JSXFuqxs2bJydXVVbGzsfY/IBgcH65tvvrFZtmXLlr/fSQB4wLjACgAekNdee025c+dW06ZN9fPPP+vo0aOKiIjQu+++q5MnT0qSunbtqjFjxmjFihX6/fff9fbbb//lPVKDgoLUpk0bvf7661qxYoV1zCVLlkiSAgMD5eDgoFWrVunChQu6evWqvLy81KtXL3Xv3l3z589XTEyMtm/frunTp2v+/PmSpDfffFOHDh1S7969deDAAX3++eeaN2/eg/4SAcDfIlYB4AFxd3fXhg0bVKRIETVv3lzBwcFq3769bty4YT3S2rNnT7Vq1Upt2rRR9erV5eXlpeeee+4vx/3oo4/0wgsv6O2331aZMmXUsWNHXbt2TZJUsGBBDRs2TP369VPevHn1zjvvSJJGjBihQYMGafTo0QoODla9evW0evVqFS1aVJJUpEgRLV26VCtWrFClSpU0c+ZMjRo16gF+dQAgfRws9zuLHwAAALAzjqwCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBYxCoAAACMRawCAADAWMQqAAAAjEWsAgAAwFjEKgAAAIxFrAIAAMBY/weEUGe9VMnNVQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xticks(np.arange(3) + 0.5, ['draw', 'loss', 'win'])\n",
        "plt.yticks(np.arange(3) + 0.5, ['draw', 'loss', 'win'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfYjwrhaE6D2"
      },
      "source": [
        "# Final thoughts\n",
        "\n",
        "Now after training with a balanced dataset, we see that our balanced accuracy is around 80%, and it's clear that the model is fairly accurate at predicting wins and losses. However, the model is still challenged at predicting draws, with a tendency to classify draws as wins. Curiously, I wonder if it is possible to get a better accuracy over this data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rij3BMBiFp8r"
      },
      "source": [
        "# Just for fun\n",
        "\n",
        "Let's look at another dataset. The features of this dataset is the sequence of column choices in an incomplete game of connect 4, and this time the label is the 'scores' for each column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4Xly4pRKd1y"
      },
      "source": [
        "# Reconstructing gameboard from move sequence\n",
        "We would like to train using the gameboard as the features, so we will need to reconstruct the gameboards from the given move sequences in the new dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wi0HweOHVKK",
        "outputId": "9766f4b6-e04f-4fe4-b2db-ce1044f7cb33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "move_sequence -> board\n",
            "444 -> [[ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  1  0  0  0]\n",
            " [ 0  0  0 -1  0  0  0]\n",
            " [ 0  0  0  1  0  0  0]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def move_sequence_to_board_vector(sequence, rows=6, columns=7):\n",
        "    board = np.zeros((rows, columns), dtype=int)\n",
        "    player = 1\n",
        "    if pd.notna(sequence):\n",
        "        for move in str(sequence):\n",
        "            move = int(move) - 1\n",
        "            for row in range(rows - 1, -1, -1):\n",
        "                if board[row, move] == 0:\n",
        "                    board[row, move] = player\n",
        "                    break\n",
        "            player *= -1\n",
        "    return board\n",
        "\n",
        "print('move_sequence -> board')\n",
        "print(f'444 -> {move_sequence_to_board_vector(444)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVSXy6doq-bt"
      },
      "source": [
        "# Add some more features\n",
        "\n",
        "Since we just want a model that plays connect 4 really well, let's add some features to our data to help the model learn more about the game. Lets calculate and include the following features:\n",
        "\n",
        "- Number of open ended 3-in-a-rows for each player\n",
        "- Number of two-in-a-rows\n",
        "- number of pieces in center column\n",
        "- distance (in moves) to win/lose state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "JEyaXc-jsifV"
      },
      "outputs": [],
      "source": [
        "def count_open_ended_three_in_a_rows(board, player):\n",
        "    count = 0\n",
        "    for i in range(4):\n",
        "        for j in range(7):\n",
        "            if board[i, j] == player:\n",
        "                count += 1\n",
        "    return count\n",
        "\n",
        "def count_open_ended_two_in_a_rows(board, player):\n",
        "    count = 0\n",
        "    for i in range(5):\n",
        "        for j in range(7):\n",
        "            if board[i, j] == player:\n",
        "                count += 1\n",
        "    return count\n",
        "\n",
        "def count_pieces_in_center_column(board, player):\n",
        "    count = 0\n",
        "    for i in range(6):\n",
        "        if board[i, 3] == player:\n",
        "            count += 1\n",
        "    return count\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibif1RA3IwGM"
      },
      "source": [
        "# About the dataset\n",
        "We generated this dataset by using the following connect 4 solver: https://github.com/PascalPons/connect4. There are two datasets. One dataset is comprised of 1000 games where both players play with perfect strategy (moves selected by minimax algorithm). The other dataset is comprised of 1000 games where players make their moves randomly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "uC8dq3RGH0ZJ"
      },
      "outputs": [],
      "source": [
        "perfect_strat_data_path = 'perfect_strategy.csv'\n",
        "no_strat_data_path = 'no_strategy.csv'\n",
        "column_names = ['game_id', 'move_sequence'] + ['col_' + str(i) for i in range(1, 8)]\n",
        "perfect_strat_data = pd.read_csv(perfect_strat_data_path, header=None, names=column_names)\n",
        "no_strat_data = pd.read_csv(no_strat_data_path, header=None, names=column_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpYfp6loI26L"
      },
      "source": [
        "The move sequence should be a string, not a number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "wfgihtF3H2YY"
      },
      "outputs": [],
      "source": [
        "# lets change the dtype of the move_sequence column to str, and anything that is currently NaN will be empty str ''\n",
        "perfect_strat_data['move_sequence'] = perfect_strat_data['move_sequence'].astype(str)\n",
        "no_strat_data['move_sequence'] = no_strat_data['move_sequence'].astype(str)\n",
        "perfect_strat_data['move_sequence'] = perfect_strat_data['move_sequence'].replace('nan', '')\n",
        "no_strat_data['move_sequence'] = no_strat_data['move_sequence'].replace('nan', '')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVC6LEuNI5az"
      },
      "source": [
        "The data contains examples from two players in many games of connect 4. Let's train the model to be player 1, by using all the examples in which the sequence has an even length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "oHN1shVVH4mJ"
      },
      "outputs": [],
      "source": [
        "perfect_strat_data = perfect_strat_data[perfect_strat_data['move_sequence'].str.len() % 2 == 0]\n",
        "no_strat_data = no_strat_data[no_strat_data['move_sequence'].str.len() % 2 == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1UtUcx99H6vB",
        "outputId": "11b3c812-1cec-40e6-8ee9-f14992ba8317"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   game_id move_sequence  col_1  col_2  col_3  col_4  col_5  col_6  col_7\n",
              "0        0                   -2     -1      0      1      0     -1     -2\n",
              "2        0            44     -3     -3     -2      1     -2     -3     -3\n",
              "4        0          4444     -2     -2     -2      1     -2     -2     -2\n",
              "6        0        444443     -2     -3      1     -3     -3      1     -2\n",
              "8        0      44444367    -13    -13      1    -14    -15      1     -3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-60aa4d92-e03a-4c24-809e-0266e4456701\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>game_id</th>\n",
              "      <th>move_sequence</th>\n",
              "      <th>col_1</th>\n",
              "      <th>col_2</th>\n",
              "      <th>col_3</th>\n",
              "      <th>col_4</th>\n",
              "      <th>col_5</th>\n",
              "      <th>col_6</th>\n",
              "      <th>col_7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>-2</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>-3</td>\n",
              "      <td>-3</td>\n",
              "      <td>-2</td>\n",
              "      <td>1</td>\n",
              "      <td>-2</td>\n",
              "      <td>-3</td>\n",
              "      <td>-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4444</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "      <td>1</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>444443</td>\n",
              "      <td>-2</td>\n",
              "      <td>-3</td>\n",
              "      <td>1</td>\n",
              "      <td>-3</td>\n",
              "      <td>-3</td>\n",
              "      <td>1</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>44444367</td>\n",
              "      <td>-13</td>\n",
              "      <td>-13</td>\n",
              "      <td>1</td>\n",
              "      <td>-14</td>\n",
              "      <td>-15</td>\n",
              "      <td>1</td>\n",
              "      <td>-3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60aa4d92-e03a-4c24-809e-0266e4456701')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-60aa4d92-e03a-4c24-809e-0266e4456701 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-60aa4d92-e03a-4c24-809e-0266e4456701');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0b697a93-3137-4c0e-b26e-eda429fdb150\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b697a93-3137-4c0e-b26e-eda429fdb150')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0b697a93-3137-4c0e-b26e-eda429fdb150 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "perfect_strat_data",
              "summary": "{\n  \"name\": \"perfect_strat_data\",\n  \"rows\": 21000,\n  \"fields\": [\n    {\n      \"column\": \"game_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 288,\n        \"min\": 0,\n        \"max\": 999,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          521,\n          737,\n          740\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"move_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12449,\n        \"samples\": [\n          \"4444443265555111\",\n          \"4444422224637537557621333777132666\",\n          \"44444732222756677666254261\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 349,\n        \"min\": -1000,\n        \"max\": 1,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          -2,\n          -3,\n          -5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 447,\n        \"min\": -1000,\n        \"max\": 1,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          -1,\n          -12,\n          -9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 393,\n        \"min\": -1000,\n        \"max\": 1,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0,\n          -2,\n          -7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 481,\n        \"min\": -1000,\n        \"max\": 1,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          1,\n          -3,\n          -2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 388,\n        \"min\": -1000,\n        \"max\": 1,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0,\n          -2,\n          -1000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 444,\n        \"min\": -1000,\n        \"max\": 1,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          -1,\n          0,\n          -8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 337,\n        \"min\": -1000,\n        \"max\": 1,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          -2,\n          -3,\n          -1000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 142
        }
      ],
      "source": [
        "perfect_strat_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8dKNlMsAH8y7",
        "outputId": "3c7f7c46-68ee-4694-9c03-90d42d222b0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   game_id move_sequence  col_1  col_2  col_3  col_4  col_5  col_6  col_7\n",
              "0        0                   -2     -1      0      1      0     -1     -2\n",
              "2        0            27     -1      3      0      3      0     -2     -1\n",
              "4        0          2722     -3      0      2      3      0     -2      0\n",
              "6        0        272261     -2      0      0     -2      0     -2     -2\n",
              "8        0      27226144     -5     -5     -3     -2     -3     -4     -4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-138aebfc-249d-4334-89c2-1e4e73fab970\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>game_id</th>\n",
              "      <th>move_sequence</th>\n",
              "      <th>col_1</th>\n",
              "      <th>col_2</th>\n",
              "      <th>col_3</th>\n",
              "      <th>col_4</th>\n",
              "      <th>col_5</th>\n",
              "      <th>col_6</th>\n",
              "      <th>col_7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>-2</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>-1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>2722</td>\n",
              "      <td>-3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>272261</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>27226144</td>\n",
              "      <td>-5</td>\n",
              "      <td>-5</td>\n",
              "      <td>-3</td>\n",
              "      <td>-2</td>\n",
              "      <td>-3</td>\n",
              "      <td>-4</td>\n",
              "      <td>-4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-138aebfc-249d-4334-89c2-1e4e73fab970')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-138aebfc-249d-4334-89c2-1e4e73fab970 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-138aebfc-249d-4334-89c2-1e4e73fab970');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-14eb79e2-e9ab-4b6a-bb5d-774e7bbd16c1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-14eb79e2-e9ab-4b6a-bb5d-774e7bbd16c1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-14eb79e2-e9ab-4b6a-bb5d-774e7bbd16c1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "no_strat_data",
              "summary": "{\n  \"name\": \"no_strat_data\",\n  \"rows\": 10863,\n  \"fields\": [\n    {\n      \"column\": \"game_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 286,\n        \"min\": 0,\n        \"max\": 999,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          521,\n          737,\n          740\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"move_sequence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8729,\n        \"samples\": [\n          \"5143\",\n          \"5316534512526461\",\n          \"347253\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 179,\n        \"min\": -1000,\n        \"max\": 18,\n        \"num_unique_values\": 38,\n        \"samples\": [\n          6,\n          15,\n          -6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 207,\n        \"min\": -1000,\n        \"max\": 18,\n        \"num_unique_values\": 38,\n        \"samples\": [\n          7,\n          6,\n          -6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 181,\n        \"min\": -1000,\n        \"max\": 18,\n        \"num_unique_values\": 38,\n        \"samples\": [\n          7,\n          18,\n          15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 151,\n        \"min\": -1000,\n        \"max\": 18,\n        \"num_unique_values\": 38,\n        \"samples\": [\n          16,\n          -17,\n          -13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 165,\n        \"min\": -1000,\n        \"max\": 18,\n        \"num_unique_values\": 38,\n        \"samples\": [\n          17,\n          -18,\n          -12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 188,\n        \"min\": -1000,\n        \"max\": 18,\n        \"num_unique_values\": 38,\n        \"samples\": [\n          15,\n          17,\n          -11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"col_7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 183,\n        \"min\": -1000,\n        \"max\": 18,\n        \"num_unique_values\": 38,\n        \"samples\": [\n          16,\n          17,\n          -11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 143
        }
      ],
      "source": [
        "no_strat_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oV7CqGdjI9lj"
      },
      "source": [
        "# What do the column scores mean?\n",
        "The scores in columns 1-7 represent the winning piece, under the assumption that both sides will complete the game using perfect strategy. Assume that it is our turn to play. If a column has a score of *1*, we will win with our *last* piece if we play that column. If a column has a score of *-2* and we play that column, our opponent will win with their *second-to-last* piece, and so on. Thus, the optimal column would be the column with the most positive score.\n",
        "\n",
        "For the classifier, we will prepare a feature matrix composed of the states of the game board, reconstructed from the sequence of game moves. The labels will be the column index, {1-7}, of the column with the most positive score. The model will recieve a game board, and predict the best column to play next."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "Y2I1YQUpwrVO"
      },
      "outputs": [],
      "source": [
        "def get_features(sequence):\n",
        "    board = move_sequence_to_board_vector(sequence)\n",
        "    return np.array(list(board.flatten())\n",
        "    + [count_open_ended_three_in_a_rows(board, 1),\n",
        "       count_open_ended_two_in_a_rows(board, 1),\n",
        "       count_pieces_in_center_column(board, 1),\n",
        "       count_open_ended_three_in_a_rows(board, -1),\n",
        "       count_open_ended_two_in_a_rows(board, -1),\n",
        "       count_pieces_in_center_column(board, -1)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64HH7kmaSQ5j"
      },
      "source": [
        "# Accepting multiple answers\n",
        "\n",
        "Since there are times when multiple columns have the max score, so we need to think about that when we are evaluating the accuracy of our model. We will have a label matrix for training, and a label matrix for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dLM-Xt8H-ut",
        "outputId": "35b72392-1096-46d6-cd98-0340b7702d3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features\n",
            "[ 0 -1  1 -1  0 -1  0  0  1  1  1  0 -1  0  0  1 -1 -1  0  1  0  0 -1  1\n",
            "  1 -1 -1  0  0  1 -1 -1  1  1 -1 -1  1 -1  1  1 -1  1  8 11  3  9 12  3]\n",
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0 -1  0  0  0  0  0  0  0]\n",
            "\n",
            "Training Labels\n",
            "0\n",
            "1\n",
            "\n",
            "Testing Labels\n",
            "[0 0 0 1 0 0 0]\n",
            "[0 0 0 1 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def encode_single_best(scores):\n",
        "    return np.argmax(scores, axis=1)\n",
        "\n",
        "def encode_multi_correct(scores):\n",
        "    max_score = np.max(scores, axis=1, keepdims=True)\n",
        "    return (scores == max_score).astype(int)\n",
        "\n",
        "X_perfect = np.array([get_features(sequence) for sequence in perfect_strat_data['move_sequence']])\n",
        "X_no_strat = np.array([get_features(sequence) for sequence in no_strat_data['move_sequence']])\n",
        "\n",
        "y_perfect_single = encode_single_best(perfect_strat_data.iloc[:, 2:].values)\n",
        "y_no_strat_single = encode_single_best(no_strat_data.iloc[:, 2:9].values)\n",
        "\n",
        "y_perfect_multi = encode_multi_correct(perfect_strat_data.iloc[:, 2:9].values)\n",
        "y_no_strat_multi = encode_multi_correct(no_strat_data.iloc[:, 2:9].values)\n",
        "\n",
        "X_perfect_train, X_perfect_test, y_perfect_train, y_perfect_test = train_test_split(X_perfect, y_perfect_single, test_size=0.2, random_state=42)\n",
        "X_no_strat_train, X_no_strat_test, y_no_strat_train, y_no_strat_test = train_test_split(X_no_strat, y_no_strat_single, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Features\")\n",
        "print(X_perfect_train[0])\n",
        "print(X_no_strat_train[0])\n",
        "print()\n",
        "\n",
        "print(\"Training Labels\")\n",
        "print(y_perfect_train[0])\n",
        "print(y_no_strat_train[0])\n",
        "print()\n",
        "\n",
        "print(\"Testing Labels\")\n",
        "print(y_perfect_multi[0])\n",
        "print(y_no_strat_multi[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNfFB9fPJCEH"
      },
      "source": [
        "# Build the model\n",
        "\n",
        "Building a simple model with 42 inputs, and 7 outputs, each for a column of the game board."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrHHZs-7IMr6",
        "outputId": "22e1b0a6-6173-460b-f321-ece04bb69721"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_132 (Dense)           (None, 128)               6272      \n",
            "                                                                 \n",
            " dense_133 (Dense)           (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_134 (Dense)           (None, 7)                 903       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23687 (92.53 KB)\n",
            "Trainable params: 23687 (92.53 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_perfect_train.shape[1],)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(7, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmLxkOtEJH90"
      },
      "source": [
        "# Perfect strategy\n",
        "\n",
        "Let's see how the model does with the perfect strategy data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I37i9_J2IOwA",
        "outputId": "6e128848-943d-40ce-ae2b-9d070a0c4e0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "473/473 [==============================] - 2s 3ms/step - loss: 1.1898 - accuracy: 0.5880 - val_loss: 0.9726 - val_accuracy: 0.6583\n",
            "Epoch 2/10\n",
            "473/473 [==============================] - 1s 3ms/step - loss: 0.8826 - accuracy: 0.6899 - val_loss: 0.8769 - val_accuracy: 0.6863\n",
            "Epoch 3/10\n",
            "473/473 [==============================] - 1s 3ms/step - loss: 0.7716 - accuracy: 0.7315 - val_loss: 0.7480 - val_accuracy: 0.7417\n",
            "Epoch 4/10\n",
            "473/473 [==============================] - 1s 3ms/step - loss: 0.6918 - accuracy: 0.7606 - val_loss: 0.7162 - val_accuracy: 0.7488\n",
            "Epoch 5/10\n",
            "473/473 [==============================] - 1s 3ms/step - loss: 0.6337 - accuracy: 0.7840 - val_loss: 0.6716 - val_accuracy: 0.7810\n",
            "Epoch 6/10\n",
            "473/473 [==============================] - 1s 3ms/step - loss: 0.5727 - accuracy: 0.8086 - val_loss: 0.6326 - val_accuracy: 0.7887\n",
            "Epoch 7/10\n",
            "473/473 [==============================] - 1s 3ms/step - loss: 0.5238 - accuracy: 0.8235 - val_loss: 0.5883 - val_accuracy: 0.8125\n",
            "Epoch 8/10\n",
            "473/473 [==============================] - 1s 3ms/step - loss: 0.4812 - accuracy: 0.8381 - val_loss: 0.5644 - val_accuracy: 0.8131\n",
            "Epoch 9/10\n",
            "473/473 [==============================] - 1s 3ms/step - loss: 0.4508 - accuracy: 0.8494 - val_loss: 0.5318 - val_accuracy: 0.8238\n",
            "Epoch 10/10\n",
            "473/473 [==============================] - 1s 3ms/step - loss: 0.4259 - accuracy: 0.8559 - val_loss: 0.5375 - val_accuracy: 0.8149\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7aa4759676d0>"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ],
      "source": [
        "model.fit(X_perfect_train, y_perfect_train, epochs=10, batch_size=32, validation_split=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIIy1CcjTQMn",
        "outputId": "6d7cebf3-1445-41d9-8af3-5eb32009eed4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132/132 [==============================] - 0s 1ms/step\n",
            "Custom Test Accuracy: 0.8757142857142857\n"
          ]
        }
      ],
      "source": [
        "def custom_accuracy(y_true, y_pred_indices):\n",
        "    correct_count = 0\n",
        "    for i, pred_index in enumerate(y_pred_indices):\n",
        "        if y_true[i, pred_index] == 1:\n",
        "            correct_count += 1\n",
        "    return correct_count / len(y_pred_indices)\n",
        "\n",
        "y_pred_proba = model.predict(X_perfect_test)\n",
        "y_pred_indices = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "y_perfect_multi_test = train_test_split(y_perfect_multi, test_size=0.2, random_state=42)[1]\n",
        "print(\"Custom Test Accuracy:\", custom_accuracy(y_perfect_multi_test, y_pred_indices))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSN--WBDJMkr"
      },
      "source": [
        "# No strategy\n",
        "\n",
        "And now the no strategy data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9mFJQH8IQVq",
        "outputId": "148af8b7-1ce1-4863-9cea-d79f253482fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.7335 - accuracy: 0.3702 - val_loss: 1.4642 - val_accuracy: 0.4108\n",
            "Epoch 2/10\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3949 - accuracy: 0.4658 - val_loss: 1.3647 - val_accuracy: 0.4822\n",
            "Epoch 3/10\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2920 - accuracy: 0.5199 - val_loss: 1.2890 - val_accuracy: 0.5201\n",
            "Epoch 4/10\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2051 - accuracy: 0.5603 - val_loss: 1.2425 - val_accuracy: 0.5443\n",
            "Epoch 5/10\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1261 - accuracy: 0.5926 - val_loss: 1.1978 - val_accuracy: 0.5489\n",
            "Epoch 6/10\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0635 - accuracy: 0.6105 - val_loss: 1.1860 - val_accuracy: 0.5662\n",
            "Epoch 7/10\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0077 - accuracy: 0.6390 - val_loss: 1.1497 - val_accuracy: 0.5765\n",
            "Epoch 8/10\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9564 - accuracy: 0.6578 - val_loss: 1.1386 - val_accuracy: 0.5915\n",
            "Epoch 9/10\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.9041 - accuracy: 0.6780 - val_loss: 1.1132 - val_accuracy: 0.5926\n",
            "Epoch 10/10\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 0.8616 - accuracy: 0.6947 - val_loss: 1.1011 - val_accuracy: 0.6076\n",
            "68/68 [==============================] - 0s 1ms/step\n",
            "Custom Test Accuracy: 0.6741831569259089\n"
          ]
        }
      ],
      "source": [
        "model.fit(X_no_strat_train, y_no_strat_train, epochs=10, batch_size=32, validation_split=0.1)\n",
        "\n",
        "y_pred_proba = model.predict(X_no_strat_test)\n",
        "y_pred_indices = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "y_no_strat_multi_test = train_test_split(y_no_strat_multi, test_size=0.2, random_state=42)[1]\n",
        "print(\"Custom Test Accuracy:\", custom_accuracy(y_no_strat_multi_test, y_pred_indices))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g41zOZk3JP5U"
      },
      "source": [
        "# A mix of each\n",
        "\n",
        "Training over the datasets combined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "xbBcmp48ISDy"
      },
      "outputs": [],
      "source": [
        "X_combined_train = np.vstack((X_perfect_train, X_no_strat_train))\n",
        "y_combined_train = np.hstack((y_perfect_train, y_no_strat_train))\n",
        "\n",
        "X_combined_test = np.vstack((X_perfect_test, X_no_strat_test))\n",
        "y_combined_test = np.hstack((y_perfect_test, y_no_strat_test))\n",
        "\n",
        "y_combined_multi = np.vstack((y_perfect_multi, y_no_strat_multi))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dm0sRIcbITgJ",
        "outputId": "6f9cd0f8-58c8-48a8-e19d-b43d67bfb7eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "717/717 [==============================] - 2s 3ms/step - loss: 0.7276 - accuracy: 0.7481 - val_loss: 1.0270 - val_accuracy: 0.6238\n",
            "Epoch 2/10\n",
            "717/717 [==============================] - 2s 3ms/step - loss: 0.5869 - accuracy: 0.7966 - val_loss: 1.0288 - val_accuracy: 0.6293\n",
            "Epoch 3/10\n",
            "717/717 [==============================] - 2s 3ms/step - loss: 0.5382 - accuracy: 0.8150 - val_loss: 1.0355 - val_accuracy: 0.6273\n",
            "Epoch 4/10\n",
            "717/717 [==============================] - 2s 3ms/step - loss: 0.5025 - accuracy: 0.8282 - val_loss: 1.0454 - val_accuracy: 0.6285\n",
            "Epoch 5/10\n",
            "717/717 [==============================] - 2s 3ms/step - loss: 0.4728 - accuracy: 0.8370 - val_loss: 1.0669 - val_accuracy: 0.6242\n",
            "Epoch 6/10\n",
            "717/717 [==============================] - 2s 3ms/step - loss: 0.4514 - accuracy: 0.8443 - val_loss: 1.0673 - val_accuracy: 0.6191\n",
            "Epoch 7/10\n",
            "717/717 [==============================] - 2s 3ms/step - loss: 0.4263 - accuracy: 0.8536 - val_loss: 1.0689 - val_accuracy: 0.6352\n",
            "Epoch 8/10\n",
            "717/717 [==============================] - 2s 3ms/step - loss: 0.4089 - accuracy: 0.8575 - val_loss: 1.0736 - val_accuracy: 0.6281\n",
            "Epoch 9/10\n",
            "717/717 [==============================] - 2s 3ms/step - loss: 0.3880 - accuracy: 0.8650 - val_loss: 1.1421 - val_accuracy: 0.6210\n",
            "Epoch 10/10\n",
            "717/717 [==============================] - 2s 3ms/step - loss: 0.3706 - accuracy: 0.8738 - val_loss: 1.1224 - val_accuracy: 0.6250\n",
            "200/200 [==============================] - 0s 1ms/step\n",
            "Custom Test Accuracy: 0.2722422720853601\n"
          ]
        }
      ],
      "source": [
        "model.fit(X_combined_train, y_combined_train, epochs=10, batch_size=32, validation_split=0.1)\n",
        "\n",
        "y_pred_proba = model.predict(X_combined_test)\n",
        "y_pred_indices = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "y_combined_multi_test = train_test_split(y_combined_multi, test_size=0.2, random_state=42)[1]\n",
        "print(\"Custom Test Accuracy:\", custom_accuracy(y_combined_multi_test, y_pred_indices))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmbD3maoJSaB"
      },
      "source": [
        "We can see the model best learned the perfect strategy data, worst learned the random play data, and predictably performed somewhere in the middle on the combined data.\n",
        "\n",
        "Lets see if we can do even better on the perfect strategy data. Just for fun, let's add more layers and increase the epochs. We will add a checkpoint callback, which will save the best model in a keras file for us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqQSmQ3kIVuy",
        "outputId": "7c2ea53f-217b-4ade-808e-90451e39adef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_135 (Dense)           (None, 128)               6272      \n",
            "                                                                 \n",
            " dense_136 (Dense)           (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_137 (Dense)           (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_138 (Dense)           (None, 512)               131584    \n",
            "                                                                 \n",
            " dense_139 (Dense)           (None, 1024)              525312    \n",
            "                                                                 \n",
            " dense_140 (Dense)           (None, 2048)              2099200   \n",
            "                                                                 \n",
            " dense_141 (Dense)           (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dense_142 (Dense)           (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_143 (Dense)           (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_144 (Dense)           (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_145 (Dense)           (None, 7)                 903       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5649287 (21.55 MB)\n",
            "Trainable params: 5649287 (21.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(48,)),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1024, activation='relu'),\n",
        "    Dense(2048, activation='relu'),\n",
        "    Dense(1024, activation='relu'),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(7, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "S5I6-TzUIXob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffc35407-5efe-4d82-8518-36168db6729f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 1.3573 - accuracy: 0.4934\n",
            "Epoch 1: val_loss improved from inf to 1.22393, saving model to connect_4_board_classifier.keras\n",
            "237/237 [==============================] - 5s 7ms/step - loss: 1.3495 - accuracy: 0.4962 - val_loss: 1.2239 - val_accuracy: 0.5304\n",
            "Epoch 2/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 1.1164 - accuracy: 0.5907\n",
            "Epoch 2: val_loss improved from 1.22393 to 1.04885, saving model to connect_4_board_classifier.keras\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 1.1125 - accuracy: 0.5919 - val_loss: 1.0488 - val_accuracy: 0.6256\n",
            "Epoch 3/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.9824 - accuracy: 0.6513\n",
            "Epoch 3: val_loss did not improve from 1.04885\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.9791 - accuracy: 0.6521 - val_loss: 1.0709 - val_accuracy: 0.6536\n",
            "Epoch 4/100\n",
            "226/237 [===========================>..] - ETA: 0s - loss: 0.8633 - accuracy: 0.6941\n",
            "Epoch 4: val_loss improved from 1.04885 to 0.88759, saving model to connect_4_board_classifier.keras\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.8647 - accuracy: 0.6936 - val_loss: 0.8876 - val_accuracy: 0.6815\n",
            "Epoch 5/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.7765 - accuracy: 0.7255\n",
            "Epoch 5: val_loss improved from 0.88759 to 0.82273, saving model to connect_4_board_classifier.keras\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.7725 - accuracy: 0.7274 - val_loss: 0.8227 - val_accuracy: 0.7214\n",
            "Epoch 6/100\n",
            "227/237 [===========================>..] - ETA: 0s - loss: 0.7363 - accuracy: 0.7425\n",
            "Epoch 6: val_loss improved from 0.82273 to 0.72715, saving model to connect_4_board_classifier.keras\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.7354 - accuracy: 0.7432 - val_loss: 0.7271 - val_accuracy: 0.7506\n",
            "Epoch 7/100\n",
            "237/237 [==============================] - ETA: 0s - loss: 0.6882 - accuracy: 0.7603\n",
            "Epoch 7: val_loss improved from 0.72715 to 0.70284, saving model to connect_4_board_classifier.keras\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.6882 - accuracy: 0.7603 - val_loss: 0.7028 - val_accuracy: 0.7607\n",
            "Epoch 8/100\n",
            "232/237 [============================>.] - ETA: 0s - loss: 0.6462 - accuracy: 0.7775\n",
            "Epoch 8: val_loss improved from 0.70284 to 0.67927, saving model to connect_4_board_classifier.keras\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.6478 - accuracy: 0.7769 - val_loss: 0.6793 - val_accuracy: 0.7726\n",
            "Epoch 9/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.5994 - accuracy: 0.7974\n",
            "Epoch 9: val_loss improved from 0.67927 to 0.62504, saving model to connect_4_board_classifier.keras\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.5991 - accuracy: 0.7975 - val_loss: 0.6250 - val_accuracy: 0.7911\n",
            "Epoch 10/100\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.8081 - accuracy: 0.7440\n",
            "Epoch 10: val_loss did not improve from 0.62504\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.8063 - accuracy: 0.7438 - val_loss: 0.7986 - val_accuracy: 0.7274\n",
            "Epoch 11/100\n",
            "237/237 [==============================] - ETA: 0s - loss: 0.6532 - accuracy: 0.7790\n",
            "Epoch 11: val_loss did not improve from 0.62504\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.6532 - accuracy: 0.7790 - val_loss: 0.6464 - val_accuracy: 0.7899\n",
            "Epoch 12/100\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.5576 - accuracy: 0.8148\n",
            "Epoch 12: val_loss did not improve from 0.62504\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.5553 - accuracy: 0.8146 - val_loss: 0.6333 - val_accuracy: 0.7881\n",
            "Epoch 13/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.5125 - accuracy: 0.8278\n",
            "Epoch 13: val_loss improved from 0.62504 to 0.58652, saving model to connect_4_board_classifier.keras\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.5126 - accuracy: 0.8279 - val_loss: 0.5865 - val_accuracy: 0.8125\n",
            "Epoch 14/100\n",
            "226/237 [===========================>..] - ETA: 0s - loss: 0.4791 - accuracy: 0.8432\n",
            "Epoch 14: val_loss improved from 0.58652 to 0.56208, saving model to connect_4_board_classifier.keras\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.4766 - accuracy: 0.8444 - val_loss: 0.5621 - val_accuracy: 0.8280\n",
            "Epoch 15/100\n",
            "227/237 [===========================>..] - ETA: 0s - loss: 0.4527 - accuracy: 0.8516\n",
            "Epoch 15: val_loss improved from 0.56208 to 0.55134, saving model to connect_4_board_classifier.keras\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.4519 - accuracy: 0.8521 - val_loss: 0.5513 - val_accuracy: 0.8155\n",
            "Epoch 16/100\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.4148 - accuracy: 0.8620\n",
            "Epoch 16: val_loss improved from 0.55134 to 0.54771, saving model to connect_4_board_classifier.keras\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.4148 - accuracy: 0.8626 - val_loss: 0.5477 - val_accuracy: 0.8226\n",
            "Epoch 17/100\n",
            "227/237 [===========================>..] - ETA: 0s - loss: 0.3998 - accuracy: 0.8667\n",
            "Epoch 17: val_loss did not improve from 0.54771\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.4012 - accuracy: 0.8667 - val_loss: 0.6012 - val_accuracy: 0.8190\n",
            "Epoch 18/100\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.3839 - accuracy: 0.8730\n",
            "Epoch 18: val_loss improved from 0.54771 to 0.52424, saving model to connect_4_board_classifier.keras\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.3826 - accuracy: 0.8733 - val_loss: 0.5242 - val_accuracy: 0.8399\n",
            "Epoch 19/100\n",
            "227/237 [===========================>..] - ETA: 0s - loss: 0.3710 - accuracy: 0.8775\n",
            "Epoch 19: val_loss improved from 0.52424 to 0.52101, saving model to connect_4_board_classifier.keras\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.3723 - accuracy: 0.8770 - val_loss: 0.5210 - val_accuracy: 0.8393\n",
            "Epoch 20/100\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.3510 - accuracy: 0.8845\n",
            "Epoch 20: val_loss did not improve from 0.52101\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.3514 - accuracy: 0.8841 - val_loss: 0.5236 - val_accuracy: 0.8369\n",
            "Epoch 21/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.3402 - accuracy: 0.8887\n",
            "Epoch 21: val_loss did not improve from 0.52101\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.3409 - accuracy: 0.8877 - val_loss: 0.5445 - val_accuracy: 0.8381\n",
            "Epoch 22/100\n",
            "226/237 [===========================>..] - ETA: 0s - loss: 0.3256 - accuracy: 0.8924\n",
            "Epoch 22: val_loss did not improve from 0.52101\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.3271 - accuracy: 0.8917 - val_loss: 0.5557 - val_accuracy: 0.8387\n",
            "Epoch 23/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.3143 - accuracy: 0.8991\n",
            "Epoch 23: val_loss did not improve from 0.52101\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.3164 - accuracy: 0.8985 - val_loss: 0.5283 - val_accuracy: 0.8393\n",
            "Epoch 24/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.3023 - accuracy: 0.8994\n",
            "Epoch 24: val_loss did not improve from 0.52101\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.3036 - accuracy: 0.8995 - val_loss: 0.5343 - val_accuracy: 0.8339\n",
            "Epoch 25/100\n",
            "233/237 [============================>.] - ETA: 0s - loss: 0.2759 - accuracy: 0.9054\n",
            "Epoch 25: val_loss did not improve from 0.52101\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.2757 - accuracy: 0.9053 - val_loss: 0.5873 - val_accuracy: 0.8387\n",
            "Epoch 26/100\n",
            "232/237 [============================>.] - ETA: 0s - loss: 0.5791 - accuracy: 0.8328\n",
            "Epoch 26: val_loss did not improve from 0.52101\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.5770 - accuracy: 0.8330 - val_loss: 0.6505 - val_accuracy: 0.7952\n",
            "Epoch 27/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.3952 - accuracy: 0.8695\n",
            "Epoch 27: val_loss improved from 0.52101 to 0.50030, saving model to connect_4_board_classifier.keras\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.3940 - accuracy: 0.8702 - val_loss: 0.5003 - val_accuracy: 0.8387\n",
            "Epoch 28/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.2970 - accuracy: 0.9038\n",
            "Epoch 28: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.2955 - accuracy: 0.9044 - val_loss: 0.5134 - val_accuracy: 0.8595\n",
            "Epoch 29/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.2596 - accuracy: 0.9151\n",
            "Epoch 29: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.2600 - accuracy: 0.9148 - val_loss: 0.5812 - val_accuracy: 0.8387\n",
            "Epoch 30/100\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.2361 - accuracy: 0.9211\n",
            "Epoch 30: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.2369 - accuracy: 0.9212 - val_loss: 0.5211 - val_accuracy: 0.8429\n",
            "Epoch 31/100\n",
            "227/237 [===========================>..] - ETA: 0s - loss: 0.2379 - accuracy: 0.9214\n",
            "Epoch 31: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.2381 - accuracy: 0.9210 - val_loss: 0.5596 - val_accuracy: 0.8476\n",
            "Epoch 32/100\n",
            "227/237 [===========================>..] - ETA: 0s - loss: 0.2204 - accuracy: 0.9277\n",
            "Epoch 32: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.2229 - accuracy: 0.9275 - val_loss: 0.5671 - val_accuracy: 0.8357\n",
            "Epoch 33/100\n",
            "227/237 [===========================>..] - ETA: 0s - loss: 0.2090 - accuracy: 0.9307\n",
            "Epoch 33: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.2080 - accuracy: 0.9312 - val_loss: 0.5947 - val_accuracy: 0.8470\n",
            "Epoch 34/100\n",
            "237/237 [==============================] - ETA: 0s - loss: 0.1925 - accuracy: 0.9365\n",
            "Epoch 34: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.1925 - accuracy: 0.9365 - val_loss: 0.6452 - val_accuracy: 0.8554\n",
            "Epoch 35/100\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.2074 - accuracy: 0.9325\n",
            "Epoch 35: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.2082 - accuracy: 0.9324 - val_loss: 0.6471 - val_accuracy: 0.8411\n",
            "Epoch 36/100\n",
            "233/237 [============================>.] - ETA: 0s - loss: 0.2063 - accuracy: 0.9332\n",
            "Epoch 36: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.2051 - accuracy: 0.9337 - val_loss: 0.6304 - val_accuracy: 0.8506\n",
            "Epoch 37/100\n",
            "227/237 [===========================>..] - ETA: 0s - loss: 0.2103 - accuracy: 0.9315\n",
            "Epoch 37: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.2086 - accuracy: 0.9322 - val_loss: 0.6136 - val_accuracy: 0.8571\n",
            "Epoch 38/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.1861 - accuracy: 0.9404\n",
            "Epoch 38: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.1879 - accuracy: 0.9397 - val_loss: 0.5577 - val_accuracy: 0.8548\n",
            "Epoch 39/100\n",
            "226/237 [===========================>..] - ETA: 0s - loss: 0.1561 - accuracy: 0.9471\n",
            "Epoch 39: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.1568 - accuracy: 0.9468 - val_loss: 0.6144 - val_accuracy: 0.8542\n",
            "Epoch 40/100\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.1696 - accuracy: 0.9458\n",
            "Epoch 40: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.1709 - accuracy: 0.9450 - val_loss: 0.5995 - val_accuracy: 0.8440\n",
            "Epoch 41/100\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.1608 - accuracy: 0.9483\n",
            "Epoch 41: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.1616 - accuracy: 0.9477 - val_loss: 0.6319 - val_accuracy: 0.8530\n",
            "Epoch 42/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.1446 - accuracy: 0.9529\n",
            "Epoch 42: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.1447 - accuracy: 0.9528 - val_loss: 0.6067 - val_accuracy: 0.8637\n",
            "Epoch 43/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.1486 - accuracy: 0.9507\n",
            "Epoch 43: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.1487 - accuracy: 0.9510 - val_loss: 0.5990 - val_accuracy: 0.8554\n",
            "Epoch 44/100\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.1423 - accuracy: 0.9552\n",
            "Epoch 44: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.1424 - accuracy: 0.9552 - val_loss: 0.7418 - val_accuracy: 0.8583\n",
            "Epoch 45/100\n",
            "235/237 [============================>.] - ETA: 0s - loss: 0.1327 - accuracy: 0.9576\n",
            "Epoch 45: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.1324 - accuracy: 0.9577 - val_loss: 0.6983 - val_accuracy: 0.8488\n",
            "Epoch 46/100\n",
            "234/237 [============================>.] - ETA: 0s - loss: 0.1292 - accuracy: 0.9587\n",
            "Epoch 46: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.1308 - accuracy: 0.9581 - val_loss: 0.6285 - val_accuracy: 0.8554\n",
            "Epoch 47/100\n",
            "227/237 [===========================>..] - ETA: 0s - loss: 0.1298 - accuracy: 0.9572\n",
            "Epoch 47: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.1299 - accuracy: 0.9575 - val_loss: 0.6837 - val_accuracy: 0.8583\n",
            "Epoch 48/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.1124 - accuracy: 0.9627\n",
            "Epoch 48: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.1127 - accuracy: 0.9632 - val_loss: 0.7043 - val_accuracy: 0.8464\n",
            "Epoch 49/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.1200 - accuracy: 0.9595\n",
            "Epoch 49: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.1231 - accuracy: 0.9587 - val_loss: 0.5822 - val_accuracy: 0.8429\n",
            "Epoch 50/100\n",
            "226/237 [===========================>..] - ETA: 0s - loss: 0.1307 - accuracy: 0.9573\n",
            "Epoch 50: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.1314 - accuracy: 0.9571 - val_loss: 0.6793 - val_accuracy: 0.8589\n",
            "Epoch 51/100\n",
            "227/237 [===========================>..] - ETA: 0s - loss: 0.1207 - accuracy: 0.9604\n",
            "Epoch 51: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.1203 - accuracy: 0.9606 - val_loss: 0.7254 - val_accuracy: 0.8554\n",
            "Epoch 52/100\n",
            "227/237 [===========================>..] - ETA: 0s - loss: 0.1198 - accuracy: 0.9612\n",
            "Epoch 52: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.1209 - accuracy: 0.9610 - val_loss: 0.6676 - val_accuracy: 0.8601\n",
            "Epoch 53/100\n",
            "226/237 [===========================>..] - ETA: 0s - loss: 0.1073 - accuracy: 0.9652\n",
            "Epoch 53: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.1072 - accuracy: 0.9651 - val_loss: 0.6995 - val_accuracy: 0.8583\n",
            "Epoch 54/100\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.1006 - accuracy: 0.9664\n",
            "Epoch 54: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.1021 - accuracy: 0.9657 - val_loss: 0.7718 - val_accuracy: 0.8530\n",
            "Epoch 55/100\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.1153 - accuracy: 0.9625\n",
            "Epoch 55: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.1163 - accuracy: 0.9626 - val_loss: 0.8560 - val_accuracy: 0.8542\n",
            "Epoch 56/100\n",
            "236/237 [============================>.] - ETA: 0s - loss: 0.1127 - accuracy: 0.9640\n",
            "Epoch 56: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.1126 - accuracy: 0.9640 - val_loss: 0.7912 - val_accuracy: 0.8554\n",
            "Epoch 57/100\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.0977 - accuracy: 0.9689\n",
            "Epoch 57: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0985 - accuracy: 0.9687 - val_loss: 0.6847 - val_accuracy: 0.8470\n",
            "Epoch 58/100\n",
            "226/237 [===========================>..] - ETA: 0s - loss: 0.1050 - accuracy: 0.9688\n",
            "Epoch 58: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.1053 - accuracy: 0.9686 - val_loss: 0.7389 - val_accuracy: 0.8470\n",
            "Epoch 59/100\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.1243 - accuracy: 0.9600\n",
            "Epoch 59: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.1230 - accuracy: 0.9605 - val_loss: 0.7139 - val_accuracy: 0.8542\n",
            "Epoch 60/100\n",
            "226/237 [===========================>..] - ETA: 0s - loss: 0.1000 - accuracy: 0.9700\n",
            "Epoch 60: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0999 - accuracy: 0.9700 - val_loss: 0.6723 - val_accuracy: 0.8583\n",
            "Epoch 61/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0890 - accuracy: 0.9737\n",
            "Epoch 61: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0899 - accuracy: 0.9733 - val_loss: 0.7149 - val_accuracy: 0.8702\n",
            "Epoch 62/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.1079 - accuracy: 0.9667\n",
            "Epoch 62: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.1084 - accuracy: 0.9663 - val_loss: 0.6656 - val_accuracy: 0.8560\n",
            "Epoch 63/100\n",
            "227/237 [===========================>..] - ETA: 0s - loss: 0.1012 - accuracy: 0.9694\n",
            "Epoch 63: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.1026 - accuracy: 0.9689 - val_loss: 0.7198 - val_accuracy: 0.8530\n",
            "Epoch 64/100\n",
            "226/237 [===========================>..] - ETA: 0s - loss: 0.1098 - accuracy: 0.9652\n",
            "Epoch 64: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.1106 - accuracy: 0.9648 - val_loss: 0.6643 - val_accuracy: 0.8595\n",
            "Epoch 65/100\n",
            "235/237 [============================>.] - ETA: 0s - loss: 0.0752 - accuracy: 0.9761\n",
            "Epoch 65: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0752 - accuracy: 0.9761 - val_loss: 0.7601 - val_accuracy: 0.8607\n",
            "Epoch 66/100\n",
            "236/237 [============================>.] - ETA: 0s - loss: 0.0802 - accuracy: 0.9742\n",
            "Epoch 66: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0802 - accuracy: 0.9742 - val_loss: 0.8390 - val_accuracy: 0.8554\n",
            "Epoch 67/100\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.0731 - accuracy: 0.9773\n",
            "Epoch 67: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0743 - accuracy: 0.9772 - val_loss: 0.9037 - val_accuracy: 0.8554\n",
            "Epoch 68/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0674 - accuracy: 0.9784\n",
            "Epoch 68: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0685 - accuracy: 0.9782 - val_loss: 0.7979 - val_accuracy: 0.8488\n",
            "Epoch 69/100\n",
            "227/237 [===========================>..] - ETA: 0s - loss: 0.0810 - accuracy: 0.9752\n",
            "Epoch 69: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0813 - accuracy: 0.9751 - val_loss: 0.7262 - val_accuracy: 0.8577\n",
            "Epoch 70/100\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.0949 - accuracy: 0.9708\n",
            "Epoch 70: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0939 - accuracy: 0.9710 - val_loss: 0.8713 - val_accuracy: 0.8530\n",
            "Epoch 71/100\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.0811 - accuracy: 0.9751\n",
            "Epoch 71: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0832 - accuracy: 0.9743 - val_loss: 0.7061 - val_accuracy: 0.8619\n",
            "Epoch 72/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0720 - accuracy: 0.9783\n",
            "Epoch 72: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0734 - accuracy: 0.9777 - val_loss: 0.7840 - val_accuracy: 0.8583\n",
            "Epoch 73/100\n",
            "227/237 [===========================>..] - ETA: 0s - loss: 0.0779 - accuracy: 0.9776\n",
            "Epoch 73: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0778 - accuracy: 0.9776 - val_loss: 0.7554 - val_accuracy: 0.8613\n",
            "Epoch 74/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0598 - accuracy: 0.9805\n",
            "Epoch 74: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0609 - accuracy: 0.9802 - val_loss: 0.8097 - val_accuracy: 0.8577\n",
            "Epoch 75/100\n",
            "237/237 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 0.9790\n",
            "Epoch 75: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0627 - accuracy: 0.9790 - val_loss: 0.9768 - val_accuracy: 0.8530\n",
            "Epoch 76/100\n",
            "227/237 [===========================>..] - ETA: 0s - loss: 0.0646 - accuracy: 0.9797\n",
            "Epoch 76: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0649 - accuracy: 0.9796 - val_loss: 0.7784 - val_accuracy: 0.8637\n",
            "Epoch 77/100\n",
            "227/237 [===========================>..] - ETA: 0s - loss: 0.0734 - accuracy: 0.9796\n",
            "Epoch 77: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0727 - accuracy: 0.9797 - val_loss: 0.8983 - val_accuracy: 0.8488\n",
            "Epoch 78/100\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.0664 - accuracy: 0.9805\n",
            "Epoch 78: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0660 - accuracy: 0.9805 - val_loss: 0.8817 - val_accuracy: 0.8536\n",
            "Epoch 79/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0914 - accuracy: 0.9727\n",
            "Epoch 79: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0899 - accuracy: 0.9729 - val_loss: 0.9853 - val_accuracy: 0.8554\n",
            "Epoch 80/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0647 - accuracy: 0.9813\n",
            "Epoch 80: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0766 - accuracy: 0.9802 - val_loss: 1.1448 - val_accuracy: 0.8131\n",
            "Epoch 81/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0915 - accuracy: 0.9735\n",
            "Epoch 81: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0907 - accuracy: 0.9738 - val_loss: 0.8575 - val_accuracy: 0.8583\n",
            "Epoch 82/100\n",
            "237/237 [==============================] - ETA: 0s - loss: 0.0641 - accuracy: 0.9808\n",
            "Epoch 82: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0641 - accuracy: 0.9808 - val_loss: 0.7764 - val_accuracy: 0.8518\n",
            "Epoch 83/100\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.0667 - accuracy: 0.9794\n",
            "Epoch 83: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0702 - accuracy: 0.9786 - val_loss: 0.9290 - val_accuracy: 0.8482\n",
            "Epoch 84/100\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.0890 - accuracy: 0.9727\n",
            "Epoch 84: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0872 - accuracy: 0.9733 - val_loss: 0.8557 - val_accuracy: 0.8548\n",
            "Epoch 85/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0587 - accuracy: 0.9828\n",
            "Epoch 85: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0585 - accuracy: 0.9827 - val_loss: 0.8346 - val_accuracy: 0.8571\n",
            "Epoch 86/100\n",
            "237/237 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 0.9821\n",
            "Epoch 86: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0603 - accuracy: 0.9821 - val_loss: 0.7556 - val_accuracy: 0.8470\n",
            "Epoch 87/100\n",
            "237/237 [==============================] - ETA: 0s - loss: 0.0522 - accuracy: 0.9847\n",
            "Epoch 87: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0522 - accuracy: 0.9847 - val_loss: 0.8598 - val_accuracy: 0.8577\n",
            "Epoch 88/100\n",
            "227/237 [===========================>..] - ETA: 0s - loss: 0.0741 - accuracy: 0.9787\n",
            "Epoch 88: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0726 - accuracy: 0.9790 - val_loss: 0.7976 - val_accuracy: 0.8577\n",
            "Epoch 89/100\n",
            "227/237 [===========================>..] - ETA: 0s - loss: 0.0573 - accuracy: 0.9834\n",
            "Epoch 89: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0563 - accuracy: 0.9836 - val_loss: 0.9091 - val_accuracy: 0.8595\n",
            "Epoch 90/100\n",
            "227/237 [===========================>..] - ETA: 0s - loss: 0.0502 - accuracy: 0.9848\n",
            "Epoch 90: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0509 - accuracy: 0.9845 - val_loss: 0.7729 - val_accuracy: 0.8536\n",
            "Epoch 91/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0623 - accuracy: 0.9825\n",
            "Epoch 91: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0616 - accuracy: 0.9827 - val_loss: 0.9253 - val_accuracy: 0.8601\n",
            "Epoch 92/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0850 - accuracy: 0.9765\n",
            "Epoch 92: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0841 - accuracy: 0.9768 - val_loss: 0.7693 - val_accuracy: 0.8655\n",
            "Epoch 93/100\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.0556 - accuracy: 0.9848\n",
            "Epoch 93: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0552 - accuracy: 0.9847 - val_loss: 0.8110 - val_accuracy: 0.8595\n",
            "Epoch 94/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0554 - accuracy: 0.9851\n",
            "Epoch 94: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0567 - accuracy: 0.9846 - val_loss: 0.8212 - val_accuracy: 0.8607\n",
            "Epoch 95/100\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.0686 - accuracy: 0.9810\n",
            "Epoch 95: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0677 - accuracy: 0.9813 - val_loss: 0.8427 - val_accuracy: 0.8464\n",
            "Epoch 96/100\n",
            "226/237 [===========================>..] - ETA: 0s - loss: 0.0452 - accuracy: 0.9858\n",
            "Epoch 96: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0465 - accuracy: 0.9857 - val_loss: 0.8770 - val_accuracy: 0.8524\n",
            "Epoch 97/100\n",
            "236/237 [============================>.] - ETA: 0s - loss: 0.0524 - accuracy: 0.9850\n",
            "Epoch 97: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0524 - accuracy: 0.9850 - val_loss: 0.9938 - val_accuracy: 0.8506\n",
            "Epoch 98/100\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.0520 - accuracy: 0.9855\n",
            "Epoch 98: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0528 - accuracy: 0.9852 - val_loss: 0.9398 - val_accuracy: 0.8595\n",
            "Epoch 99/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0480 - accuracy: 0.9860\n",
            "Epoch 99: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0489 - accuracy: 0.9858 - val_loss: 0.8368 - val_accuracy: 0.8589\n",
            "Epoch 100/100\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0517 - accuracy: 0.9849\n",
            "Epoch 100: val_loss did not improve from 0.50030\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0544 - accuracy: 0.9849 - val_loss: 0.7988 - val_accuracy: 0.8524\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "Custom Test Accuracy: 0.8985714285714286\n"
          ]
        }
      ],
      "source": [
        "checkpoint_path = 'connect_4_board_classifier.keras'\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
        "\n",
        "model.fit(X_perfect_train, y_perfect_train, epochs=100, batch_size=64,\n",
        "          validation_split=0.1, callbacks=[checkpoint])\n",
        "\n",
        "y_pred_proba = model.predict(X_perfect_test)\n",
        "y_pred_indices = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "y_perfect_multi_test = train_test_split(y_perfect_multi, test_size=0.2, random_state=42)[1]\n",
        "print(\"Custom Test Accuracy:\", custom_accuracy(y_perfect_multi_test, y_pred_indices))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "zFCPe5D8IaD3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "6cd5d353-ddee-42ad-cab2-ca49eae2e37b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132/132 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def multi_label_confusion_matrix(y_true_multi, y_pred_classes, num_classes):\n",
        "    cm = np.zeros((num_classes, num_classes), dtype=int)\n",
        "    for true, pred in zip(y_true_multi, y_pred_classes):\n",
        "        true_indices = np.where(true == 1)[0]\n",
        "        true_index = np.argmax(true)\n",
        "        if pred in true_indices:\n",
        "            true_index = pred\n",
        "        cm[true_index, pred] += 1\n",
        "    return cm\n",
        "\n",
        "y_pred = model.predict(X_perfect_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "num_classes = y_perfect_multi_test.shape[1]\n",
        "\n",
        "cm = multi_label_confusion_matrix(y_perfect_multi_test, y_pred_classes, num_classes)\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Custom Accuracy Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmdMqT92JXiZ"
      },
      "source": [
        "# Can it play?\n",
        "\n",
        "As one might imagine, using this model to play an entire game is as straight-forward as predicting each move until the game is complete. Putting our model up against something that uses minimax or Monte Carlo tree search (like the program used to generate this last dataset) would be pointless because we know our model stands no chance at all. However, how would it perform against a more imperfect opponent, like a human?\n",
        "\n",
        "## Not really\n",
        "\n",
        "After playing just a few games, one quickly realizes that the model lacks the ability to recognize critical moves, where a move leads to a win or a loss. The model is not trained to make a winning move, just a pretty good move. So let's try one more thing."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional NN"
      ],
      "metadata": {
        "id": "hut6kR8fYbYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def encode_single_best(scores):\n",
        "    return np.argmax(scores, axis=1)\n",
        "\n",
        "def encode_multi_correct(scores):\n",
        "    max_score = np.max(scores, axis=1, keepdims=True)\n",
        "    return (scores == max_score).astype(int)\n",
        "\n",
        "X_perfect = np.array([move_sequence_to_board_vector(sequence) for sequence in perfect_strat_data['move_sequence']])\n",
        "y_perfect_single = encode_single_best(perfect_strat_data.iloc[:, 2:].values)\n",
        "y_perfect_multi = encode_multi_correct(perfect_strat_data.iloc[:, 2:9].values)\n",
        "\n",
        "X_perfect_train, X_perfect_test, y_perfect_train, y_perfect_test = train_test_split(X_perfect, y_perfect_single, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Features\")\n",
        "print(X_perfect_train[0])\n",
        "print()\n",
        "\n",
        "print(\"Training Labels\")\n",
        "print(y_perfect_train[0])\n",
        "print()\n",
        "\n",
        "print(\"Testing Labels\")\n",
        "print(y_perfect_multi[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZp0UMUJZ6O2",
        "outputId": "1238aa97-735d-4c0e-809c-7e3fedcc7190"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features\n",
            "[[ 0 -1  1 -1  0 -1  0]\n",
            " [ 0  1  1  1  0 -1  0]\n",
            " [ 0  1 -1 -1  0  1  0]\n",
            " [ 0 -1  1  1 -1 -1  0]\n",
            " [ 0  1 -1 -1  1  1 -1]\n",
            " [-1  1 -1  1  1 -1  1]]\n",
            "\n",
            "Training Labels\n",
            "0\n",
            "\n",
            "Testing Labels\n",
            "[0 0 0 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(6, 7, 1)),\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1024, activation='relu'),\n",
        "    Dense(2048, activation='relu'),\n",
        "    Dense(1024, activation='relu'),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(7, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTYk8IMCcrwz",
        "outputId": "30534575-e58d-4498-f0d9-8d4fafab2086"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_20 (Conv2D)          (None, 6, 7, 32)          320       \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 6, 7, 64)          18496     \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 6, 7, 128)         73856     \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 5376)              0         \n",
            "                                                                 \n",
            " dense_192 (Dense)           (None, 128)               688256    \n",
            "                                                                 \n",
            " dense_193 (Dense)           (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_194 (Dense)           (None, 512)               131584    \n",
            "                                                                 \n",
            " dense_195 (Dense)           (None, 1024)              525312    \n",
            "                                                                 \n",
            " dense_196 (Dense)           (None, 2048)              2099200   \n",
            "                                                                 \n",
            " dense_197 (Dense)           (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dense_198 (Dense)           (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_199 (Dense)           (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_200 (Dense)           (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_201 (Dense)           (None, 7)                 903       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6358151 (24.25 MB)\n",
            "Trainable params: 6358151 (24.25 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = 'connect_4_board_classifier.keras'\n",
        "checkpoint = ModelCheckpoint(checkpoint_path, save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
        "\n",
        "model.fit(X_perfect_train, y_perfect_train, epochs=200, batch_size=64,\n",
        "          validation_split=0.1, callbacks=[checkpoint])\n",
        "\n",
        "y_pred_proba = model.predict(X_perfect_test)\n",
        "y_pred_indices = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "y_perfect_multi_test = train_test_split(y_perfect_multi, test_size=0.2, random_state=42)[1]\n",
        "print(\"Custom Test Accuracy:\", custom_accuracy(y_perfect_multi_test, y_pred_indices))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xco-VMMRem7M",
        "outputId": "92f2a60d-9437-4e71-b25e-6427696b88ba"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "237/237 [==============================] - ETA: 0s - loss: 1.4636 - accuracy: 0.4464\n",
            "Epoch 1: val_loss improved from inf to 1.37744, saving model to connect_4_board_classifier.keras\n",
            "237/237 [==============================] - 5s 9ms/step - loss: 1.4636 - accuracy: 0.4464 - val_loss: 1.3774 - val_accuracy: 0.4554\n",
            "Epoch 2/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 1.1992 - accuracy: 0.5464\n",
            "Epoch 2: val_loss improved from 1.37744 to 1.08313, saving model to connect_4_board_classifier.keras\n",
            "237/237 [==============================] - 2s 7ms/step - loss: 1.1947 - accuracy: 0.5490 - val_loss: 1.0831 - val_accuracy: 0.6095\n",
            "Epoch 3/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.9867 - accuracy: 0.6320\n",
            "Epoch 3: val_loss improved from 1.08313 to 0.99678, saving model to connect_4_board_classifier.keras\n",
            "237/237 [==============================] - 2s 7ms/step - loss: 0.9823 - accuracy: 0.6337 - val_loss: 0.9968 - val_accuracy: 0.6601\n",
            "Epoch 4/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.8062 - accuracy: 0.7249\n",
            "Epoch 4: val_loss improved from 0.99678 to 0.70582, saving model to connect_4_board_classifier.keras\n",
            "237/237 [==============================] - 2s 7ms/step - loss: 0.8020 - accuracy: 0.7269 - val_loss: 0.7058 - val_accuracy: 0.7875\n",
            "Epoch 5/200\n",
            "237/237 [==============================] - ETA: 0s - loss: 0.5957 - accuracy: 0.8120\n",
            "Epoch 5: val_loss improved from 0.70582 to 0.60484, saving model to connect_4_board_classifier.keras\n",
            "237/237 [==============================] - 2s 7ms/step - loss: 0.5957 - accuracy: 0.8120 - val_loss: 0.6048 - val_accuracy: 0.8060\n",
            "Epoch 6/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.4897 - accuracy: 0.8516\n",
            "Epoch 6: val_loss improved from 0.60484 to 0.47938, saving model to connect_4_board_classifier.keras\n",
            "237/237 [==============================] - 2s 7ms/step - loss: 0.4875 - accuracy: 0.8525 - val_loss: 0.4794 - val_accuracy: 0.8530\n",
            "Epoch 7/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.3662 - accuracy: 0.8948\n",
            "Epoch 7: val_loss improved from 0.47938 to 0.45077, saving model to connect_4_board_classifier.keras\n",
            "237/237 [==============================] - 2s 7ms/step - loss: 0.3647 - accuracy: 0.8954 - val_loss: 0.4508 - val_accuracy: 0.8708\n",
            "Epoch 8/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.3038 - accuracy: 0.9132\n",
            "Epoch 8: val_loss improved from 0.45077 to 0.43974, saving model to connect_4_board_classifier.keras\n",
            "237/237 [==============================] - 2s 7ms/step - loss: 0.3023 - accuracy: 0.9138 - val_loss: 0.4397 - val_accuracy: 0.8845\n",
            "Epoch 9/200\n",
            "237/237 [==============================] - ETA: 0s - loss: 0.2426 - accuracy: 0.9337\n",
            "Epoch 9: val_loss improved from 0.43974 to 0.39585, saving model to connect_4_board_classifier.keras\n",
            "237/237 [==============================] - 2s 7ms/step - loss: 0.2426 - accuracy: 0.9337 - val_loss: 0.3958 - val_accuracy: 0.9012\n",
            "Epoch 10/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.2121 - accuracy: 0.9400\n",
            "Epoch 10: val_loss did not improve from 0.39585\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.2136 - accuracy: 0.9397 - val_loss: 0.4300 - val_accuracy: 0.8994\n",
            "Epoch 11/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.1850 - accuracy: 0.9457\n",
            "Epoch 11: val_loss improved from 0.39585 to 0.34176, saving model to connect_4_board_classifier.keras\n",
            "237/237 [==============================] - 2s 7ms/step - loss: 0.1863 - accuracy: 0.9456 - val_loss: 0.3418 - val_accuracy: 0.9149\n",
            "Epoch 12/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.1582 - accuracy: 0.9555\n",
            "Epoch 12: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.1581 - accuracy: 0.9555 - val_loss: 0.3587 - val_accuracy: 0.9107\n",
            "Epoch 13/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.1543 - accuracy: 0.9579\n",
            "Epoch 13: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.1548 - accuracy: 0.9576 - val_loss: 0.3569 - val_accuracy: 0.9119\n",
            "Epoch 14/200\n",
            "237/237 [==============================] - ETA: 0s - loss: 0.1623 - accuracy: 0.9542\n",
            "Epoch 14: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.1623 - accuracy: 0.9542 - val_loss: 0.4737 - val_accuracy: 0.9036\n",
            "Epoch 15/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.1382 - accuracy: 0.9604\n",
            "Epoch 15: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.1394 - accuracy: 0.9600 - val_loss: 0.4417 - val_accuracy: 0.9113\n",
            "Epoch 16/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.1142 - accuracy: 0.9665\n",
            "Epoch 16: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.1155 - accuracy: 0.9663 - val_loss: 0.3759 - val_accuracy: 0.9101\n",
            "Epoch 17/200\n",
            "234/237 [============================>.] - ETA: 0s - loss: 0.1100 - accuracy: 0.9673\n",
            "Epoch 17: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.1100 - accuracy: 0.9673 - val_loss: 0.4852 - val_accuracy: 0.9143\n",
            "Epoch 18/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0891 - accuracy: 0.9750\n",
            "Epoch 18: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0894 - accuracy: 0.9752 - val_loss: 0.4082 - val_accuracy: 0.9226\n",
            "Epoch 19/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.0871 - accuracy: 0.9775\n",
            "Epoch 19: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0860 - accuracy: 0.9776 - val_loss: 0.4081 - val_accuracy: 0.9190\n",
            "Epoch 20/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0798 - accuracy: 0.9779\n",
            "Epoch 20: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0803 - accuracy: 0.9774 - val_loss: 0.4436 - val_accuracy: 0.9137\n",
            "Epoch 21/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0857 - accuracy: 0.9772\n",
            "Epoch 21: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0842 - accuracy: 0.9776 - val_loss: 0.4875 - val_accuracy: 0.9226\n",
            "Epoch 22/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0759 - accuracy: 0.9791\n",
            "Epoch 22: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0769 - accuracy: 0.9789 - val_loss: 0.4324 - val_accuracy: 0.9292\n",
            "Epoch 23/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.0701 - accuracy: 0.9810\n",
            "Epoch 23: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0702 - accuracy: 0.9810 - val_loss: 0.4738 - val_accuracy: 0.9185\n",
            "Epoch 24/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.1005 - accuracy: 0.9738\n",
            "Epoch 24: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0999 - accuracy: 0.9740 - val_loss: 0.3875 - val_accuracy: 0.9119\n",
            "Epoch 25/200\n",
            "232/237 [============================>.] - ETA: 0s - loss: 0.0830 - accuracy: 0.9772\n",
            "Epoch 25: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0836 - accuracy: 0.9772 - val_loss: 0.4496 - val_accuracy: 0.9089\n",
            "Epoch 26/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.0722 - accuracy: 0.9807\n",
            "Epoch 26: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0721 - accuracy: 0.9808 - val_loss: 0.5323 - val_accuracy: 0.9179\n",
            "Epoch 27/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0717 - accuracy: 0.9812\n",
            "Epoch 27: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0714 - accuracy: 0.9812 - val_loss: 0.4841 - val_accuracy: 0.9173\n",
            "Epoch 28/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0539 - accuracy: 0.9860\n",
            "Epoch 28: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0545 - accuracy: 0.9858 - val_loss: 0.5343 - val_accuracy: 0.9155\n",
            "Epoch 29/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.0719 - accuracy: 0.9820\n",
            "Epoch 29: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0713 - accuracy: 0.9820 - val_loss: 0.4673 - val_accuracy: 0.9214\n",
            "Epoch 30/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.0577 - accuracy: 0.9867\n",
            "Epoch 30: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0569 - accuracy: 0.9868 - val_loss: 0.5165 - val_accuracy: 0.9220\n",
            "Epoch 31/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0548 - accuracy: 0.9867\n",
            "Epoch 31: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0549 - accuracy: 0.9866 - val_loss: 0.4490 - val_accuracy: 0.9173\n",
            "Epoch 32/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0410 - accuracy: 0.9895\n",
            "Epoch 32: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0414 - accuracy: 0.9894 - val_loss: 0.5574 - val_accuracy: 0.9202\n",
            "Epoch 33/200\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.0518 - accuracy: 0.9864\n",
            "Epoch 33: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0515 - accuracy: 0.9864 - val_loss: 0.6128 - val_accuracy: 0.9137\n",
            "Epoch 34/200\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.0482 - accuracy: 0.9871\n",
            "Epoch 34: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0500 - accuracy: 0.9866 - val_loss: 0.4124 - val_accuracy: 0.9137\n",
            "Epoch 35/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0503 - accuracy: 0.9876\n",
            "Epoch 35: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0506 - accuracy: 0.9876 - val_loss: 0.4517 - val_accuracy: 0.9250\n",
            "Epoch 36/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0324 - accuracy: 0.9909\n",
            "Epoch 36: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0319 - accuracy: 0.9910 - val_loss: 0.5809 - val_accuracy: 0.9155\n",
            "Epoch 37/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.0300 - accuracy: 0.9925\n",
            "Epoch 37: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0308 - accuracy: 0.9924 - val_loss: 0.5111 - val_accuracy: 0.9173\n",
            "Epoch 38/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.0346 - accuracy: 0.9916\n",
            "Epoch 38: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0342 - accuracy: 0.9917 - val_loss: 0.4761 - val_accuracy: 0.9190\n",
            "Epoch 39/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0487 - accuracy: 0.9893\n",
            "Epoch 39: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0485 - accuracy: 0.9893 - val_loss: 0.5219 - val_accuracy: 0.9244\n",
            "Epoch 40/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0539 - accuracy: 0.9886\n",
            "Epoch 40: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0542 - accuracy: 0.9884 - val_loss: 0.4372 - val_accuracy: 0.9161\n",
            "Epoch 41/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0641 - accuracy: 0.9855\n",
            "Epoch 41: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0646 - accuracy: 0.9853 - val_loss: 0.5522 - val_accuracy: 0.9179\n",
            "Epoch 42/200\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.0412 - accuracy: 0.9905\n",
            "Epoch 42: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0426 - accuracy: 0.9901 - val_loss: 0.5729 - val_accuracy: 0.9167\n",
            "Epoch 43/200\n",
            "237/237 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 0.9915\n",
            "Epoch 43: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0357 - accuracy: 0.9915 - val_loss: 0.4673 - val_accuracy: 0.9244\n",
            "Epoch 44/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0386 - accuracy: 0.9902\n",
            "Epoch 44: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0392 - accuracy: 0.9900 - val_loss: 0.5151 - val_accuracy: 0.9232\n",
            "Epoch 45/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0388 - accuracy: 0.9904\n",
            "Epoch 45: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0378 - accuracy: 0.9907 - val_loss: 0.6402 - val_accuracy: 0.9250\n",
            "Epoch 46/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0459 - accuracy: 0.9904\n",
            "Epoch 46: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0469 - accuracy: 0.9901 - val_loss: 0.4457 - val_accuracy: 0.9179\n",
            "Epoch 47/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0480 - accuracy: 0.9897\n",
            "Epoch 47: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0485 - accuracy: 0.9897 - val_loss: 0.5441 - val_accuracy: 0.9232\n",
            "Epoch 48/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0313 - accuracy: 0.9939\n",
            "Epoch 48: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0311 - accuracy: 0.9938 - val_loss: 0.6193 - val_accuracy: 0.9250\n",
            "Epoch 49/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.0382 - accuracy: 0.9924\n",
            "Epoch 49: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0381 - accuracy: 0.9923 - val_loss: 0.5947 - val_accuracy: 0.9208\n",
            "Epoch 50/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0375 - accuracy: 0.9926\n",
            "Epoch 50: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0370 - accuracy: 0.9927 - val_loss: 0.6163 - val_accuracy: 0.9107\n",
            "Epoch 51/200\n",
            "236/237 [============================>.] - ETA: 0s - loss: 0.0402 - accuracy: 0.9913\n",
            "Epoch 51: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0402 - accuracy: 0.9913 - val_loss: 0.6613 - val_accuracy: 0.9286\n",
            "Epoch 52/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0317 - accuracy: 0.9930\n",
            "Epoch 52: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0314 - accuracy: 0.9930 - val_loss: 0.6152 - val_accuracy: 0.9280\n",
            "Epoch 53/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0398 - accuracy: 0.9926\n",
            "Epoch 53: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0558 - accuracy: 0.9905 - val_loss: 63.9167 - val_accuracy: 0.6905\n",
            "Epoch 54/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.3350 - accuracy: 0.9481\n",
            "Epoch 54: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.3293 - accuracy: 0.9489 - val_loss: 0.4152 - val_accuracy: 0.9250\n",
            "Epoch 55/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.9922\n",
            "Epoch 55: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0373 - accuracy: 0.9921 - val_loss: 0.5475 - val_accuracy: 0.9202\n",
            "Epoch 56/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.0313 - accuracy: 0.9922\n",
            "Epoch 56: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0312 - accuracy: 0.9922 - val_loss: 0.4280 - val_accuracy: 0.9220\n",
            "Epoch 57/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.9955\n",
            "Epoch 57: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0185 - accuracy: 0.9956 - val_loss: 0.5914 - val_accuracy: 0.9292\n",
            "Epoch 58/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0204 - accuracy: 0.9964\n",
            "Epoch 58: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0199 - accuracy: 0.9965 - val_loss: 0.5430 - val_accuracy: 0.9280\n",
            "Epoch 59/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.0214 - accuracy: 0.9950\n",
            "Epoch 59: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0225 - accuracy: 0.9948 - val_loss: 0.6214 - val_accuracy: 0.9149\n",
            "Epoch 60/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0424 - accuracy: 0.9919\n",
            "Epoch 60: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0419 - accuracy: 0.9920 - val_loss: 0.5287 - val_accuracy: 0.9220\n",
            "Epoch 61/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0336 - accuracy: 0.9915\n",
            "Epoch 61: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0347 - accuracy: 0.9911 - val_loss: 0.5316 - val_accuracy: 0.9202\n",
            "Epoch 62/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.0363 - accuracy: 0.9915\n",
            "Epoch 62: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0358 - accuracy: 0.9916 - val_loss: 0.6325 - val_accuracy: 0.9238\n",
            "Epoch 63/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0175 - accuracy: 0.9965\n",
            "Epoch 63: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0174 - accuracy: 0.9965 - val_loss: 0.5652 - val_accuracy: 0.9256\n",
            "Epoch 64/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.9957\n",
            "Epoch 64: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0208 - accuracy: 0.9957 - val_loss: 0.5771 - val_accuracy: 0.9298\n",
            "Epoch 65/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.9976\n",
            "Epoch 65: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.6841 - val_accuracy: 0.9226\n",
            "Epoch 66/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9944\n",
            "Epoch 66: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0314 - accuracy: 0.9944 - val_loss: 0.7911 - val_accuracy: 0.9214\n",
            "Epoch 67/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.9937\n",
            "Epoch 67: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0291 - accuracy: 0.9938 - val_loss: 0.6567 - val_accuracy: 0.9208\n",
            "Epoch 68/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0260 - accuracy: 0.9941\n",
            "Epoch 68: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0257 - accuracy: 0.9942 - val_loss: 0.6280 - val_accuracy: 0.9232\n",
            "Epoch 69/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0334 - accuracy: 0.9941\n",
            "Epoch 69: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0343 - accuracy: 0.9942 - val_loss: 0.6473 - val_accuracy: 0.9250\n",
            "Epoch 70/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 0.9961\n",
            "Epoch 70: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0191 - accuracy: 0.9962 - val_loss: 0.7579 - val_accuracy: 0.9298\n",
            "Epoch 71/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0150 - accuracy: 0.9971\n",
            "Epoch 71: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0159 - accuracy: 0.9970 - val_loss: 0.8791 - val_accuracy: 0.9131\n",
            "Epoch 72/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0460 - accuracy: 0.9905\n",
            "Epoch 72: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0466 - accuracy: 0.9905 - val_loss: 0.6365 - val_accuracy: 0.9250\n",
            "Epoch 73/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9935\n",
            "Epoch 73: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0320 - accuracy: 0.9935 - val_loss: 0.6129 - val_accuracy: 0.9250\n",
            "Epoch 74/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9956\n",
            "Epoch 74: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0190 - accuracy: 0.9954 - val_loss: 0.6344 - val_accuracy: 0.9321\n",
            "Epoch 75/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 0.9943\n",
            "Epoch 75: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0291 - accuracy: 0.9943 - val_loss: 0.5407 - val_accuracy: 0.9190\n",
            "Epoch 76/200\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.0168 - accuracy: 0.9964\n",
            "Epoch 76: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0165 - accuracy: 0.9965 - val_loss: 0.5927 - val_accuracy: 0.9304\n",
            "Epoch 77/200\n",
            "233/237 [============================>.] - ETA: 0s - loss: 0.0236 - accuracy: 0.9956\n",
            "Epoch 77: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0233 - accuracy: 0.9956 - val_loss: 0.5103 - val_accuracy: 0.9274\n",
            "Epoch 78/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.9983\n",
            "Epoch 78: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0101 - accuracy: 0.9983 - val_loss: 0.6659 - val_accuracy: 0.9286\n",
            "Epoch 79/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9978\n",
            "Epoch 79: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0116 - accuracy: 0.9976 - val_loss: 0.6869 - val_accuracy: 0.9315\n",
            "Epoch 80/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 0.9945\n",
            "Epoch 80: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0267 - accuracy: 0.9946 - val_loss: 0.6746 - val_accuracy: 0.9196\n",
            "Epoch 81/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9976\n",
            "Epoch 81: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0148 - accuracy: 0.9976 - val_loss: 0.6773 - val_accuracy: 0.9196\n",
            "Epoch 82/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0303 - accuracy: 0.9941\n",
            "Epoch 82: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0307 - accuracy: 0.9939 - val_loss: 0.5805 - val_accuracy: 0.9149\n",
            "Epoch 83/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0224 - accuracy: 0.9953\n",
            "Epoch 83: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0219 - accuracy: 0.9954 - val_loss: 0.6502 - val_accuracy: 0.9167\n",
            "Epoch 84/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0113 - accuracy: 0.9982\n",
            "Epoch 84: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0117 - accuracy: 0.9982 - val_loss: 0.6607 - val_accuracy: 0.9280\n",
            "Epoch 85/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.0338 - accuracy: 0.9933\n",
            "Epoch 85: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0342 - accuracy: 0.9934 - val_loss: 0.4196 - val_accuracy: 0.9244\n",
            "Epoch 86/200\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.0197 - accuracy: 0.9951\n",
            "Epoch 86: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0200 - accuracy: 0.9950 - val_loss: 0.5962 - val_accuracy: 0.9286\n",
            "Epoch 87/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.0305 - accuracy: 0.9943\n",
            "Epoch 87: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0302 - accuracy: 0.9944 - val_loss: 0.5749 - val_accuracy: 0.9256\n",
            "Epoch 88/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0170 - accuracy: 0.9961\n",
            "Epoch 88: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0174 - accuracy: 0.9960 - val_loss: 0.6713 - val_accuracy: 0.9214\n",
            "Epoch 89/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0293 - accuracy: 0.9953\n",
            "Epoch 89: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0294 - accuracy: 0.9951 - val_loss: 0.5166 - val_accuracy: 0.9226\n",
            "Epoch 90/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0293 - accuracy: 0.9953\n",
            "Epoch 90: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0306 - accuracy: 0.9952 - val_loss: 0.5328 - val_accuracy: 0.9286\n",
            "Epoch 91/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9969\n",
            "Epoch 91: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0140 - accuracy: 0.9969 - val_loss: 0.6412 - val_accuracy: 0.9304\n",
            "Epoch 92/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9989\n",
            "Epoch 92: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 1.3519 - val_accuracy: 0.9095\n",
            "Epoch 93/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0512 - accuracy: 0.9872\n",
            "Epoch 93: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0504 - accuracy: 0.9874 - val_loss: 0.6547 - val_accuracy: 0.9185\n",
            "Epoch 94/200\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.0189 - accuracy: 0.9963\n",
            "Epoch 94: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0191 - accuracy: 0.9963 - val_loss: 0.7204 - val_accuracy: 0.9232\n",
            "Epoch 95/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0247 - accuracy: 0.9953\n",
            "Epoch 95: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0255 - accuracy: 0.9954 - val_loss: 0.7305 - val_accuracy: 0.9161\n",
            "Epoch 96/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.9948\n",
            "Epoch 96: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0262 - accuracy: 0.9949 - val_loss: 0.5271 - val_accuracy: 0.9256\n",
            "Epoch 97/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0213 - accuracy: 0.9956\n",
            "Epoch 97: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0213 - accuracy: 0.9954 - val_loss: 0.6307 - val_accuracy: 0.9202\n",
            "Epoch 98/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9972\n",
            "Epoch 98: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0149 - accuracy: 0.9972 - val_loss: 0.5809 - val_accuracy: 0.9250\n",
            "Epoch 99/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9974\n",
            "Epoch 99: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0143 - accuracy: 0.9974 - val_loss: 0.5887 - val_accuracy: 0.9292\n",
            "Epoch 100/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9968\n",
            "Epoch 100: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0164 - accuracy: 0.9968 - val_loss: 0.5164 - val_accuracy: 0.9244\n",
            "Epoch 101/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.9963\n",
            "Epoch 101: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0162 - accuracy: 0.9962 - val_loss: 0.5558 - val_accuracy: 0.9286\n",
            "Epoch 102/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0308 - accuracy: 0.9942\n",
            "Epoch 102: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0302 - accuracy: 0.9942 - val_loss: 0.6639 - val_accuracy: 0.9244\n",
            "Epoch 103/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9961\n",
            "Epoch 103: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0192 - accuracy: 0.9960 - val_loss: 0.5162 - val_accuracy: 0.9244\n",
            "Epoch 104/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.0297 - accuracy: 0.9959\n",
            "Epoch 104: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0292 - accuracy: 0.9960 - val_loss: 0.5311 - val_accuracy: 0.9274\n",
            "Epoch 105/200\n",
            "233/237 [============================>.] - ETA: 0s - loss: 0.0293 - accuracy: 0.9947\n",
            "Epoch 105: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0289 - accuracy: 0.9948 - val_loss: 0.6294 - val_accuracy: 0.9232\n",
            "Epoch 106/200\n",
            "234/237 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9965\n",
            "Epoch 106: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0160 - accuracy: 0.9964 - val_loss: 0.6609 - val_accuracy: 0.9250\n",
            "Epoch 107/200\n",
            "237/237 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9977\n",
            "Epoch 107: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0113 - accuracy: 0.9977 - val_loss: 0.6436 - val_accuracy: 0.9244\n",
            "Epoch 108/200\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.0356 - accuracy: 0.9921\n",
            "Epoch 108: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0352 - accuracy: 0.9921 - val_loss: 0.9663 - val_accuracy: 0.9137\n",
            "Epoch 109/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0234 - accuracy: 0.9948\n",
            "Epoch 109: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0232 - accuracy: 0.9948 - val_loss: 0.9188 - val_accuracy: 0.9173\n",
            "Epoch 110/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0256 - accuracy: 0.9957\n",
            "Epoch 110: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0256 - accuracy: 0.9957 - val_loss: 0.7441 - val_accuracy: 0.9107\n",
            "Epoch 111/200\n",
            "235/237 [============================>.] - ETA: 0s - loss: 0.0518 - accuracy: 0.9923\n",
            "Epoch 111: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0515 - accuracy: 0.9923 - val_loss: 0.5942 - val_accuracy: 0.9244\n",
            "Epoch 112/200\n",
            "234/237 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9987\n",
            "Epoch 112: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.8450 - val_accuracy: 0.9220\n",
            "Epoch 113/200\n",
            "237/237 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9957\n",
            "Epoch 113: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0234 - accuracy: 0.9957 - val_loss: 0.6137 - val_accuracy: 0.9298\n",
            "Epoch 114/200\n",
            "236/237 [============================>.] - ETA: 0s - loss: 0.0223 - accuracy: 0.9964\n",
            "Epoch 114: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0223 - accuracy: 0.9964 - val_loss: 0.7239 - val_accuracy: 0.9220\n",
            "Epoch 115/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0113 - accuracy: 0.9984\n",
            "Epoch 115: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0110 - accuracy: 0.9985 - val_loss: 0.7472 - val_accuracy: 0.9250\n",
            "Epoch 116/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9978\n",
            "Epoch 116: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0161 - accuracy: 0.9978 - val_loss: 0.6992 - val_accuracy: 0.9310\n",
            "Epoch 117/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9972\n",
            "Epoch 117: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0253 - accuracy: 0.9970 - val_loss: 0.8321 - val_accuracy: 0.9238\n",
            "Epoch 118/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0261 - accuracy: 0.9950\n",
            "Epoch 118: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0264 - accuracy: 0.9949 - val_loss: 0.5814 - val_accuracy: 0.9292\n",
            "Epoch 119/200\n",
            "237/237 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9989\n",
            "Epoch 119: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.7660 - val_accuracy: 0.9280\n",
            "Epoch 120/200\n",
            "235/237 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9989\n",
            "Epoch 120: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0095 - accuracy: 0.9989 - val_loss: 0.6773 - val_accuracy: 0.9357\n",
            "Epoch 121/200\n",
            "234/237 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9994\n",
            "Epoch 121: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.9236 - val_accuracy: 0.9327\n",
            "Epoch 122/200\n",
            "237/237 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9989\n",
            "Epoch 122: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 0.6124 - val_accuracy: 0.9214\n",
            "Epoch 123/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0225 - accuracy: 0.9955\n",
            "Epoch 123: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0235 - accuracy: 0.9954 - val_loss: 0.6598 - val_accuracy: 0.9238\n",
            "Epoch 124/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.0179 - accuracy: 0.9971\n",
            "Epoch 124: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0175 - accuracy: 0.9972 - val_loss: 0.6478 - val_accuracy: 0.9262\n",
            "Epoch 125/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.9965\n",
            "Epoch 125: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0198 - accuracy: 0.9964 - val_loss: 0.7104 - val_accuracy: 0.9268\n",
            "Epoch 126/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0375 - accuracy: 0.9929\n",
            "Epoch 126: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0382 - accuracy: 0.9931 - val_loss: 0.6823 - val_accuracy: 0.9298\n",
            "Epoch 127/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9965\n",
            "Epoch 127: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0152 - accuracy: 0.9965 - val_loss: 0.7011 - val_accuracy: 0.9304\n",
            "Epoch 128/200\n",
            "237/237 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9984\n",
            "Epoch 128: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0114 - accuracy: 0.9984 - val_loss: 0.8976 - val_accuracy: 0.9268\n",
            "Epoch 129/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0061 - accuracy: 0.9992\n",
            "Epoch 129: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0060 - accuracy: 0.9992 - val_loss: 0.8803 - val_accuracy: 0.9327\n",
            "Epoch 130/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9996\n",
            "Epoch 130: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 1.3845 - val_accuracy: 0.9304\n",
            "Epoch 131/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0047 - accuracy: 0.9996\n",
            "Epoch 131: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0064 - accuracy: 0.9994 - val_loss: 0.6500 - val_accuracy: 0.9244\n",
            "Epoch 132/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9976\n",
            "Epoch 132: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0130 - accuracy: 0.9976 - val_loss: 0.6385 - val_accuracy: 0.9286\n",
            "Epoch 133/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9963\n",
            "Epoch 133: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0162 - accuracy: 0.9962 - val_loss: 0.7867 - val_accuracy: 0.9220\n",
            "Epoch 134/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0884 - accuracy: 0.9807\n",
            "Epoch 134: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0868 - accuracy: 0.9810 - val_loss: 0.5357 - val_accuracy: 0.9208\n",
            "Epoch 135/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9971\n",
            "Epoch 135: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0151 - accuracy: 0.9972 - val_loss: 0.6435 - val_accuracy: 0.9286\n",
            "Epoch 136/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0077 - accuracy: 0.9986\n",
            "Epoch 136: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.7177 - val_accuracy: 0.9280\n",
            "Epoch 137/200\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 0.0104 - accuracy: 0.9979\n",
            "Epoch 137: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0127 - accuracy: 0.9976 - val_loss: 0.5730 - val_accuracy: 0.9196\n",
            "Epoch 138/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.9962\n",
            "Epoch 138: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 0.0180 - accuracy: 0.9963 - val_loss: 0.5503 - val_accuracy: 0.9220\n",
            "Epoch 139/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 0.0080 - accuracy: 0.9983\n",
            "Epoch 139: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.5629 - val_accuracy: 0.9292\n",
            "Epoch 140/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9997\n",
            "Epoch 140: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.7354 - val_accuracy: 0.9327\n",
            "Epoch 141/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 7.1099e-04 - accuracy: 0.9999\n",
            "Epoch 141: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 6.9352e-04 - accuracy: 0.9999 - val_loss: 1.0958 - val_accuracy: 0.9351\n",
            "Epoch 142/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 6.1144e-06 - accuracy: 1.0000\n",
            "Epoch 142: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 6.0091e-06 - accuracy: 1.0000 - val_loss: 1.1773 - val_accuracy: 0.9357\n",
            "Epoch 143/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 2.1225e-06 - accuracy: 1.0000\n",
            "Epoch 143: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 2.0747e-06 - accuracy: 1.0000 - val_loss: 1.2578 - val_accuracy: 0.9357\n",
            "Epoch 144/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 1.0961e-06 - accuracy: 1.0000\n",
            "Epoch 144: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 1.0633e-06 - accuracy: 1.0000 - val_loss: 1.3150 - val_accuracy: 0.9357\n",
            "Epoch 145/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 5.6936e-07 - accuracy: 1.0000\n",
            "Epoch 145: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 5.5795e-07 - accuracy: 1.0000 - val_loss: 1.3941 - val_accuracy: 0.9357\n",
            "Epoch 146/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 1.5786e-07 - accuracy: 1.0000\n",
            "Epoch 146: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 1.5398e-07 - accuracy: 1.0000 - val_loss: 1.4429 - val_accuracy: 0.9357\n",
            "Epoch 147/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 9.4063e-08 - accuracy: 1.0000\n",
            "Epoch 147: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 9.2347e-08 - accuracy: 1.0000 - val_loss: 1.4819 - val_accuracy: 0.9345\n",
            "Epoch 148/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 6.3334e-08 - accuracy: 1.0000\n",
            "Epoch 148: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 6.2266e-08 - accuracy: 1.0000 - val_loss: 1.5143 - val_accuracy: 0.9345\n",
            "Epoch 149/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 4.4888e-08 - accuracy: 1.0000\n",
            "Epoch 149: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 4.3913e-08 - accuracy: 1.0000 - val_loss: 1.5420 - val_accuracy: 0.9345\n",
            "Epoch 150/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 3.3599e-08 - accuracy: 1.0000\n",
            "Epoch 150: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 3.3081e-08 - accuracy: 1.0000 - val_loss: 1.5645 - val_accuracy: 0.9345\n",
            "Epoch 151/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 2.6407e-08 - accuracy: 1.0000\n",
            "Epoch 151: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 2.5820e-08 - accuracy: 1.0000 - val_loss: 1.5875 - val_accuracy: 0.9345\n",
            "Epoch 152/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 2.1031e-08 - accuracy: 1.0000\n",
            "Epoch 152: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 2.0632e-08 - accuracy: 1.0000 - val_loss: 1.6077 - val_accuracy: 0.9345\n",
            "Epoch 153/200\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 1.7213e-08 - accuracy: 1.0000\n",
            "Epoch 153: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 1.6706e-08 - accuracy: 1.0000 - val_loss: 1.6270 - val_accuracy: 0.9345\n",
            "Epoch 154/200\n",
            "236/237 [============================>.] - ETA: 0s - loss: 1.3899e-08 - accuracy: 1.0000\n",
            "Epoch 154: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 1.3884e-08 - accuracy: 1.0000 - val_loss: 1.6443 - val_accuracy: 0.9345\n",
            "Epoch 155/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 1.1942e-08 - accuracy: 1.0000\n",
            "Epoch 155: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 1.1676e-08 - accuracy: 1.0000 - val_loss: 1.6610 - val_accuracy: 0.9345\n",
            "Epoch 156/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 1.0091e-08 - accuracy: 1.0000\n",
            "Epoch 156: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 1.0013e-08 - accuracy: 1.0000 - val_loss: 1.6763 - val_accuracy: 0.9345\n",
            "Epoch 157/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 8.7925e-09 - accuracy: 1.0000\n",
            "Epoch 157: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 8.5464e-09 - accuracy: 1.0000 - val_loss: 1.6916 - val_accuracy: 0.9339\n",
            "Epoch 158/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 7.4505e-09 - accuracy: 1.0000\n",
            "Epoch 158: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 7.3559e-09 - accuracy: 1.0000 - val_loss: 1.7051 - val_accuracy: 0.9339\n",
            "Epoch 159/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 6.5354e-09 - accuracy: 1.0000\n",
            "Epoch 159: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 6.3783e-09 - accuracy: 1.0000 - val_loss: 1.7187 - val_accuracy: 0.9339\n",
            "Epoch 160/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 5.7094e-09 - accuracy: 1.0000\n",
            "Epoch 160: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 5.5583e-09 - accuracy: 1.0000 - val_loss: 1.7318 - val_accuracy: 0.9339\n",
            "Epoch 161/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 4.9106e-09 - accuracy: 1.0000\n",
            "Epoch 161: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 4.8566e-09 - accuracy: 1.0000 - val_loss: 1.7444 - val_accuracy: 0.9339\n",
            "Epoch 162/200\n",
            "235/237 [============================>.] - ETA: 0s - loss: 4.2642e-09 - accuracy: 1.0000\n",
            "Epoch 162: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 4.2417e-09 - accuracy: 1.0000 - val_loss: 1.7566 - val_accuracy: 0.9339\n",
            "Epoch 163/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 3.8717e-09 - accuracy: 1.0000\n",
            "Epoch 163: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 3.7607e-09 - accuracy: 1.0000 - val_loss: 1.7684 - val_accuracy: 0.9339\n",
            "Epoch 164/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 3.3140e-09 - accuracy: 1.0000\n",
            "Epoch 164: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 3.2956e-09 - accuracy: 1.0000 - val_loss: 1.7795 - val_accuracy: 0.9339\n",
            "Epoch 165/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 2.9883e-09 - accuracy: 1.0000\n",
            "Epoch 165: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 2.9093e-09 - accuracy: 1.0000 - val_loss: 1.7910 - val_accuracy: 0.9339\n",
            "Epoch 166/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 2.5883e-09 - accuracy: 1.0000\n",
            "Epoch 166: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 5ms/step - loss: 2.5860e-09 - accuracy: 1.0000 - val_loss: 1.8014 - val_accuracy: 0.9339\n",
            "Epoch 167/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 2.2838e-09 - accuracy: 1.0000\n",
            "Epoch 167: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 2.2706e-09 - accuracy: 1.0000 - val_loss: 1.8114 - val_accuracy: 0.9339\n",
            "Epoch 168/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 1.9917e-09 - accuracy: 1.0000\n",
            "Epoch 168: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 2.0420e-09 - accuracy: 1.0000 - val_loss: 1.8212 - val_accuracy: 0.9339\n",
            "Epoch 169/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 1.8868e-09 - accuracy: 1.0000\n",
            "Epoch 169: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 1.8528e-09 - accuracy: 1.0000 - val_loss: 1.8315 - val_accuracy: 0.9339\n",
            "Epoch 170/200\n",
            "237/237 [==============================] - ETA: 0s - loss: 1.6714e-09 - accuracy: 1.0000\n",
            "Epoch 170: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 1.6714e-09 - accuracy: 1.0000 - val_loss: 1.8409 - val_accuracy: 0.9339\n",
            "Epoch 171/200\n",
            "236/237 [============================>.] - ETA: 0s - loss: 1.4759e-09 - accuracy: 1.0000\n",
            "Epoch 171: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 1.4743e-09 - accuracy: 1.0000 - val_loss: 1.8497 - val_accuracy: 0.9339\n",
            "Epoch 172/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 1.3305e-09 - accuracy: 1.0000\n",
            "Epoch 172: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 1.3088e-09 - accuracy: 1.0000 - val_loss: 1.8588 - val_accuracy: 0.9339\n",
            "Epoch 173/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 1.1743e-09 - accuracy: 1.0000\n",
            "Epoch 173: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 1.1669e-09 - accuracy: 1.0000 - val_loss: 1.8676 - val_accuracy: 0.9339\n",
            "Epoch 174/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 1.0644e-09 - accuracy: 1.0000\n",
            "Epoch 174: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 1.0407e-09 - accuracy: 1.0000 - val_loss: 1.8761 - val_accuracy: 0.9339\n",
            "Epoch 175/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 9.7181e-10 - accuracy: 1.0000\n",
            "Epoch 175: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 9.5399e-10 - accuracy: 1.0000 - val_loss: 1.8838 - val_accuracy: 0.9339\n",
            "Epoch 176/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 8.7891e-10 - accuracy: 1.0000\n",
            "Epoch 176: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 8.7515e-10 - accuracy: 1.0000 - val_loss: 1.8924 - val_accuracy: 0.9339\n",
            "Epoch 177/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 7.7409e-10 - accuracy: 1.0000\n",
            "Epoch 177: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 7.8054e-10 - accuracy: 1.0000 - val_loss: 1.9001 - val_accuracy: 0.9339\n",
            "Epoch 178/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 4.0492e-10 - accuracy: 1.0000\n",
            "Epoch 178: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 7.1746e-10 - accuracy: 1.0000 - val_loss: 1.9072 - val_accuracy: 0.9339\n",
            "Epoch 179/200\n",
            "235/237 [============================>.] - ETA: 0s - loss: 6.4202e-10 - accuracy: 1.0000\n",
            "Epoch 179: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 6.3862e-10 - accuracy: 1.0000 - val_loss: 1.9159 - val_accuracy: 0.9339\n",
            "Epoch 180/200\n",
            "236/237 [============================>.] - ETA: 0s - loss: 5.6826e-10 - accuracy: 1.0000\n",
            "Epoch 180: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 5.6766e-10 - accuracy: 1.0000 - val_loss: 1.9232 - val_accuracy: 0.9339\n",
            "Epoch 181/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 5.1606e-10 - accuracy: 1.0000\n",
            "Epoch 181: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 5.0459e-10 - accuracy: 1.0000 - val_loss: 1.9303 - val_accuracy: 0.9339\n",
            "Epoch 182/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 4.5351e-10 - accuracy: 1.0000\n",
            "Epoch 182: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 4.4152e-10 - accuracy: 1.0000 - val_loss: 1.9367 - val_accuracy: 0.9339\n",
            "Epoch 183/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 4.0669e-10 - accuracy: 1.0000\n",
            "Epoch 183: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 4.0209e-10 - accuracy: 1.0000 - val_loss: 1.9440 - val_accuracy: 0.9339\n",
            "Epoch 184/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 3.6285e-10 - accuracy: 1.0000\n",
            "Epoch 184: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 3.7844e-10 - accuracy: 1.0000 - val_loss: 1.9505 - val_accuracy: 0.9339\n",
            "Epoch 185/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 2.9028e-10 - accuracy: 1.0000\n",
            "Epoch 185: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 3.3114e-10 - accuracy: 1.0000 - val_loss: 1.9565 - val_accuracy: 0.9339\n",
            "Epoch 186/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 3.1722e-10 - accuracy: 1.0000\n",
            "Epoch 186: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 3.0748e-10 - accuracy: 1.0000 - val_loss: 1.9630 - val_accuracy: 0.9339\n",
            "Epoch 187/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 2.7655e-10 - accuracy: 1.0000\n",
            "Epoch 187: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 2.8383e-10 - accuracy: 1.0000 - val_loss: 1.9691 - val_accuracy: 0.9339\n",
            "Epoch 188/200\n",
            "236/237 [============================>.] - ETA: 0s - loss: 2.5256e-10 - accuracy: 1.0000\n",
            "Epoch 188: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 2.5229e-10 - accuracy: 1.0000 - val_loss: 1.9755 - val_accuracy: 0.9339\n",
            "Epoch 189/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 2.4997e-10 - accuracy: 1.0000\n",
            "Epoch 189: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 2.4441e-10 - accuracy: 1.0000 - val_loss: 1.9816 - val_accuracy: 0.9339\n",
            "Epoch 190/200\n",
            "230/237 [============================>.] - ETA: 0s - loss: 2.2676e-10 - accuracy: 1.0000\n",
            "Epoch 190: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 2.2076e-10 - accuracy: 1.0000 - val_loss: 1.9873 - val_accuracy: 0.9339\n",
            "Epoch 191/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 2.0335e-10 - accuracy: 1.0000\n",
            "Epoch 191: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 1.9711e-10 - accuracy: 1.0000 - val_loss: 1.9932 - val_accuracy: 0.9339\n",
            "Epoch 192/200\n",
            "237/237 [==============================] - ETA: 0s - loss: 1.7345e-10 - accuracy: 1.0000\n",
            "Epoch 192: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 1.7345e-10 - accuracy: 1.0000 - val_loss: 1.9986 - val_accuracy: 0.9339\n",
            "Epoch 193/200\n",
            "237/237 [==============================] - ETA: 0s - loss: 1.5768e-10 - accuracy: 1.0000\n",
            "Epoch 193: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 1.5768e-10 - accuracy: 1.0000 - val_loss: 2.0038 - val_accuracy: 0.9339\n",
            "Epoch 194/200\n",
            "228/237 [===========================>..] - ETA: 0s - loss: 1.3071e-10 - accuracy: 1.0000\n",
            "Epoch 194: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 1.2615e-10 - accuracy: 1.0000 - val_loss: 2.0093 - val_accuracy: 0.9339\n",
            "Epoch 195/200\n",
            "236/237 [============================>.] - ETA: 0s - loss: 1.1839e-10 - accuracy: 1.0000\n",
            "Epoch 195: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 1.1826e-10 - accuracy: 1.0000 - val_loss: 2.0144 - val_accuracy: 0.9339\n",
            "Epoch 196/200\n",
            "237/237 [==============================] - ETA: 0s - loss: 1.2615e-10 - accuracy: 1.0000\n",
            "Epoch 196: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 1.2615e-10 - accuracy: 1.0000 - val_loss: 2.0197 - val_accuracy: 0.9339\n",
            "Epoch 197/200\n",
            "231/237 [============================>.] - ETA: 0s - loss: 9.6761e-11 - accuracy: 1.0000\n",
            "Epoch 197: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 1.0249e-10 - accuracy: 1.0000 - val_loss: 2.0246 - val_accuracy: 0.9339\n",
            "Epoch 198/200\n",
            "232/237 [============================>.] - ETA: 0s - loss: 9.6344e-11 - accuracy: 1.0000\n",
            "Epoch 198: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 9.4611e-11 - accuracy: 1.0000 - val_loss: 2.0295 - val_accuracy: 0.9339\n",
            "Epoch 199/200\n",
            "229/237 [===========================>..] - ETA: 0s - loss: 9.7606e-11 - accuracy: 1.0000\n",
            "Epoch 199: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 9.4611e-11 - accuracy: 1.0000 - val_loss: 2.0342 - val_accuracy: 0.9339\n",
            "Epoch 200/200\n",
            "234/237 [============================>.] - ETA: 0s - loss: 8.7560e-11 - accuracy: 1.0000\n",
            "Epoch 200: val_loss did not improve from 0.34176\n",
            "237/237 [==============================] - 1s 6ms/step - loss: 8.6726e-11 - accuracy: 1.0000 - val_loss: 2.0386 - val_accuracy: 0.9339\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "Custom Test Accuracy: 0.9619047619047619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_label_confusion_matrix(y_true_multi, y_pred_classes, num_classes):\n",
        "    cm = np.zeros((num_classes, num_classes), dtype=int)\n",
        "    for true, pred in zip(y_true_multi, y_pred_classes):\n",
        "        true_indices = np.where(true == 1)[0]\n",
        "        true_index = np.argmax(true)\n",
        "        if pred in true_indices:\n",
        "            true_index = pred\n",
        "        cm[true_index, pred] += 1\n",
        "    return cm\n",
        "\n",
        "y_pred = model.predict(X_perfect_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "num_classes = y_perfect_multi_test.shape[1]\n",
        "\n",
        "cm = multi_label_confusion_matrix(y_perfect_multi_test, y_pred_classes, num_classes)\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Custom Accuracy Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "LlviY7C4e0_q",
        "outputId": "5f423fae-dcab-484f-93af-eed3ad7a109c"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132/132 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}